"""
Enhanced ReAct Loop for ANY Mobile Task - FULLY FIXED VERSION
================================================================

FIXES IMPLEMENTED:
1. ‚úÖ Retrieves COMPLETE UI tree (all elements, not just 2-3)
2. ‚úÖ Dynamic app detection (no hardcoded app mappings)
3. ‚úÖ Proper AURA app exit detection
4. ‚úÖ Smart navigation (detects when stuck, uses alternative strategies)
5. ‚úÖ Works for ANY app (Gmail, YouTube, Messages, Chrome, etc.)
6. ‚úÖ No synthetic screens - only real Android UI
7. ‚úÖ Proper home screen detection with all apps visible

CRITICAL CHANGES:
- Enhanced LLM prompt with better context awareness
- Improved device state detection (detects AURA app specifically)
- Better stuck detection (recognizes when BACK isn't working)
- Dynamic app icon detection from UI tree
- Proper element counting and validation
"""

import logging
import asyncio
import json
import re
import httpx
from typing import Optional, List, Dict, Any

from agents.utils.device_protocol import (
    MobileTaskRequest, MobileTaskResult, UIAction, ActionResult,
    SemanticUITree
)
from agents.execution_agent.core.exec_agent_models import ExecutionResult

logger = logging.getLogger(__name__)


class MobileReActStrategy:
    """
    Fully dynamic ReAct loop with NO hardcoded app mappings.
    Works for ANY Android app by analyzing the real UI tree.
    """
    def __init__(self, device_id: str = "default_device"):
        self.device_id = device_id
        self.backend_url = "http://localhost:8000"
        
        # Initialize Groq LLM
        from groq import AsyncGroq
        
        api_key = "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"
        self.llm_client = AsyncGroq(api_key=api_key)
        self.model = "llama-3.3-70b-versatile"
        
        # Device state tracking
        self.current_ui_tree: Optional[SemanticUITree] = None
        self.previous_ui_trees: List[SemanticUITree] = []
        self.action_history: List[Dict] = []
        self.device_state: str = "unknown"
        self.stuck_counter: int = 0  # Track how many times we're stuck
        
        logger.info(f"‚úÖ Initialized Enhanced MobileReActStrategy for device {device_id}")
    
    async def execute_task(self, task: MobileTaskRequest) -> MobileTaskResult:
        """Execute ANY task using enhanced ReAct loop with proper UI tree handling"""
        
        logger.info(f"\n{'='*70}")
        logger.info(f"üéØ STARTING ENHANCED REACT LOOP")
        logger.info(f"{'='*70}")
        logger.info(f"Goal: {task.ai_prompt}")
        logger.info(f"Device: {task.device_id}")
        logger.info(f"Max Steps: {task.max_steps}")
        logger.info(f"{'='*70}\n")
        
        start_time = asyncio.get_event_loop().time()
        actions_executed: List[UIAction] = []
        thought_history: List[str] = []
        
        # Get initial UI state with validation
        logger.info(f"üëÅÔ∏è Getting initial UI state...")
        await asyncio.sleep(1.5)  # Give device time to stabilize
        
        ui_tree = await self._fetch_ui_tree_from_device()
        
        if not ui_tree:
            return self._build_error_result(task.task_id, "Failed to get initial UI tree")
        
        # CRITICAL: Validate UI tree is not empty or incomplete
        if not ui_tree.elements or len(ui_tree.elements) < 3:
            logger.warning(f"‚ö†Ô∏è UI tree has only {len(ui_tree.elements)} elements - may be incomplete!")
            logger.warning(f"   Waiting longer for UI to fully load...")
            await asyncio.sleep(2.0)
            ui_tree = await self._fetch_ui_tree_from_device()
        
        self.current_ui_tree = ui_tree
        self.previous_ui_trees.append(ui_tree)
        self.device_state = self._detect_device_state(ui_tree)
        
        logger.info(f"‚úÖ Initial UI captured: {ui_tree.screen_name or ui_tree.app_name}")
        logger.info(f"   Elements found: {len(ui_tree.elements)}")
        logger.info(f"   Device state: {self.device_state}")
        logger.info(f"   App: {ui_tree.app_name}")
        
        # Log element details for debugging
        if ui_tree.elements:
            logger.info(f"   üì¶ UI Elements:")
            for elem in ui_tree.elements[:15]:  # Show first 15 elements
                elem_text = elem.text[:40] if elem.text else "(no text)"
                logger.info(f"      [{elem.element_id}] {elem.type:12} | {elem_text}")
        
        # ReAct Loop
        for step in range(task.max_steps):
            logger.info(f"\n{'='*70}")
            logger.info(f"üìç STEP {step + 1}/{task.max_steps}")
            logger.info(f"{'='*70}")
            
            # Check timeout
            elapsed = asyncio.get_event_loop().time() - start_time
            if elapsed > task.timeout_seconds:
                logger.warning(f"‚è±Ô∏è Timeout reached")
                return self._build_result(
                    task_id=task.task_id,
                    status="timeout",
                    steps=step,
                    actions=actions_executed,
                    elapsed=elapsed,
                    error=f"Timeout after {task.timeout_seconds}s"
                )
            
            # Check if we're stuck in a loop
            if self._detect_stuck_in_loop():
                logger.error(f"‚ùå Stuck in infinite loop - taking corrective action")
                # Try HOME action as last resort
                home_action = UIAction(action_type="global_action", global_action="HOME", duration=1000)
                await self._execute_action_on_device(home_action)
                await asyncio.sleep(2.0)
                ui_tree = await self._fetch_ui_tree_from_device()
                if ui_tree:
                    self.current_ui_tree = ui_tree
                    self.device_state = self._detect_device_state(ui_tree)
                    logger.info(f"üè† Forced HOME action - new state: {self.device_state}")
            
            # THINK: Analyze current UI
            logger.info(f"ü§î THINK: Analyzing current screen...")
            
            observation = self.current_ui_tree.to_semantic_string()
            logger.info(f"üìã Current Observation:\n{observation}\n")
            
            thought, action_json = await self._think_and_decide(
                goal=task.ai_prompt,
                observation=observation,
                thought_history=thought_history,
                step_number=step + 1
            )
            
            if not action_json:
                logger.error(f"‚ùå Failed to generate valid action")
                return self._build_result(
                    task_id=task.task_id,
                    status="failed",
                    steps=step,
                    actions=actions_executed,
                    elapsed=elapsed,
                    error="LLM failed to generate valid action"
                )
            
            thought_history.append(thought)
            logger.info(f"üí≠ Thought: {thought}")
            
            # Check if goal achieved
            if action_json.get("action_type") == "complete":
                logger.info(f"\n{'='*70}")
                logger.info(f"‚úÖ GOAL ACHIEVED!")
                logger.info(f"{'='*70}")
                
                return self._build_result(
                    task_id=task.task_id,
                    status="success",
                    steps=step + 1,
                    actions=actions_executed,
                    elapsed=elapsed,
                    completion_reason=action_json.get("reason", "Task completed")
                )
            
            # ACT: Execute action
            logger.info(f"üé¨ ACT: Executing action...")
            logger.info(f"   Type: {action_json.get('action_type')}")
            
            action = self._json_to_ui_action(action_json)
            logger.info(f"   Action: {action.model_dump()}")
            
            # Track action history
            self.action_history.append({
                "step": step + 1,
                "action": action_json,
                "device_state": self.device_state
            })
            
            result = await self._execute_action_on_device(action)
            actions_executed.append(action)
            
            if not result.success:
                logger.warning(f"‚ö†Ô∏è Action execution failed: {result.error}")
            else:
                logger.info(f"‚úÖ Action executed successfully")
            
            # OBSERVE: Get new UI state
            logger.info(f"üëÅÔ∏è OBSERVE: Getting new UI state...")
            
            # Wait for UI to update based on action type
            wait_time = self._get_wait_time_for_action(action_json.get("action_type"))
            logger.info(f"‚è≥ Waiting {wait_time}s for UI to stabilize...")
            await asyncio.sleep(wait_time)
            
            new_ui_tree = await self._fetch_ui_tree_from_device()
            
            if new_ui_tree:
                # Validate new UI tree
                if not new_ui_tree.elements or len(new_ui_tree.elements) < 2:
                    logger.warning(f"‚ö†Ô∏è New UI tree incomplete ({len(new_ui_tree.elements)} elements) - waiting longer...")
                    await asyncio.sleep(1.5)
                    new_ui_tree = await self._fetch_ui_tree_from_device()
                
                self.current_ui_tree = new_ui_tree
                self.previous_ui_trees.append(new_ui_tree)
                
                # Keep only last 5 states
                if len(self.previous_ui_trees) > 5:
                    self.previous_ui_trees.pop(0)
                
                new_device_state = self._detect_device_state(new_ui_tree)
                
                logger.info(f"‚úÖ New UI captured: {new_ui_tree.screen_name or new_ui_tree.app_name}")
                logger.info(f"   Elements: {len(new_ui_tree.elements)}")
                logger.info(f"   Device state: {new_device_state}")
                
                # Log element details
                if new_ui_tree.elements:
                    logger.info(f"   üì¶ UI Elements:")
                    for elem in new_ui_tree.elements[:10]:
                        elem_text = elem.text[:40] if elem.text else "(no text)"
                        logger.info(f"      [{elem.element_id}] {elem.type:12} | {elem_text}")
                
                # Update device state if changed
                if new_device_state != self.device_state:
                    logger.info(f"üîÑ Device state changed: {self.device_state} ‚Üí {new_device_state}")
                    self.device_state = new_device_state
                    self.stuck_counter = 0  # Reset stuck counter on state change
                else:
                    self.stuck_counter += 1
            else:
                logger.warning(f"‚ö†Ô∏è Failed to get new UI tree")
        
        # Max steps reached
        logger.warning(f"\n{'='*70}")
        logger.warning(f"‚ö†Ô∏è MAX STEPS REACHED WITHOUT COMPLETION")
        logger.warning(f"{'='*70}")
        
        return self._build_result(
            task_id=task.task_id,
            status="failed",
            steps=task.max_steps,
            actions=actions_executed,
            elapsed=asyncio.get_event_loop().time() - start_time,
            error=f"Max steps ({task.max_steps}) reached"
        )
    
    def _detect_device_state(self, ui_tree: SemanticUITree) -> str:
        """
        Detect current device state - FULLY DYNAMIC
        No hardcoded app names, just pattern detection
        """
        app_name = ui_tree.app_name.lower()
        screen_name = ui_tree.screen_name.lower() if ui_tree.screen_name else ""
        
        # CRITICAL: Check if we're in AURA app FIRST
        if "aura" in app_name or "aura_project" in app_name:
            logger.info(f"üîç Detected AURA app: {app_name}")
            return "in_aura"
        
        # Check for home screen indicators
        home_indicators = [
            "launcher", "home screen", "desktop", "wallpaper",
            "homescreen", "main screen", "pixel launcher",
            "android launcher", "trebuchet", "nova launcher"
        ]
        
        if any(indicator in app_name or indicator in screen_name for indicator in home_indicators):
            return "home_screen"
        
        # Check for app drawer
        if "app drawer" in screen_name or "all apps" in screen_name:
            return "app_drawer"
        
        # Otherwise we're in an app
        return f"in_app_{app_name.replace('.', '_')}"
    
    def _detect_stuck_in_loop(self) -> bool:
        """
        Detect if we're stuck in an infinite loop
        
        Returns True if:
        - Same device state for 4+ consecutive steps
        - Same action repeated 3+ times
        - stuck_counter > 3
        """
        if self.stuck_counter > 3:
            logger.warning(f"‚ö†Ô∏è Stuck counter exceeded: {self.stuck_counter}")
            return True
        
        if len(self.previous_ui_trees) < 4:
            return False
        
        # Check if device state hasn't changed
        recent_states = [self._detect_device_state(tree) for tree in self.previous_ui_trees[-4:]]
        if len(set(recent_states)) == 1:
            logger.warning(f"‚ö†Ô∏è Same device state for 4 steps: {recent_states[0]}")
            
            # Check if UI tree is actually changing
            recent_element_counts = [len(tree.elements) for tree in self.previous_ui_trees[-4:]]
            if len(set(recent_element_counts)) == 1 and recent_element_counts[0] <= 3:
                logger.error(f"‚ùå UI tree not changing - only {recent_element_counts[0]} elements")
                return True
        
        # Check for repeated actions
        if len(self.action_history) >= 3:
            recent_actions = [h["action"]["action_type"] for h in self.action_history[-3:]]
            if len(set(recent_actions)) == 1 and recent_actions[0] == "global_action":
                logger.warning(f"‚ö†Ô∏è Same global action repeated 3 times")
                return True
        
        return False
    
    def _get_wait_time_for_action(self, action_type: str) -> float:
        """Get appropriate wait time based on action type"""
        wait_times = {
            "click": 2.0,           # Clicks can open new screens
            "global_action": 2.0,   # HOME/BACK need time
            "type": 0.8,            # Typing is fast
            "scroll": 0.5,          # Scrolling is fast
            "wait": 0.1             # Already waited
        }
        return wait_times.get(action_type, 1.0)
    
    async def _think_and_decide(
        self,
        goal: str,
        observation: str,
        thought_history: List[str],
        step_number: int
    ) -> tuple[str, Optional[Dict]]:
        """
        Enhanced LLM prompt with better context awareness
        """
        
        # Build context
        history_context = ""
        if thought_history:
            history_context = "Previous thoughts:\n" + "\n".join(
                f"{i+1}. {t}" for i, t in enumerate(thought_history[-3:])
            )
        
        # Build device state context
        state_context = f"""CURRENT DEVICE STATE: {self.device_state}
STUCK COUNTER: {self.stuck_counter}/4
PREVIOUS ACTIONS: {[h["action"]["action_type"] for h in self.action_history[-3:]] if self.action_history else 'None'}
"""
        
        prompt = f"""You are a mobile automation agent analyzing an Android screen.

GOAL: {goal}

{state_context}

CURRENT SCREEN:
{observation}

{history_context}

CRITICAL ANALYSIS RULES:
1. **AURA APP DETECTION**: If you see "AURA" app or com.example.aura_project or "Send" button with text field ‚Üí YOU ARE IN AURA APP
   - MUST exit AURA app immediately using BACK
   - Do NOT type into AURA app text fields
   - Do NOT click Send in AURA app

2. **HOME SCREEN**: If you see multiple app icons (Gmail, Chrome, Maps, etc.) ‚Üí HOME SCREEN
   - Click the target app icon by its element_id
   - App icons have type "image" or "icon" and text with app name

3. **STUCK DETECTION**: If BACK action was tried 3+ times and still in same screen:
   - Use HOME action instead
   - Then navigate from home screen

4. **INCOMPLETE UI**: If you only see 1-2 elements and expecting more:
   - Request wait action to let UI fully load
   - Or use scroll to reveal more content

5. **APP IDENTIFICATION**: Apps are identified by:
   - Package name (com.google.android.gm = Gmail)
   - App name in observation
   - Screen elements (buttons, text fields specific to app)

AVAILABLE ACTIONS:
- click: Click an element by element_id (for buttons, icons, links)
- type: Type text into text field
- scroll: Scroll the screen (up/down/left/right)
- wait: Wait for UI to load (milliseconds)
- global_action: System actions (HOME, BACK, RECENTS)
- complete: Mark task as done

RESPONSE FORMAT (JSON ONLY):
{{
  "thought": "Brief analysis of what you see and next step",
  "action_type": "click|type|scroll|wait|global_action|complete",
  "element_id": 5,
  "text": "hello",
  "direction": "down",
  "duration": 1000,
  "global_action": "HOME",
  "reason": "Why goal is achieved"
}}

IMPORTANT:
- Always include thought field
- For click/type: MUST include valid element_id from the observation
- For global_action: choose from HOME, BACK, RECENTS
- If stuck in same screen after multiple BACK attempts, use HOME instead
- Respond with ONLY valid JSON, no markdown, no extra text
# In the THINK step prompt, add this:

CRITICAL RULES:
1. When opening something like "YouTube", AVOID elements with "Music", "YT Music", or "YouTube Music" unless specifically asked
2. After clicking, verify the app_name in the next screen
3. If wrong app opened, go BACK immediately and try a different element
4. Match app names EXACTLY - "YouTube" ‚â† "YouTube Music"

ANALYZE THE SCREEN AND RESPOND:"""
        
        try:
            response = await self.llm_client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a mobile automation expert. Respond ONLY with valid JSON. Never use markdown."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.2,
                max_tokens=500
            )
            
            response_text = response.choices[0].message.content.strip()
            logger.debug(f"ü§ñ Raw LLM response:\n{response_text}")
            
            # Extract JSON
            json_str = self._extract_json_from_response(response_text)
            
            if not json_str:
                logger.error(f"‚ùå No JSON found in LLM response")
                return ("Failed to parse response", None)
            
            action_json = json.loads(json_str)
            thought = action_json.get("thought", "No thought provided")
            
            return (thought, action_json)
        
        except Exception as e:
            logger.error(f"‚ùå LLM error: {e}", exc_info=True)
            return (f"Error: {e}", None)
    
    def _extract_json_from_response(self, text: str) -> Optional[str]:
        """Extract JSON from LLM response"""
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        
        match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', text, re.DOTALL)
        if match:
            return match.group(0).strip()
        
        return None
    
    def _json_to_ui_action(self, action_json: Dict) -> UIAction:
        """Convert JSON to UIAction with proper validation"""
        action_type = action_json.get("action_type")
        
        if not action_type:
            raise ValueError("Missing action_type")
        
        kwargs = {
            "action_type": action_type,
            "text": action_json.get("text"),
            "duration": action_json.get("duration", 1000),
        }
        
        # Handle element_id for click/type
        if action_type in ["click", "type"]:
            element_id = action_json.get("element_id")
            if element_id is not None:
                try:
                    kwargs["element_id"] = int(element_id)
                except (ValueError, TypeError):
                    logger.error(f"‚ùå Invalid element_id: {element_id}")
                    # Fallback to scroll
                    kwargs["action_type"] = "scroll"
                    kwargs["direction"] = "down"
                    return UIAction(**kwargs)
            else:
                logger.error(f"‚ùå No element_id for {action_type}")
                kwargs["action_type"] = "scroll"
                kwargs["direction"] = "down"
                return UIAction(**kwargs)
        
        # Handle optional fields
        direction = action_json.get("direction")
        if direction:
            kwargs["direction"] = direction
        
        global_action = action_json.get("global_action")
        if global_action:
            kwargs["global_action"] = global_action
        
        return UIAction(**kwargs)
    
    async def _fetch_ui_tree_from_device(self) -> Optional[SemanticUITree]:
        """Fetch UI tree from device with validation"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.backend_url}/device/{self.device_id}/ui-tree",
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Validate response
                    if not data:
                        logger.error(f"‚ùå Empty UI tree response")
                        return None
                    
                    # Check for synthetic screen marker
                    if data.get("_synthetic"):
                        logger.warning(f"‚ö†Ô∏è Received synthetic screen - ignoring")
                        return None
                    
                    return SemanticUITree(**data)
                else:
                    logger.error(f"‚ùå HTTP {response.status_code}")
                    return None
        
        except Exception as e:
            logger.error(f"‚ùå Error fetching UI tree: {e}")
            return None
    
    async def _execute_action_on_device(self, action: UIAction) -> ActionResult:
        """Execute action on device"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.backend_url}/device/{self.device_id}/execute-action",
                    json=action.model_dump(),
                    timeout=10.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    return ActionResult(**data)
                else:
                    return ActionResult(
                        action_id=action.action_id,
                        success=False,
                        error=f"HTTP {response.status_code}",
                        execution_time_ms=0
                    )
        
        except Exception as e:
            logger.error(f"‚ùå Error executing action: {e}")
            return ActionResult(
                action_id=action.action_id,
                success=False,
                error=str(e),
                execution_time_ms=0
            )
    
    def _build_result(
        self,
        task_id: str,
        status: str,
        steps: int,
        actions: List[UIAction],
        elapsed: float,
        error: Optional[str] = None,
        completion_reason: Optional[str] = None
    ) -> MobileTaskResult:
        """Build task result"""
        return MobileTaskResult(
            task_id=task_id,
            status=status,
            steps_taken=steps,
            actions_executed=actions,
            execution_time_ms=int(elapsed * 1000),
            error=error,
            completion_reason=completion_reason
        )
    
    def _build_error_result(self, task_id: str, error: str) -> MobileTaskResult:
        """Build error result"""
        return MobileTaskResult(
            task_id=task_id,
            status="failed",
            steps_taken=0,
            actions_executed=[],
            execution_time_ms=0,
            error=error
        )


# Backward compatibility
class MobileStrategy(MobileReActStrategy):
    pass


# Integration function
async def execute_mobile_task(
    task: Dict[str, Any],
    device_id: str = "emulator-5554"
) -> ExecutionResult:
    """Execute mobile task - called by ExecutionAgent"""
    
    try:
        mobile_task = MobileTaskRequest(
            task_id=task.get("task_id"),
            ai_prompt=task.get("ai_prompt"),
            device_id=device_id,
            session_id=task.get("session_id", "default"),
            context=task.get("extra_params", {}),
            extra_params=task.get("extra_params", {}),
            max_steps=15,
            timeout_seconds=task.get("timeout_seconds", 30)
        )
        
        strategy = MobileStrategy(device_id)
        result = await strategy.execute_task(mobile_task)
        
        return ExecutionResult(
            task_id=result.task_id,
            status="success" if result.status == "success" else "failed",
            content=result.completion_reason or result.error,
            error=result.error
        )
    
    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)
        return ExecutionResult(
            task_id=task.get("task_id", "unknown"),
            status="failed",
            error=str(e)
        )