{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a938594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ü§ñ TASK COORDINATION AGENT - GEMINI API\n",
      "======================================================================\n",
      "üì° Using: gemini-2.0-flash-exp\n",
      "üîë API Key: ‚úì Set\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ü§ñ TASK COORDINATION AGENT - READY!\n",
      "======================================================================\n",
      "Commands:\n",
      "  ‚Ä¢ Type your request naturally\n",
      "  ‚Ä¢ I'll ask questions if I need more details\n",
      "  ‚Ä¢ I'll auto-create the task when ready\n",
      "  ‚Ä¢ '/exit' - Quit\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù You said: \"can you please help me\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Of course! What do you need help with?\n",
      "\n",
      "üìù You said: \"my assignment\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: I can help coordinate that. Which assignment do you need help with? What is the file name and where is it located (e.g., Moodle, email, Google Drive)?\n",
      "\n",
      "üìù You said: \"math assignment, but first you should download it from moodle\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Okay, I can help with that. Could you please specify: 1. What is the exact name of the math assignment file on Moodle? 2. Which Moodle course is it located in? 3. Where on your computer should I save the downloaded file? (e.g., Desktop, Downloads folder, a specific folder)\n",
      "\n",
      "üìù You said: \"its found in probability and statisitcs course. named as assignment1.pdf, save it to my university folder found on my desktop\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Perfect! I have all the information. Creating the task now...\n",
      "\n",
      "‚úÖ Task information complete!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ TASK DECOMPOSITION\n",
      "======================================================================\n",
      "\n",
      "üìä Asking LLM to analyze conversation and create JSON...\n",
      "üìã Generated Task JSON:\n",
      "{\n",
      "  \"action\": \"Download math assignment from Moodle\",\n",
      "  \"context\": \"user/web\",\n",
      "  \"strategy\": \"browser/file\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"Download the math assignment file named 'assignment1.pdf' from the Probability and Statistics course on Moodle and save it to the 'university' folder located on the user's desktop.\",\n",
      "    \"file_path\": \"{{desktop_path}}/university/assignment1.pdf\",\n",
      "    \"content\": \"\",\n",
      "    \"file_type\": \"pdf\"\n",
      "  },\n",
      "  \"task_id\": \"\",\n",
      "  \"depends_on\": \"\",\n",
      "  \"priority\": \"\",\n",
      "  \"timeout\": null,\n",
      "  \"retry_count\": null\n",
      "}\n",
      "\n",
      "üíæ Saved to: tasks.jsonl\n",
      "======================================================================\n",
      "\n",
      "üîÑ Ready for next task!\n",
      "\n",
      "üìù You said: \"open file\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Sure, I can help coordinate that. Which file would you like me to open, and where is it located? (e.g., desktop, downloads folder, a specific directory)\n",
      "\n",
      "üìù You said: \"lab1.ipynb found in my downloads\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Perfect! I have all the information. Creating the task now...\n",
      "\n",
      "‚úÖ Task information complete!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ TASK DECOMPOSITION\n",
      "======================================================================\n",
      "\n",
      "üìä Asking LLM to analyze conversation and create JSON...\n",
      "üìã Generated Task JSON:\n",
      "{\n",
      "  \"action\": \"open file\",\n",
      "  \"context\": \"user\",\n",
      "  \"strategy\": \"file\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"Open the file named lab1.ipynb located in the user's downloads directory.\",\n",
      "    \"file_path\": \"{{downloads_path}}/lab1.ipynb\",\n",
      "    \"content\": \"\",\n",
      "    \"file_type\": \"ipynb\"\n",
      "  },\n",
      "  \"task_id\": \"\",\n",
      "  \"depends_on\": \"\",\n",
      "  \"priority\": \"\",\n",
      "  \"timeout\": null,\n",
      "  \"retry_count\": null\n",
      "}\n",
      "\n",
      "üíæ Saved to: tasks.jsonl\n",
      "======================================================================\n",
      "\n",
      "üîÑ Ready for next task!\n",
      "\n",
      "üìù You said: \"save file\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Okay, I can help coordinate saving a file. What is the name of the file you want to save, and where should I save it?\n",
      "\n",
      "üìù You said: \"save the currently open word document file\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Okay. What do you want to name the file, and where (which folder) should I save it?\n",
      "\n",
      "üìù You said: \"name is as test, save it as pdf. downloads\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Okay, I understand. You want to save the currently open Word document as a PDF file named \"test\" in the downloads folder. Is that correct?\n",
      "\n",
      "üìù You said: \"yes\"\n",
      "   ü§î Thinking... ‚úì\n",
      "ü§ñ Agent: Perfect! I have all the information. Creating the task now...\n",
      "\n",
      "‚úÖ Task information complete!\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéØ TASK DECOMPOSITION\n",
      "======================================================================\n",
      "\n",
      "üìä Asking LLM to analyze conversation and create JSON...\n",
      "üìã Generated Task JSON:\n",
      "{\n",
      "  \"action\": \"save_file\",\n",
      "  \"context\": \"system\",\n",
      "  \"strategy\": \"file\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"Save the currently open Word document as a PDF file named 'test' in the downloads folder.\",\n",
      "    \"file_path\": \"{{desktop_path}}/Downloads/test.pdf\",\n",
      "    \"content\": \"\",\n",
      "    \"file_type\": \"pdf\"\n",
      "  },\n",
      "  \"task_id\": \"\",\n",
      "  \"depends_on\": \"\",\n",
      "  \"priority\": \"\",\n",
      "  \"timeout\": null,\n",
      "  \"retry_count\": null\n",
      "}\n",
      "\n",
      "üíæ Saved to: tasks.jsonl\n",
      "======================================================================\n",
      "\n",
      "üîÑ Ready for next task!\n",
      "\n",
      "\n",
      "üí¨ Goodbye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "smart_agent_gemini.py - GEMINI API VERSION\n",
    "\n",
    "TASK COORDINATION AGENT ‚Äî Gemini-2.0-Flash-Exp\n",
    "- Full LLM-driven conversation (no hardcoded logic)\n",
    "- LLM detects vagueness and when enough info is gathered\n",
    "- LLM extracts all information and creates JSON\n",
    "\"\"\"\n",
    "\n",
    "import os, re, json, uuid, time, sys\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "\n",
    "\n",
    "##ADDED BY JANA BEGIN\n",
    "import asyncio\n",
    "import logging\n",
    "from utils.protocol import Channels\n",
    "from utils.broker import broker\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "##ADDED BY JANA END\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG - GEMINI API\n",
    "# -----------------------\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\", \"AIzaSyCAcgPGPayUebEzo8cH7vH06sWdunBGgz8\")  # Set: export GEMINI_API_KEY=your_key\n",
    "MODEL_NAME = \"gemini-2.0-flash-exp\"  # Smartest fast model\n",
    "API_URL = f\"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent\"\n",
    "\n",
    "CONV_SAVE_PATH = \"conversations.jsonl\"\n",
    "TASKS_SAVE_PATH = \"tasks.jsonl\"\n",
    "MAX_TOKENS = 150\n",
    "\n",
    "# -----------------------\n",
    "# Utility helpers\n",
    "# -----------------------\n",
    "def sanitize_text(t: str) -> str:\n",
    "    if not t: return \"\"\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = re.sub(r\"<\\|[^>]+\\|>\", \"\", t)\n",
    "    return t.strip()\n",
    "\n",
    "def append_jsonl(path: str, obj: dict):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# -----------------------\n",
    "# Gemini API Call\n",
    "# -----------------------\n",
    "def call_gemini_api(messages: List[Dict[str, str]], max_tokens=MAX_TOKENS) -> str:\n",
    "    \"\"\"Call Google Gemini API\"\"\"\n",
    "    \n",
    "    if not GEMINI_API_KEY:\n",
    "        raise ValueError(\"‚ö†Ô∏è  GEMINI_API_KEY not set! Run: export GEMINI_API_KEY=your_key\")\n",
    "    \n",
    "    # Convert messages to Gemini format\n",
    "    # Gemini uses: system instruction + contents (user/model pairs)\n",
    "    system_instruction = None\n",
    "    contents = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        if msg['role'] == 'system':\n",
    "            system_instruction = msg['content']\n",
    "        elif msg['role'] == 'user':\n",
    "            contents.append({\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": msg['content']}]\n",
    "            })\n",
    "        elif msg['role'] == 'assistant':\n",
    "            contents.append({\n",
    "                \"role\": \"model\",\n",
    "                \"parts\": [{\"text\": msg['content']}]\n",
    "            })\n",
    "    \n",
    "    # Build payload\n",
    "    payload = {\n",
    "        \"contents\": contents,\n",
    "        \"generationConfig\": {\n",
    "            \"maxOutputTokens\": max_tokens,\n",
    "            \"temperature\": 0.7,\n",
    "            \"topP\": 0.9,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add system instruction if present\n",
    "    if system_instruction:\n",
    "        payload[\"systemInstruction\"] = {\n",
    "            \"parts\": [{\"text\": system_instruction}]\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}?key={GEMINI_API_KEY}\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            json=payload,\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        # Extract text from Gemini response\n",
    "        if \"candidates\" in result and len(result[\"candidates\"]) > 0:\n",
    "            candidate = result[\"candidates\"][0]\n",
    "            if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n",
    "                text = candidate[\"content\"][\"parts\"][0].get(\"text\", \"\")\n",
    "                return sanitize_text(text)\n",
    "        \n",
    "        return \"\"\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ö†Ô∏è  API Error: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"    Response: {e.response.text}\")\n",
    "        return \"\"\n",
    "\n",
    "# -----------------------\n",
    "# System Prompts - LLM-DRIVEN\n",
    "# -----------------------\n",
    "SYSTEM_PROMPT = \"\"\"You are a TASK COORDINATION AGENT. Your role is to gather information from users and prepare task instructions for execution agents that will carry out the actual work.\n",
    "\n",
    "CRITICAL RULES:\n",
    "1. You do NOT execute tasks yourself - you coordinate them\n",
    "2. NEVER say \"I can't do X\" or \"I don't have the ability to X\"\n",
    "3. ALWAYS respond as if the task WILL be done by downstream agents\n",
    "4. DETECT VAGUENESS: If the user's request is unclear or missing critical details, ask specific clarifying questions\n",
    "5. Ask clarifying questions to gather ALL necessary details (what, where, when, how, which file, etc.)\n",
    "6. When you have COMPLETE information, respond with EXACTLY: \"TASK_COMPLETE\"\n",
    "7. Only say \"TASK_COMPLETE\" when you have ALL details needed to execute the task\n",
    "\n",
    "VAGUENESS DETECTION:\n",
    "- \"download my assignment\" ‚Üí VAGUE (which assignment? from where?)\n",
    "- \"help with homework\" ‚Üí VAGUE (what subject? what kind of help?)\n",
    "- \"open a website\" ‚Üí VAGUE (which website?)\n",
    "- \"download assignment1.pdf from Moodle MIU course to desktop/university\" ‚Üí CLEAR\n",
    "- \"search for AI news on Google\" ‚Üí CLEAR\n",
    "\n",
    "Your responses should be:\n",
    "- Helpful and confirming (\"Sure, I can help coordinate that\")\n",
    "- Question-focused when vague (ask for specific missing details)\n",
    "- Never refusing or explaining limitations\n",
    "- Natural and conversational\n",
    "\n",
    "Examples:\n",
    "\n",
    "User: hi\n",
    "You: Hello! How can I help you today?\n",
    "\n",
    "User: can you help me\n",
    "You: Of course! What do you need help with?\n",
    "\n",
    "User: Download my assignment\n",
    "You: I can help coordinate that download. Which assignment do you need, and where is it located (Moodle, Google Drive, email, etc.)?\n",
    "\n",
    "User: I need help with my math homework\n",
    "You: I can help with that. Where is the homework file, and what specific help do you need?\n",
    "\n",
    "User: It's on Moodle in the Calculus course\n",
    "You: Got it. What's the filename, and where would you like me to save it?\n",
    "\n",
    "User: assignment1.pdf, save it to desktop/university folder\n",
    "You: TASK_COMPLETE\n",
    "\n",
    "User: Open Chrome and search for AI news\n",
    "You: I can set that up. Should I search on a specific site like Google News, or just a general Google search?\n",
    "\n",
    "User: Just Google search is fine\n",
    "You: TASK_COMPLETE\n",
    "\n",
    "User: Download the PDF from my email and summarize it\n",
    "You: I can coordinate that. Which email contains the PDF (subject line or sender), and should I save it somewhere specific?\n",
    "\n",
    "Remember: You are gathering information FOR execution agents. Always be helpful, detect vagueness, ask clarifying questions, and never refuse tasks. Only say TASK_COMPLETE when you have everything needed.\"\"\"\n",
    "\n",
    "DECOMPOSITION_PROMPT = \"\"\"You are a task decomposition expert. Based on the conversation, create a detailed JSON task for the execution agent.\n",
    "\n",
    "CONVERSATION HISTORY:\n",
    "{conversation}\n",
    "\n",
    "Your job:\n",
    "1. Analyze the ENTIRE conversation\n",
    "2. Extract ALL information provided\n",
    "3. Create a JSON task in this EXACT format:\n",
    "\n",
    "{{\n",
    "    \"action\": \"describe_the_action\",\n",
    "    \"context\": \"system/user/web\",\n",
    "    \"strategy\": \"system/browser/file\", \n",
    "    \"params\": {{\n",
    "        \"action_type\": \"detailed description of what to do\",\n",
    "        \"file_path\": \"use {{{{desktop_path}}}}, {{{{timestamp}}}} placeholders if mentioned\",\n",
    "        \"content\": \"any content or placeholders like {{{{web_content}}}}\",\n",
    "        \"file_type\": \"file extension if applicable\"\n",
    "    }},\n",
    "    \"task_id\": \"\",\n",
    "    \"depends_on\": \"\",\n",
    "    \"priority\": \"\",\n",
    "    \"timeout\": null,\n",
    "    \"retry_count\": null\n",
    "}}\n",
    "\n",
    "IMPORTANT:\n",
    "- Leave empty fields as empty strings \"\"\n",
    "- Leave numeric fields as null if not specified\n",
    "- Use placeholders like {{{{desktop_path}}}}, {{{{timestamp}}}}, {{{{web_content}}}} where appropriate\n",
    "- The action can be ANYTHING the user described - don't limit to predefined actions\n",
    "- Extract ALL details from the conversation into action_type\n",
    "- Be comprehensive - include source, destination, file names, everything\n",
    "\n",
    "Respond with ONLY the JSON, nothing else.\"\"\"\n",
    "\n",
    "# -----------------------\n",
    "# Agent - FULL LLM DRIVEN\n",
    "# -----------------------\n",
    "class TaskCoordinationAgent:\n",
    "    def __init__(self):\n",
    "        print(\"=\"*70)\n",
    "        print(\"ü§ñ TASK COORDINATION AGENT - GEMINI API\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"üì° Using: {MODEL_NAME}\")\n",
    "        print(f\"üîë API Key: {'‚úì Set' if GEMINI_API_KEY else '‚úó Missing'}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        if not GEMINI_API_KEY:\n",
    "            print(\"‚ö†Ô∏è  WARNING: GEMINI_API_KEY not found!\")\n",
    "            print(\"   Set it with: export GEMINI_API_KEY=your_key\\n\")\n",
    "            print(\"   Get your key from: https://aistudio.google.com/app/apikey\\n\")\n",
    "        \n",
    "        self.memory = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "        self.save_path = CONV_SAVE_PATH\n",
    "        self.tasks_path = TASKS_SAVE_PATH\n",
    "\n",
    "    def save_memory(self):\n",
    "        \"\"\"Save conversation to JSONL\"\"\"\n",
    "        append_jsonl(self.save_path, {\n",
    "            \"id\": uuid.uuid4().hex,\n",
    "            \"timestamp\": int(time.time()),\n",
    "            \"memory\": self.memory\n",
    "        })\n",
    "\n",
    "    def check_completion(self, response: str) -> bool:\n",
    "        \"\"\"Check if LLM signals task is complete\"\"\"\n",
    "        return \"TASK_COMPLETE\" in response\n",
    "\n",
    "    async def decompose_task(self):\n",
    "        \"\"\"Let LLM extract information and create JSON\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üéØ TASK DECOMPOSITION\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        # Build conversation history for LLM\n",
    "        conversation = \"\\n\".join([\n",
    "            f\"{m['role'].upper()}: {m['content']}\" \n",
    "            for m in self.memory if m['role'] in ['user', 'assistant']\n",
    "        ])\n",
    "        \n",
    "        # Ask LLM to create the JSON\n",
    "        decomp_messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a task decomposition expert that creates JSON tasks.\"},\n",
    "            {\"role\": \"user\", \"content\": DECOMPOSITION_PROMPT.format(conversation=conversation)}\n",
    "        ]\n",
    "        \n",
    "        print(\"üìä Asking LLM to analyze conversation and create JSON...\")\n",
    "        response = call_gemini_api(decomp_messages, max_tokens=500)\n",
    "        \n",
    "        # Try to extract JSON from response\n",
    "        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                task = json.loads(json_match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"‚ö†Ô∏è  LLM response was not valid JSON, using fallback structure\\n\")\n",
    "                task = {\n",
    "                    \"action\": \"user_request\",\n",
    "                    \"context\": \"system\",\n",
    "                    \"strategy\": \"system\",\n",
    "                    \"params\": {\n",
    "                        \"action_type\": conversation[:300],\n",
    "                        \"file_path\": \"\",\n",
    "                        \"content\": \"\",\n",
    "                        \"file_type\": \"\"\n",
    "                    },\n",
    "                    \"task_id\": \"\",\n",
    "                    \"depends_on\": \"\",\n",
    "                    \"priority\": \"\",\n",
    "                    \"timeout\": None,\n",
    "                    \"retry_count\": None\n",
    "                }\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Could not find JSON in LLM response, using fallback\\n\")\n",
    "            task = {\n",
    "                \"action\": \"user_request\",\n",
    "                \"context\": \"system\",\n",
    "                \"strategy\": \"system\",\n",
    "                \"params\": {\n",
    "                    \"action_type\": conversation[:300],\n",
    "                    \"file_path\": \"\",\n",
    "                    \"content\": \"\",\n",
    "                    \"file_type\": \"\"\n",
    "                },\n",
    "                \"task_id\": \"\",\n",
    "                \"depends_on\": \"\",\n",
    "                \"priority\": \"\",\n",
    "                \"timeout\": None,\n",
    "                \"retry_count\": None\n",
    "            }\n",
    "\n",
    "        ##COMMENTED BY JANA BEGIN\n",
    "        \n",
    "        # # Save to file\n",
    "        # append_jsonl(self.tasks_path, {\n",
    "        #     \"timestamp\": int(time.time()),\n",
    "        #     \"task\": task\n",
    "        # })\n",
    "        \n",
    "        # print(\"üìã Generated Task JSON:\")\n",
    "        # print(json.dumps(task, indent=2))\n",
    "        # print(f\"\\nüíæ Saved to: {self.tasks_path}\")\n",
    "        # print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "        ##COMMENTED BY JANA END\n",
    "\n",
    "        ##ADDED BY JANA BEGIN\n",
    "        await broker.publish(Channels.LANGUAGE_TO_COORDINATOR, task)\n",
    "        ##ADDED BY JANA END \n",
    "\n",
    "        # return task\n",
    "\n",
    "    def user_turn(self, user_text: str) -> tuple:\n",
    "        \"\"\"Process user input, return (response, is_complete)\"\"\"\n",
    "        \n",
    "        user_text = sanitize_text(user_text)\n",
    "        \n",
    "        # Add user message to memory\n",
    "        self.memory.append({\"role\": \"user\", \"content\": user_text})\n",
    "        \n",
    "        # Keep only recent history (system + last 10 messages)\n",
    "        if len(self.memory) > 11:\n",
    "            self.memory = [self.memory[0]] + self.memory[-10:]\n",
    "        \n",
    "        # Generate response from LLM\n",
    "        print(\"   ü§î Thinking...\", end=\" \", flush=True)\n",
    "        response = call_gemini_api(self.memory, max_tokens=200)\n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        if not response:\n",
    "            response = \"I'm having trouble connecting. Please try again.\"\n",
    "            return response, False\n",
    "        \n",
    "        # Check if task is complete\n",
    "        is_complete = self.check_completion(response)\n",
    "        \n",
    "        # Clean up response for display (remove TASK_COMPLETE marker)\n",
    "        display_response = response.replace(\"TASK_COMPLETE\", \"\").strip()\n",
    "        if not display_response and is_complete:\n",
    "            display_response = \"Perfect! I have all the information. Creating the task now...\"\n",
    "        \n",
    "        # Add assistant response to memory\n",
    "        self.memory.append({\"role\": \"assistant\", \"content\": response})\n",
    "        \n",
    "        # Save memory\n",
    "        self.save_memory()\n",
    "        \n",
    "        return display_response, is_complete\n",
    "    \n",
    "##ADDED BY JANA BEGIN\n",
    "# -----------------------\n",
    "# Async Agent Starter for Broker\n",
    "# -----------------------\n",
    "    async def start_language_agent(broker):\n",
    "        agent = TaskCoordinationAgent()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ü§ñ TASK COORDINATION AGENT - READY!\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Waiting for user requests...\\n\")\n",
    "        \n",
    "        async def handle_user_input(message: dict):\n",
    "            user_input = message\n",
    "            \n",
    "            \n",
    "            # Echo user input BEFORE processing\n",
    "            print(f\"üìù User said: \\\"{user_input}\\\"\")\n",
    "            \n",
    "            # Process input with LLM\n",
    "            response, is_complete = agent.user_turn(user_input)\n",
    "            \n",
    "            # Display response\n",
    "            print(f\"ü§ñ Agent: {response}\\n\")\n",
    "            \n",
    "            # Auto-decompose if complete\n",
    "            if is_complete:\n",
    "                print(\"‚úÖ Task information complete!\\n\")\n",
    "                await agent.decompose_task()\n",
    "                \n",
    "                # Reset for next task\n",
    "                agent.memory = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "                print(\"üîÑ Ready for next task!\\n\")\n",
    "\n",
    "        await broker.subscribe(Channels.LANGUAGE_INPUT, handle_user_input)\n",
    "        logger.info(\"‚úÖ Language Agent started\")\n",
    "    \n",
    "        while True:\n",
    "            await asyncio.sleep(1)\n",
    "##ADDED BY JANA END\n",
    "\n",
    "##COMMENTED BY JANA BEGIN\n",
    "\n",
    "# # -----------------------\n",
    "# # CLI\n",
    "# # -----------------------\n",
    "# def main():\n",
    "#     agent = TaskCoordinationAgent()\n",
    "    \n",
    "#     print(\"=\"*70)\n",
    "#     print(\"ü§ñ TASK COORDINATION AGENT - READY!\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(\"Commands:\")\n",
    "#     print(\"  ‚Ä¢ Type your request naturally\")\n",
    "#     print(\"  ‚Ä¢ I'll ask questions if I need more details\")\n",
    "#     print(\"  ‚Ä¢ I'll auto-create the task when ready\")\n",
    "#     print(\"  ‚Ä¢ '/exit' - Quit\")\n",
    "#     print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "#     while True:\n",
    "#         try:\n",
    "#             user_input = input(\"üë§ You: \").strip()\n",
    "            \n",
    "#             if not user_input:\n",
    "#                 continue\n",
    "            \n",
    "#             if user_input.lower() in {\"/exit\", \"exit\", \"quit\"}:\n",
    "#                 print(\"\\nüí¨ Goodbye!\\n\")\n",
    "#                 break\n",
    "            \n",
    "#             # Echo user input BEFORE processing\n",
    "#             print(f\"üìù You said: \\\"{user_input}\\\"\")\n",
    "            \n",
    "#             # Process input with LLM\n",
    "#             response, is_complete = agent.user_turn(user_input)\n",
    "            \n",
    "#             # Display response\n",
    "#             print(f\"ü§ñ Agent: {response}\\n\")\n",
    "            \n",
    "#             # Auto-decompose if complete\n",
    "#             if is_complete:\n",
    "#                 print(\"‚úÖ Task information complete!\\n\")\n",
    "#                 agent.decompose_task()\n",
    "                \n",
    "#                 # Reset for next task\n",
    "#                 agent.memory = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "#                 print(\"üîÑ Ready for next task!\\n\")\n",
    "        \n",
    "#         except KeyboardInterrupt:\n",
    "#             print(\"\\n\\nüí¨ Goodbye!\\n\")\n",
    "#             break\n",
    "#         except Exception as ex:\n",
    "#             print(f\"\\n‚ö†Ô∏è  ERROR: {ex}\\n\", file=sys.stderr)\n",
    "#             import traceback\n",
    "#             traceback.print_exc()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "##COMMENTED BY JANA END"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
