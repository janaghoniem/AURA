{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5063808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de6ff3",
   "metadata": {},
   "source": [
    "## Dataset exploration and cleaning\n",
    "sharc dataset was used to train the classifer model (distilled bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed36f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting pre-processing ---\n",
      "Reading from: C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\n",
      "Writing to: C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\cleaned_data.jsonl\n",
      "Processing C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\sharc_train.json...\n",
      "Finished processing C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\sharc_train.json.\n",
      "Processing C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\sharc_dev.json...\n",
      "Finished processing C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\sharc_dev.json.\n",
      "\n",
      "âœ… file combination completed. Cleaned data saved to C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\cleaned_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"--- Starting pre-processing ---\")\n",
    "\n",
    "\n",
    "base_json_path = r\"C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\"\n",
    "\n",
    "\n",
    "train_path = os.path.join(base_json_path, \"sharc_train.json\")\n",
    "dev_path = os.path.join(base_json_path, \"sharc_dev.json\")\n",
    "output_path = os.path.join(base_json_path, \"cleaned_data.jsonl\") # New file\n",
    "\n",
    "print(f\"Reading from: {base_json_path}\")\n",
    "print(f\"Writing to: {output_path}\")\n",
    "\n",
    "\n",
    "def parse_example(ex):\n",
    "    \"\"\"Parses a single example dictionary.\"\"\"\n",
    "    user_utt = f\"{ex.get('scenario','')} {ex.get('question','')}\".strip()\n",
    "    history = ex.get('history')\n",
    "    clar_q = None\n",
    "    if history:\n",
    "        clar_q = history[0].get('follow_up_question')\n",
    "    \n",
    "    return {\n",
    "        \"user_utterance\": user_utt,\n",
    "        \"clarify_required\": bool(clar_q),\n",
    "        \"clarifying_question\": clar_q or \"\"\n",
    "    }\n",
    "\n",
    "\n",
    "with open(output_path, 'w') as outfile:\n",
    "    print(f\"Processing {train_path}...\")\n",
    "    with open(train_path) as f:\n",
    "        train_data = json.load(f)\n",
    "    \n",
    "    for ex in train_data:\n",
    "        cleaned_ex = parse_example(ex)\n",
    "        outfile.write(json.dumps(cleaned_ex) + '\\n') # Write as one line\n",
    "    \n",
    "    del train_data \n",
    "    gc.collect() \n",
    "    print(f\"Finished processing {train_path}.\")\n",
    "\n",
    "\n",
    "with open(output_path, 'a') as outfile:\n",
    "    print(f\"Processing {dev_path}...\")\n",
    "    with open(dev_path) as f:\n",
    "        dev_data = json.load(f)\n",
    "        \n",
    "    for ex in dev_data:\n",
    "        cleaned_ex = parse_example(ex)\n",
    "        outfile.write(json.dumps(cleaned_ex) + '\\n')\n",
    "    \n",
    "    del dev_data\n",
    "    gc.collect()\n",
    "    print(f\"Finished processing {dev_path}.\")\n",
    "\n",
    "print(f\"\\nâœ… file combination completed. Cleaned data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0391d0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned data from C:\\\\Users\\\\Shosh\\\\Desktop\\\\Univeristy\\\\Graduation project\\\\code\\\\sharc1-official\\\\sharc1-official\\\\json\\cleaned_data.jsonl...\n",
      "Data loaded successfully.\n",
      "\n",
      "--- First 5 Rows ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_utterance</th>\n",
       "      <th>clarify_required</th>\n",
       "      <th>clarifying_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a doctor. It does not involve a municipal...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Am I eligible for the Parenting Payment?</td>\n",
       "      <td>True</td>\n",
       "      <td>Is your income under the limits?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have an unconditional offer for a course wit...</td>\n",
       "      <td>True</td>\n",
       "      <td>Do you have an unconditional offer of a place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am a 32 year old man from the United States....</td>\n",
       "      <td>True</td>\n",
       "      <td>Are you selling seeds from ornamental plants w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I run a rather large business.  According to w...</td>\n",
       "      <td>True</td>\n",
       "      <td>Does the business meet SBA size standards?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have questions about Housing Benefit. My ext...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>It is a meal. Can I claim this expense?</td>\n",
       "      <td>True</td>\n",
       "      <td>Is it a travel expense to cover your fare if y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>My family is middle class, I'm 35 and I am par...</td>\n",
       "      <td>True</td>\n",
       "      <td>Are you a low-income family?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I've been waiting for my check.  I don't reall...</td>\n",
       "      <td>True</td>\n",
       "      <td>Is it 10,000 or less?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I don't have any state benefits. Can this bene...</td>\n",
       "      <td>True</td>\n",
       "      <td>Do you have income support?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      user_utterance  clarify_required  \\\n",
       "0  I am a doctor. It does not involve a municipal...             False   \n",
       "1           Am I eligible for the Parenting Payment?              True   \n",
       "2  I have an unconditional offer for a course wit...              True   \n",
       "3  I am a 32 year old man from the United States....              True   \n",
       "4  I run a rather large business.  According to w...              True   \n",
       "5  I have questions about Housing Benefit. My ext...             False   \n",
       "6            It is a meal. Can I claim this expense?              True   \n",
       "7  My family is middle class, I'm 35 and I am par...              True   \n",
       "8  I've been waiting for my check.  I don't reall...              True   \n",
       "9  I don't have any state benefits. Can this bene...              True   \n",
       "\n",
       "                                 clarifying_question  \n",
       "0                                                     \n",
       "1                   Is your income under the limits?  \n",
       "2  Do you have an unconditional offer of a place ...  \n",
       "3  Are you selling seeds from ornamental plants w...  \n",
       "4         Does the business meet SBA size standards?  \n",
       "5                                                     \n",
       "6  Is it a travel expense to cover your fare if y...  \n",
       "7                       Are you a low-income family?  \n",
       "8                              Is it 10,000 or less?  \n",
       "9                        Do you have income support?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_path = os.path.join(base_json_path, \"cleaned_data.jsonl\")\n",
    "\n",
    "print(f\"Loading cleaned data from {preprocessed_path}...\")\n",
    "df = pd.read_json(preprocessed_path, lines=True)\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- First 5 Rows ---\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810a49d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Column Info (Types & Non-Null Counts) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24160 entries, 0 to 24159\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   user_utterance       24160 non-null  object\n",
      " 1   clarify_required     24160 non-null  bool  \n",
      " 2   clarifying_question  24160 non-null  object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 401.2+ KB\n",
      "\n",
      "--- 2. Checking for 'Hidden' Missing Values (Empty Strings) ---\n",
      "Empty 'user_utterance' strings: 0\n",
      "Empty 'clarifying_question' strings: 7645\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Info & Missing Values\n",
    "\n",
    "print(\"--- 1. Column Info (Types & Non-Null Counts) ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- 2. Checking for 'Hidden' Missing Values (Empty Strings) ---\")\n",
    "# Your pre-processing script prevents 'None', but let's check for empty strings.\n",
    "empty_utterances = (df['user_utterance'] == \"\").sum()\n",
    "print(f\"Empty 'user_utterance' strings: {empty_utterances}\")\n",
    "\n",
    "# This should be equal to the number of 'False' cases, which is normal.\n",
    "empty_questions = (df['clarifying_question'] == \"\").sum()\n",
    "print(f\"Empty 'clarifying_question' strings: {empty_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cfeeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Counts for 'clarify_required' ---\n",
      "clarify_required\n",
      "True     16515\n",
      "False     7645\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Percentage for 'clarify_required' ---\n",
      "clarify_required\n",
      "True     68.356788\n",
      "False    31.643212\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Class Imbalance\n",
    "\n",
    "print(\"--- Raw Counts for 'clarify_required' ---\")\n",
    "print(df['clarify_required'].value_counts())\n",
    "\n",
    "print(\"\\n--- Percentage for 'clarify_required' ---\")\n",
    "class_percentages = df['clarify_required'].value_counts(normalize=True) * 100\n",
    "print(class_percentages)\n",
    "\n",
    "# Optional: Plot a quick bar chart\n",
    "class_percentages.plot(kind='bar',\n",
    "                       title='Class Imbalance (clarify_required)',\n",
    "                       color=['#4C72B0', '#C44E52'])\n",
    "plt.ylabel('Percentage')\n",
    "plt.xticks(ticks=[0, 1], labels=['False (Clear)', 'True (Vague)'], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe211df",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path = os.path.join(base_json_path, \"cleaned_data.jsonl\") \n",
    "\n",
    "# --- ðŸ’¡ NEW FOLDERS ---\n",
    "drive_checkpoint_path = \"./sharc_distilbert_checkpoints\" \n",
    "final_model_path = \"./sharc_distilbert_final\" \n",
    "print(f\"NEW Classifier will be saved to: {final_model_path}\")\n",
    "\n",
    "# --- 2. Loading Data ---\n",
    "all_ds = load_dataset('json', data_files=preprocessed_path, split='train')\n",
    "\n",
    "# --- 3. Preparing Classifier Dataset ---\n",
    "splits = all_ds.train_test_split(test_size=0.2, seed=42)\n",
    "clf_train_ds = splits['train'].map(\n",
    "    lambda x: {\"labels\": int(x[\"clarify_required\"])},\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "clf_valid_ds = splits['test'].map(\n",
    "    lambda x: {\"labels\": int(x[\"clarify_required\"])},\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "del all_ds, splits\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "model_name = \"distilbert-base-uncased\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"user_utterance\"], truncation=True, max_length=128)\n",
    "\n",
    "tokenized_train_ds = clf_train_ds.map(\n",
    "    tokenize_fn, batched=True, remove_columns=[\"user_utterance\", \"clarifying_question\", \"clarify_required\"]\n",
    ")\n",
    "tokenized_valid_ds = clf_valid_ds.map(\n",
    "    tokenize_fn, batched=True, remove_columns=[\"user_utterance\", \"clarifying_question\", \"clarify_required\"]\n",
    ")\n",
    "del clf_train_ds, clf_valid_ds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d19fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=drive_checkpoint_path,\n",
    "    num_train_epochs=5, \n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4, \n",
    "    no_cuda=True, \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2\n",
    ")\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_valid_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e90ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Start/Resume Training ---\n",
    "print(\"\\n--- Starting/Resuming Training (DistilBERT) ---\")\n",
    "trainer.train()\n",
    "\n",
    "# --- 8. Save the Final Model ---\n",
    "print(f\"\\n--- Training Complete. Saving final model to {final_model_path} ---\")\n",
    "trainer.save_model(final_model_path)\n",
    "print(\"âœ… *NEW* Classifier training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d08fc1",
   "metadata": {},
   "source": [
    "## Language Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd98628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classifier from: c:\\Users\\Shosh\\Desktop\\Univeristy\\Graduation project\\code\\sharc_distilbert_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classifier loaded.\n",
      "Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reasoner loaded.\n",
      "\n",
      "======================================================================\n",
      "ðŸ¤– SMART LANGUAGE AGENT - Ready!\n",
      "======================================================================\n",
      "I will ask one clear follow-up question at a time when needed â€” like a human.\n",
      "When all info is present I will show the LLM reasoning and the JSON plan (task_id left empty).\n",
      "Type 'quit' to exit, 'reset' to start over.\n",
      "\n",
      "\n",
      "ðŸ’¬ Agent: Example: \"What type of file do you want to save?\n",
      "\n",
      "ðŸ’¬ Agent: Thanks â€” I have what I need. Generating plan...\n",
      "\n",
      "\n",
      "ðŸ§© LLM Reasoning & Task Decomposition:\n",
      "[NEEDS INFO]\n",
      "\n",
      "1. Open the word document\n",
      "2. Go to File > Save As\n",
      "3. Choose PDF as the format\n",
      "4. Save the file in your desktop\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "1. Go to File > Save As\n",
      "2. Choose PDF as the format\n",
      "3. Save the file in your desktop\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "[NEEDS INFO]\n",
      "\n",
      "\n",
      "ðŸ“¦ Final JSON plan (task_id left blank):\n",
      "{\n",
      "  \"action\": \"save\",\n",
      "  \"context\": \"local\",\n",
      "  \"strategy\": \"local\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"save\",\n",
      "    \"app_name\": \"word\",\n",
      "    \"destination_hint\": \"desktop\",\n",
      "    \"original_text\": \"save this\"\n",
      "  },\n",
      "  \"task_id\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ“ Saved reasoning+plan to: output_logs/plan_1762109621_5c659b54.json\n",
      "\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ðŸ¤– SMART LANGUAGE AGENT (Context-Agnostic + Human-like Clarifications)\n",
    "# ==========================================================\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "# --- 1. Load Classifier ---\n",
    "classifier_path = \"./sharc_distilbert_final\"\n",
    "classifier_path_abs = os.path.abspath(classifier_path)\n",
    "print(f\"Loading classifier from: {classifier_path_abs}\")\n",
    "classifier = pipeline(\"text-classification\", model=classifier_path_abs)\n",
    "print(\"âœ… Classifier loaded.\")\n",
    "\n",
    "# --- 2. Load Reasoning Model ---\n",
    "reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "print(f\"Loading {reasoning_model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(reasoning_model_name)\n",
    "reasoner = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=reasoning_model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float32}\n",
    ")\n",
    "print(\"âœ… Reasoner loaded.\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3. Conversation History Manager\n",
    "# ==========================================================\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.messages = []  # full chat turns if you want to expand\n",
    "        self.original_task = None\n",
    "        self.clarifications = []  # list of dicts {question, answer}\n",
    "        self.entities_mentioned = {}\n",
    "        self.questions_asked = set()\n",
    "        self.last_question = None\n",
    "\n",
    "    def set_original_task(self, task):\n",
    "        self.original_task = task\n",
    "        self._extract_entities(task)\n",
    "\n",
    "    def add_clarification(self, question, answer):\n",
    "        self.clarifications.append({\"question\": question, \"answer\": answer})\n",
    "        self._extract_entities(answer)\n",
    "\n",
    "    def set_last_question(self, q):\n",
    "        self.last_question = q\n",
    "\n",
    "    def mark_question_asked(self, q_type):\n",
    "        self.questions_asked.add(q_type)\n",
    "\n",
    "    def get_full_context(self):\n",
    "        context = f\"Task: {self.original_task}\\n\"\n",
    "        if self.clarifications:\n",
    "            context += \"Clarifications:\\n\"\n",
    "            for i, c in enumerate(self.clarifications, 1):\n",
    "                context += f\"{i}. Q: {c['question']} A: {c['answer']}\\n\"\n",
    "        return context\n",
    "\n",
    "    def _extract_entities(self, text):\n",
    "        \"\"\"Extract general-purpose task entities (conservative).\"\"\"\n",
    "        t = (text or \"\").lower()\n",
    "\n",
    "        # ACTION - conservative mapping, default 'other'\n",
    "        if re.search(r\"\\b(save|store|download|save as|archive)\\b\", t):\n",
    "            self.entities_mentioned[\"action\"] = \"save\"\n",
    "        elif re.search(r\"\\b(open|launch|start)\\b\", t):\n",
    "            self.entities_mentioned[\"action\"] = \"open_app\"\n",
    "        elif re.search(r\"\\b(delete|remove)\\b\", t):\n",
    "            self.entities_mentioned[\"action\"] = \"delete\"\n",
    "        elif re.search(r\"\\b(calculate|compute|sum|evaluate|what is)\\b\", t):\n",
    "            self.entities_mentioned[\"action\"] = \"calculate\"\n",
    "        elif re.search(r\"\\b(search|find|lookup)\\b\", t):\n",
    "            self.entities_mentioned[\"action\"] = \"search\"\n",
    "        else:\n",
    "            # keep 'other' until clarified\n",
    "            self.entities_mentioned.setdefault(\"action\", \"other\")\n",
    "\n",
    "        # App / File Detection - conservative\n",
    "        app_match = re.search(r\"\\b(spotify|chrome|calculator|word|excel|notepad|zoom|vscode|vs code|photoshop|sublime|edge|firefox)\\b\", t)\n",
    "        if app_match:\n",
    "            self.entities_mentioned[\"app_name\"] = app_match.group()\n",
    "\n",
    "        # filename detection\n",
    "        file_match = re.search(r\"([\\w\\-\\s]+?\\.(?:pdf|docx?|xlsx?|pptx?|txt|csv))\", text or \"\", flags=re.IGNORECASE)\n",
    "        if file_match:\n",
    "            self.entities_mentioned[\"filename\"] = file_match.group(1).strip()\n",
    "\n",
    "        # detect if user mentions \"from website\" or \"from site\" or url\n",
    "        if re.search(r\"\\b(website|webpage|page|url|http://|https://)\\b\", t):\n",
    "            self.entities_mentioned[\"context\"] = \"web\"\n",
    "        elif re.search(r\"\\b(file|document|local|desktop|folder|drive|c:\\\\|/home/)\\b\", t):\n",
    "            self.entities_mentioned[\"context\"] = \"local\"\n",
    "        else:\n",
    "            # preserve existing context if set, otherwise general\n",
    "            self.entities_mentioned.setdefault(\"context\", \"general\")\n",
    "\n",
    "        # detect location/destination mention\n",
    "        if re.search(r\"\\b(desktop|downloads|documents|folder|google drive|dropbox|s3|database)\\b\", t):\n",
    "            self.entities_mentioned[\"destination_hint\"] = re.search(r\"\\b(desktop|downloads|documents|folder|google drive|dropbox|s3|database)\\b\", t).group()\n",
    "\n",
    "        # expression detection for calculations\n",
    "        expr_match = re.search(r\"([\\d\\.\\+\\-\\*/\\^\\(\\)\\s]+)$\", text or \"\")\n",
    "        if expr_match and len(expr_match.group(1).strip()) > 0:\n",
    "            self.entities_mentioned[\"expression\"] = expr_match.group(1).strip()\n",
    "\n",
    "    def get_missing_info(self):\n",
    "        \"\"\"Return list of missing info slots that matter for the detected action/context.\"\"\"\n",
    "        missing = []\n",
    "        action = self.entities_mentioned.get(\"action\", \"\")\n",
    "        ctx = self.entities_mentioned.get(\"context\", \"\")\n",
    "\n",
    "        # For save: we need WHAT and WHERE and SOURCE\n",
    "        if action == \"save\":\n",
    "            # What to save\n",
    "            if \"filename\" not in self.entities_mentioned and \"what_to_save\" not in self.questions_asked:\n",
    "                missing.append(\"what_to_save\")\n",
    "            # Source (web/local/app)\n",
    "            if ctx == \"general\" and \"source_type\" not in self.questions_asked:\n",
    "                # unknown source (web/local/app)\n",
    "                missing.append(\"source_type\")\n",
    "            # Where to save / destination\n",
    "            if \"destination_hint\" not in self.entities_mentioned and \"destination\" not in self.questions_asked:\n",
    "                missing.append(\"destination\")\n",
    "        # For open_app: need app_name\n",
    "        if action == \"open_app\":\n",
    "            if \"app_name\" not in self.entities_mentioned and \"app_name\" not in self.questions_asked:\n",
    "                missing.append(\"app_name\")\n",
    "        # For download/search: need target or query\n",
    "        if action == \"search\":\n",
    "            if \"search_term\" not in self.entities_mentioned and \"search_term\" not in self.questions_asked:\n",
    "                missing.append(\"search_term\")\n",
    "        # For calculate\n",
    "        if action == \"calculate\":\n",
    "            if \"expression\" not in self.entities_mentioned and \"expression\" not in self.questions_asked:\n",
    "                missing.append(\"expression\")\n",
    "\n",
    "        # If action unknown and hasn't been clarified\n",
    "        if action == \"other\" and \"clarify_action\" not in self.questions_asked:\n",
    "            missing.insert(0, \"clarify_action\")\n",
    "\n",
    "        return missing\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "# ==========================================================\n",
    "# 4. Clarifying Question Generator (LLM-driven, one question at a time)\n",
    "# ==========================================================\n",
    "def generate_clarifying_question_llm(history):\n",
    "    \"\"\"\n",
    "    Use the reasoner LLM to produce a single human-like clarifying question\n",
    "    tailored to the current missing info and context. Returns the question string.\n",
    "    \"\"\"\n",
    "\n",
    "    missing = history.get_missing_info()\n",
    "    # If nothing missing, return None\n",
    "    if not missing:\n",
    "        return None\n",
    "\n",
    "    # Prepare a succinct prompt describing only concrete facts and the missing slot(s).\n",
    "    facts = {\n",
    "        \"original_task\": history.original_task,\n",
    "        \"entities\": history.entities_mentioned,\n",
    "        \"clarifications_so_far\": history.clarifications,\n",
    "        \"missing_slots\": missing\n",
    "    }\n",
    "\n",
    "    # Build a short directed prompt asking the LLM to produce a single concise natural question.\n",
    "    # Instruction: produce one direct, human-like question suitable to ask the user next.\n",
    "    prompt = (\n",
    "        \"You are a helpful assistant that asks exactly one clear, polite follow-up question to \"\n",
    "        \"clarify a user's instruction so an automation agent can proceed. \"\n",
    "        \"Do NOT provide a list. Produce a single question only (one line), phrased naturally as if a human asked it.\\n\\n\"\n",
    "        f\"Facts:\\n{json.dumps(facts, indent=2)}\\n\\n\"\n",
    "        \"Produce ONE clarifying question (end with a question mark). Keep it short and specific. \"\n",
    "        \"Do not add any explanation or multiple questions.\"\n",
    "    )\n",
    "\n",
    "    # Call the reasoner deterministically (low temp, no sampling)\n",
    "    try:\n",
    "        resp = reasoner(prompt, max_new_tokens=64, do_sample=False, temperature=0.0, top_p=0.9)\n",
    "        raw = resp[0][\"generated_text\"]\n",
    "        # The model may echo the prompt; get the tail\n",
    "        tail = raw.split(prompt)[-1].strip()\n",
    "        # Extract the first line that ends with '?' or the first sentence.\n",
    "        # Search for first occurrence of '?' and take until that point.\n",
    "        qm_idx = tail.find('?')\n",
    "        if qm_idx != -1:\n",
    "            question = tail[:qm_idx+1].strip().replace('\\n', ' ')\n",
    "        else:\n",
    "            # fallback: first line\n",
    "            first_line = tail.splitlines()[0].strip() if tail.splitlines() else tail.strip()\n",
    "            question = first_line if first_line.endswith('?') else first_line + '?'\n",
    "        # sanitize: avoid overly long\n",
    "        if len(question) > 200:\n",
    "            question = question[:197].rsplit(' ', 1)[0] + '?'\n",
    "    except Exception:\n",
    "        question = None\n",
    "\n",
    "    # Last-resort fallback to a polite generic single question\n",
    "    if not question or len(question.strip()) == 0:\n",
    "        # Choose a slot-specific fallback if possible\n",
    "        slot = missing[0]\n",
    "        fallbacks = {\n",
    "            \"what_to_save\": \"What exactly would you like me to save?\",\n",
    "            \"source_type\": \"Is the content from a website or a local file?\",\n",
    "            \"destination\": \"Where should I save it (e.g., Desktop, Downloads, or a specific folder)?\",\n",
    "            \"clarify_action\": \"Could you tell me what you want me to do with this â€” save, open, delete, or something else?\",\n",
    "            \"app_name\": \"Which application should I open?\",\n",
    "            \"search_term\": \"What should I search for?\",\n",
    "            \"expression\": \"What's the expression you want me to calculate?\"\n",
    "        }\n",
    "        question = fallbacks.get(slot, \"Could you clarify what you mean?\")\n",
    "\n",
    "    # Mark that we've asked about that missing slot (to avoid repetition)\n",
    "    # Use the slot name to track which question we asked\n",
    "    history.mark_question_asked(missing[0])\n",
    "    history.set_last_question(question)\n",
    "    return question\n",
    "\n",
    "# ==========================================================\n",
    "# 5. Task Decomposition + JSON Output (LLM-assisted decomposition)\n",
    "# ==========================================================\n",
    "def decompose_task(history):\n",
    "    \"\"\"Generate clear, assumption-free reasoning and structured step-by-step plan.\"\"\"\n",
    "\n",
    "    full_context = history.get_full_context().strip()\n",
    "    action = history.entities_mentioned.get(\"action\", \"other\")\n",
    "    context = history.entities_mentioned.get(\"context\", \"general\")\n",
    "\n",
    "    # Build a strict reasoning prompt that forbids assumptions and extra conversions\n",
    "    system_prompt = (\n",
    "        \"You are a reasoning assistant for a SMART AUTOMATION AGENT.\\n\"\n",
    "        \"Your job: explain HOW to perform the userâ€™s requested action, step by step.\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"1. Use only the facts provided in context or clarifications. Do NOT assume anything unmentioned.\\n\"\n",
    "        \"2. Do NOT invent extra conversions, new files, apps, or redundant steps.\\n\"\n",
    "        \"3. The steps should describe HOW to do the task â€” for example, user interface actions like 'Open file', 'Go to File > Save As', etc.\\n\"\n",
    "        \"4. Keep it short (5â€“10 numbered steps max). No looping or repetition.\\n\"\n",
    "        \"5. Focus on the userâ€™s requested direction â€” not the opposite (e.g., if saving Word â†’ PDF, do NOT go PDF â†’ Word).\\n\"\n",
    "        \"6. If something is unclear or missing, skip it or mark it as [NEEDS INFO] instead of assuming.\\n\"\n",
    "        \"\\nOutput format:\\n\"\n",
    "        \"Reasoning (2â€“5 concise sentences)\\n\"\n",
    "        \"Numbered Steps (1 per line, max 10)\\n\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"{system_prompt}\\n\\nFacts:\\n{full_context}\\n\\nGenerate your reasoning and step list now.\"\n",
    "\n",
    "    # Generate deterministic reasoning\n",
    "    try:\n",
    "        resp = reasoner(\n",
    "            prompt,\n",
    "            max_new_tokens=350,\n",
    "            do_sample=False,\n",
    "            temperature=0.1,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        raw = resp[0][\"generated_text\"]\n",
    "        tail = raw.split(prompt)[-1].strip()\n",
    "        llm_output = tail\n",
    "    except Exception:\n",
    "        llm_output = (\n",
    "            \"Reasoning: Based on provided info, the agent will perform the save action without assumptions.\\n\\n\"\n",
    "            \"1. Identify the file or content to save.\\n\"\n",
    "            \"2. Open it in its respective application.\\n\"\n",
    "            \"3. Use 'File > Save As' and select the required format (e.g., PDF).\\n\"\n",
    "            \"4. Choose the destination folder (e.g., Desktop).\\n\"\n",
    "            \"5. Confirm and complete the save operation.\"\n",
    "        )\n",
    "\n",
    "    # ðŸ”§ Post-process hallucinated or repeated steps\n",
    "    lines = llm_output.splitlines()\n",
    "    unique_steps = []\n",
    "    seen = set()\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\d+\\.\", line.strip()):\n",
    "            normalized = re.sub(r\"\\s+\", \" \", line.strip().lower())\n",
    "            if normalized not in seen:\n",
    "                seen.add(normalized)\n",
    "                unique_steps.append(line)\n",
    "        else:\n",
    "            # keep reasoning part\n",
    "            unique_steps.append(line)\n",
    "    llm_output = \"\\n\".join(unique_steps)\n",
    "\n",
    "    print(\"\\nðŸ§© LLM Reasoning & Task Decomposition:\")\n",
    "    print(llm_output)\n",
    "    print()\n",
    "\n",
    "    # Detect strategy\n",
    "    if context in (\"local\", \"file\"):\n",
    "        strategy = \"local\"\n",
    "    elif context == \"web\":\n",
    "        strategy = \"web\"\n",
    "    else:\n",
    "        strategy = \"manual\"\n",
    "\n",
    "    # --- ðŸ†• Detect and include action_type ---\n",
    "    # Try to infer the intended task goal from the user input\n",
    "    original_text = history.original_task.lower()\n",
    "    if \"save\" in original_text and \"pdf\" in original_text:\n",
    "        action_type = \"save to pdf\"\n",
    "    elif \"convert\" in original_text:\n",
    "        action_type = \"convert file\"\n",
    "    elif \"open\" in original_text:\n",
    "        action_type = \"open file\"\n",
    "    elif \"delete\" in original_text:\n",
    "        action_type = \"delete file\"\n",
    "    elif \"rename\" in original_text:\n",
    "        action_type = \"rename file\"\n",
    "    else:\n",
    "        action_type = action  # fallback, e.g., \"other\"\n",
    "\n",
    "    # Build params\n",
    "    params = {\"action_type\": action_type}\n",
    "    for key in (\"app_name\", \"filename\", \"destination_hint\", \"expression\"):\n",
    "        if key in history.entities_mentioned:\n",
    "            params[key] = history.entities_mentioned[key]\n",
    "    params.setdefault(\"original_text\", history.original_task)\n",
    "\n",
    "    json_plan = {\n",
    "        \"action\": action,\n",
    "        \"context\": context,\n",
    "        \"strategy\": strategy,\n",
    "        \"params\": params,\n",
    "        \"task_id\": \"\"  # must stay blank\n",
    "    }\n",
    "\n",
    "    # Save output\n",
    "    os.makedirs(\"output_logs\", exist_ok=True)\n",
    "    fname = f\"output_logs/plan_{int(time.time())}_{str(uuid.uuid4())[:8]}.json\"\n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"llm_reasoning\": llm_output, \"llm_json_output\": json_plan}, f, indent=2)\n",
    "\n",
    "    print(\"ðŸ“¦ Final JSON plan (task_id left blank):\")\n",
    "    print(json.dumps(json_plan, indent=2))\n",
    "    print(f\"\\nðŸ“ Saved reasoning+plan to: {fname}\")\n",
    "\n",
    "    return llm_output, json_plan, fname\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 6. Interaction Loop (Human-like one-question-at-a-time)\n",
    "# ==========================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ¤– SMART LANGUAGE AGENT - Ready!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"I will ask one clear follow-up question at a time when needed â€” like a human.\\n\"\n",
    "      \"When all info is present I will show the LLM reasoning and the JSON plan (task_id left empty).\")\n",
    "print(\"Type 'quit' to exit, 'reset' to start over.\\n\")\n",
    "\n",
    "history = ConversationHistory()\n",
    "in_clarification = False\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if not in_clarification:\n",
    "            user_input = input(\"\\nðŸ‘¤ You: \").strip()\n",
    "            if user_input.lower() == \"quit\":\n",
    "                print(\"\\nðŸ‘‹ Goodbye!\")\n",
    "                break\n",
    "            if user_input.lower() == \"reset\":\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                print(\"âœ… Reset complete.\")\n",
    "                continue\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            # Set original task and extract entities\n",
    "            history.set_original_task(user_input)\n",
    "            classification = classifier(user_input)[0]  # you may use label if needed\n",
    "\n",
    "            # Decide whether we need clarification\n",
    "            missing = history.get_missing_info()\n",
    "            # Also treat ambiguous wording as missing even when slots are empty\n",
    "            # e.g., \"save this\" should lead to a question\n",
    "            # generate single human-like question using LLM\n",
    "            if missing:\n",
    "                question = generate_clarifying_question_llm(history)\n",
    "                # Print the single question (natural tone)\n",
    "                print(f\"\\nðŸ’¬ Agent: {question}\")\n",
    "                in_clarification = True\n",
    "                continue\n",
    "            else:\n",
    "                # No missing slots; still run a quick ambiguity check:\n",
    "                # if action is 'other' or context 'general' -> ask a targeted Q\n",
    "                action = history.entities_mentioned.get(\"action\", \"other\")\n",
    "                context = history.entities_mentioned.get(\"context\", \"general\")\n",
    "                ambiguous = (action == \"other\" or context == \"general\")\n",
    "                # Also check for vague pronouns\n",
    "                if re.search(r\"\\b(this|that|it|there|here|those|these)\\b\", user_input.lower()):\n",
    "                    ambiguous = True\n",
    "\n",
    "                if ambiguous:\n",
    "                    question = generate_clarifying_question_llm(history)\n",
    "                    print(f\"\\nðŸ’¬ Agent: {question}\")\n",
    "                    in_clarification = True\n",
    "                    continue\n",
    "\n",
    "                # Otherwise we have enough explicit info -> decompose & output\n",
    "                print(\"\\nðŸ’¬ Agent: I have enough information â€” generating plan...\\n\")\n",
    "                llm_reasoning, plan, path = decompose_task(history)\n",
    "                # after producing plan, reset for next turn\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # in clarification mode - user answered the last single question\n",
    "            answer = input(\"\\nðŸ‘¤ You: \").strip()\n",
    "            if answer.lower() == \"quit\":\n",
    "                print(\"\\nðŸ‘‹ Goodbye!\")\n",
    "                break\n",
    "            if answer.lower() == \"reset\":\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                print(\"âœ… Reset complete.\")\n",
    "                continue\n",
    "            if not answer:\n",
    "                continue\n",
    "\n",
    "            # record clarification and re-evaluate\n",
    "            history.add_clarification(history.last_question, answer)\n",
    "\n",
    "            # Recompute missing slots\n",
    "            missing = history.get_missing_info()\n",
    "            if missing:\n",
    "                # generate next single human-like question\n",
    "                question = generate_clarifying_question_llm(history)\n",
    "                print(f\"\\nðŸ’¬ Agent: {question}\")\n",
    "                in_clarification = True\n",
    "                continue\n",
    "            else:\n",
    "                # All required info collected -> decompose plan\n",
    "                print(\"\\nðŸ’¬ Agent: Thanks â€” I have what I need. Generating plan...\\n\")\n",
    "                llm_reasoning, plan, path = decompose_task(history)\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                continue\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nðŸ‘‹ Interrupted. Goodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ Unexpected error: {e}\")\n",
    "        # don't crash; reset and continue\n",
    "        history.reset()\n",
    "        in_clarification = False\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reasoner loaded.\n",
      "\n",
      "======================================================================\n",
      "ðŸ¤– SMART LANGUAGE AGENT\n",
      "======================================================================\n",
      "I'll help you complete tasks by asking clear questions when needed.\n",
      "Type 'quit' to exit, 'reset' to start over.\n",
      "\n",
      "\n",
      "[User input]: save this\n",
      "[LLM question generation failed: Repetitive text detected, using template]\n",
      "\n",
      "ðŸ’¬ Agent: What would you like me to save?\n",
      "\n",
      "\n",
      "[User response]: word document file\n",
      "[LLM question generation failed: Not a proper question, using template]\n",
      "\n",
      "ðŸ’¬ Agent: Where should I save it - Desktop, Downloads, or Documents?\n",
      "\n",
      "\n",
      "[User response]: desktop\n",
      "[LLM question generation failed: Repetitive text detected, using template]\n",
      "\n",
      "ðŸ’¬ Agent: What format should I save it as - PDF, Word document, text file, or something else?\n",
      "\n",
      "\n",
      "[User response]: pdf\n",
      "\n",
      "ðŸ’¬ Agent: Perfect! I have everything I need. Preparing your task...\n",
      "\n",
      "\n",
      "ðŸ§  Task Reasoning:\n",
      "The agent will save the file from local_file to desktop in THE SPECIFIED FORMAT format.\n",
      "\n",
      "ðŸ“‹ Generated JSON for Coordinator Agent:\n",
      "{\n",
      "  \"action\": \"save\",\n",
      "  \"context\": \"system\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"save_file\",\n",
      "    \"file_path\": \"{{desktop_path}}/document.pdf\",\n",
      "    \"format\": \"pdf\",\n",
      "    \"source\": \"file_system\",\n",
      "    \"file_type\": \"word\"\n",
      "  },\n",
      "  \"task_id\": \"\",\n",
      "  \"depends_on\": \"\",\n",
      "  \"priority\": \"\",\n",
      "  \"timeout\": \"\",\n",
      "  \"retry_count\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ’¾ Saved to: output_logs/task_1762126296_79bc1de2.json\n",
      "\n",
      "\n",
      "ðŸ‘‹ Thanks for using the agent. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ðŸ¤– SMART LANGUAGE AGENT - No Classifier (Anti-Hallucination)\n",
    "# ==========================================================\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "# --- Load Reasoning Model ---\n",
    "reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "print(f\"Loading {reasoning_model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(reasoning_model_name)\n",
    "reasoner = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=reasoning_model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float32}\n",
    ")\n",
    "print(\"âœ… Reasoner loaded.\")\n",
    "\n",
    "# ==========================================================\n",
    "# Few-Shot Examples for Question Generation\n",
    "# ==========================================================\n",
    "FEW_SHOT_EXAMPLES = \"\"\"Example 1:\n",
    "User: \"save this\"\n",
    "Missing: what_to_save, source_context, destination\n",
    "Question: \"What would you like me to save? Is it something currently open on your screen, a file on your computer, or content from a website?\"\n",
    "\n",
    "Example 2:\n",
    "User: \"open chrome\"\n",
    "Missing: (nothing)\n",
    "Question: (none needed)\n",
    "\n",
    "Example 3:\n",
    "User: \"save the document to desktop\"\n",
    "Missing: source_context, file_format\n",
    "Question: \"Is this document already open in an application, or should I look for it first? Also, what format should I save it as?\"\n",
    "\n",
    "Example 4:\n",
    "User: \"help with my math assignment\"\n",
    "Missing: where_to_find, specific_assignment\n",
    "Question: \"Where can I find this assignment - is it on Moodle, Canvas, or somewhere else? And which assignment is it?\"\n",
    "\n",
    "Example 5:\n",
    "User: \"send a message\"\n",
    "Missing: platform, recipient\n",
    "Question: \"Which platform should I use - Discord, WhatsApp, or something else? And who should I send it to?\"\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# Conversation History Manager (Rule-Based Entity Extraction)\n",
    "# ==========================================================\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.original_task = None\n",
    "        self.clarifications = []\n",
    "        self.entities_mentioned = {}\n",
    "        self.questions_asked = set()\n",
    "        self.last_question = None\n",
    "\n",
    "    def set_original_task(self, task):\n",
    "        self.original_task = task\n",
    "        self._extract_entities(task)\n",
    "\n",
    "    def add_clarification(self, question, answer):\n",
    "        self.clarifications.append({\"question\": question, \"answer\": answer})\n",
    "        self._extract_entities(answer)\n",
    "\n",
    "    def set_last_question(self, q):\n",
    "        self.last_question = q\n",
    "\n",
    "    def mark_question_asked(self, q_type):\n",
    "        self.questions_asked.add(q_type)\n",
    "\n",
    "    def get_full_context(self):\n",
    "        context = f\"Original request: {self.original_task}\\n\"\n",
    "        if self.clarifications:\n",
    "            context += \"Information gathered:\\n\"\n",
    "            for i, c in enumerate(self.clarifications, 1):\n",
    "                context += f\"  {i}. Q: {c['question']}\\n     A: {c['answer']}\\n\"\n",
    "        return context\n",
    "\n",
    "    def _extract_entities(self, text):\n",
    "        \"\"\"Extract task-relevant entities from text using reliable regex patterns.\"\"\"\n",
    "        if not text:\n",
    "            return\n",
    "            \n",
    "        t = text.lower()\n",
    "        original_text = text  # Keep original for case-sensitive matches\n",
    "\n",
    "        # ===== ACTION DETECTION =====\n",
    "        action_patterns = {\n",
    "            \"save\": r\"\\b(save|store|download|export|save as)\\b\",\n",
    "            \"open\": r\"\\b(open|launch|start|run)\\b(?!\\s+application)\",  # Avoid \"open application\" false positive\n",
    "            \"delete\": r\"\\b(delete|remove|erase|trash)\\b\",\n",
    "            \"send_message\": r\"\\b(send|message|text|dm|post)\\b\",\n",
    "            \"search\": r\"\\b(search|find|lookup|locate)\\b\",\n",
    "            \"solve\": r\"\\b(solve|help|help with|do|complete|work on)\\b.*\\b(assignment|homework|problem|exercise|quiz|test)\\b\",\n",
    "            \"convert\": r\"\\b(convert|transform|change|make into)\\b\",\n",
    "            \"calculate\": r\"\\b(calculate|compute)\\b.*[\\d\\+\\-\\*/]\",\n",
    "            \"browse\": r\"\\b(browse|surf|go to|visit)\\b\"\n",
    "        }\n",
    "        \n",
    "        for action, pattern in action_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"action\"] = action\n",
    "                break\n",
    "        \n",
    "        # ===== VAGUE REFERENCE DETECTION =====\n",
    "        # Critical: \"save this\", \"open that\", etc. need clarification\n",
    "        if re.search(r\"\\b(this|that|it|there|something)\\b\", t) and \"action\" in self.entities_mentioned:\n",
    "            if self.entities_mentioned[\"action\"] in [\"save\", \"open\", \"convert\", \"delete\"]:\n",
    "                self.entities_mentioned[\"has_vague_reference\"] = True\n",
    "        \n",
    "        # ===== SOURCE CONTEXT =====\n",
    "        if re.search(r\"\\b(currently open|open file|current|active window|on screen|on my screen)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"open_application\"\n",
    "        elif re.search(r\"\\b(website|webpage|web page|browser|online|url|http)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"web\"\n",
    "        elif re.search(r\"\\b(file|document|folder|directory|desktop|downloads|my pc|computer|entire pc)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"local_file\"\n",
    "        \n",
    "        # ===== APPLICATION DETECTION =====\n",
    "        app_patterns = {\n",
    "            \"word\": r\"\\b(word|winword|microsoft word|ms word)\\b\",\n",
    "            \"excel\": r\"\\b(excel|ms excel|microsoft excel)\\b\",\n",
    "            \"powerpoint\": r\"\\b(powerpoint|ppt|ms powerpoint)\\b\",\n",
    "            \"notepad\": r\"\\b(notepad)\\b\",\n",
    "            \"chrome\": r\"\\b(chrome|google chrome)\\b\",\n",
    "            \"firefox\": r\"\\b(firefox|mozilla)\\b\",\n",
    "            \"edge\": r\"\\b(edge|microsoft edge)\\b\",\n",
    "            \"calculator\": r\"\\b(calculator|calc)\\b\",\n",
    "            \"spotify\": r\"\\b(spotify)\\b\",\n",
    "            \"discord\": r\"\\b(discord)\\b\",\n",
    "            \"whatsapp\": r\"\\b(whatsapp)\\b\",\n",
    "            \"moodle\": r\"\\b(moodle)\\b\",\n",
    "            \"canvas\": r\"\\b(canvas)\\b\"\n",
    "        }\n",
    "        \n",
    "        for app, pattern in app_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"app_name\"] = app\n",
    "                break\n",
    "        \n",
    "        # Generic browser/internet (needs clarification which browser)\n",
    "        if re.search(r\"\\b(browser|internet)\\b\", t) and \"app_name\" not in self.entities_mentioned:\n",
    "            self.entities_mentioned[\"needs_browser\"] = True\n",
    "\n",
    "        # ===== FILENAME DETECTION =====\n",
    "        # Look for files with extensions\n",
    "        file_match = re.search(r\"([\\w\\-\\s]+?\\.(?:pdf|docx?|xlsx?|pptx?|txt|csv|png|jpg|jpeg|mp3|mp4|zip))\", original_text, flags=re.IGNORECASE)\n",
    "        if file_match:\n",
    "            self.entities_mentioned[\"filename\"] = file_match.group(1).strip()\n",
    "        \n",
    "        # Named file without extension (e.g., \"file called report\")\n",
    "        named_file = re.search(r\"\\b(?:file|document|assignment|report|project)\\s+(?:named|called)\\s+([\\w\\-\\s]+)\", t)\n",
    "        if named_file:\n",
    "            self.entities_mentioned[\"filename_base\"] = named_file.group(1).strip()\n",
    "\n",
    "        # ===== DESTINATION DETECTION =====\n",
    "        dest_patterns = {\n",
    "            \"desktop\": r\"\\b(desktop|on desktop|to desktop)\\b\",\n",
    "            \"downloads\": r\"\\b(downloads|download folder)\\b\",\n",
    "            \"documents\": r\"\\b(documents|my documents)\\b\"\n",
    "        }\n",
    "        for dest, pattern in dest_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"destination\"] = dest\n",
    "                break\n",
    "\n",
    "        # ===== FILE FORMAT DETECTION (TARGET - what to save AS) =====\n",
    "        # Be careful: distinguish between source and target format\n",
    "        format_patterns = {\n",
    "            \"pdf\": r\"\\b(as pdf|to pdf|save as pdf|pdf format|\\.pdf)\\b\",\n",
    "            \"docx\": r\"\\b(as docx|to word|as word document|\\.docx)\\b\",\n",
    "            \"txt\": r\"\\b(as txt|to text|as text file|\\.txt)\\b\",\n",
    "            \"xlsx\": r\"\\b(as xlsx|to excel|as spreadsheet|\\.xlsx)\\b\",\n",
    "            \"png\": r\"\\b(as png|to png|\\.png)\\b\",\n",
    "            \"jpg\": r\"\\b(as jpg|to jpg|as jpeg|\\.jpg)\\b\"\n",
    "        }\n",
    "        for fmt, pattern in format_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"target_format\"] = fmt\n",
    "                break\n",
    "\n",
    "        # ===== ACADEMIC/ASSIGNMENT DETECTION =====\n",
    "        if re.search(r\"\\b(assignment|homework|problem|exercise|quiz|test|exam|project)\\b\", t):\n",
    "            self.entities_mentioned[\"task_type\"] = \"assignment\"\n",
    "            \n",
    "            # Course subject\n",
    "            course_match = re.search(r\"\\b(math|mathematics|physics|chemistry|biology|english|history|computer science|cs|programming|calculus|algebra)\\b\", t, re.IGNORECASE)\n",
    "            if course_match:\n",
    "                self.entities_mentioned[\"subject\"] = course_match.group(1)\n",
    "            \n",
    "            # Platform (Moodle, Canvas, etc.)\n",
    "            platform_patterns = {\n",
    "                \"moodle\": r\"\\b(moodle)\\b\",\n",
    "                \"canvas\": r\"\\b(canvas)\\b\",\n",
    "                \"blackboard\": r\"\\b(blackboard)\\b\",\n",
    "                \"google_classroom\": r\"\\b(google classroom|classroom)\\b\"\n",
    "            }\n",
    "            for platform, pattern in platform_patterns.items():\n",
    "                if re.search(pattern, t):\n",
    "                    self.entities_mentioned[\"platform\"] = platform\n",
    "                    break\n",
    "\n",
    "        # ===== MESSAGING PLATFORM =====\n",
    "        if re.search(r\"\\b(discord)\\b\", t):\n",
    "            self.entities_mentioned[\"messaging_platform\"] = \"discord\"\n",
    "        elif re.search(r\"\\b(whatsapp)\\b\", t):\n",
    "            self.entities_mentioned[\"messaging_platform\"] = \"whatsapp\"\n",
    "        \n",
    "        # MESSAGE RECIPIENT\n",
    "        recipient_match = re.search(r\"\\b(?:to|message|dm)\\s+([\\w\\s]+?)(?:\\s+on|\\s+channel|$)\", t)\n",
    "        if recipient_match:\n",
    "            self.entities_mentioned[\"recipient\"] = recipient_match.group(1).strip()\n",
    "        \n",
    "        # MESSAGE CONTENT\n",
    "        msg_match = re.search(r\"(?:say|message|text|send)\\s+['\\\"](.+?)['\\\"]\", original_text, re.IGNORECASE)\n",
    "        if msg_match:\n",
    "            self.entities_mentioned[\"message_content\"] = msg_match.group(1).strip()\n",
    "\n",
    "        # ===== SEARCH QUERY =====\n",
    "        search_match = re.search(r\"(?:search for|find|lookup|locate)\\s+(.+?)(?:\\s+in|\\s+on|$)\", original_text, re.IGNORECASE)\n",
    "        if search_match:\n",
    "            self.entities_mentioned[\"search_query\"] = search_match.group(1).strip()\n",
    "\n",
    "        # ===== EXPRESSION FOR CALCULATION =====\n",
    "        expr_match = re.search(r\"([\\d\\.\\+\\-\\*/\\^\\(\\)\\s]+)$\", text or \"\")\n",
    "        if expr_match and len(expr_match.group(1).strip()) > 2:\n",
    "            self.entities_mentioned[\"expression\"] = expr_match.group(1).strip()\n",
    "\n",
    "    def get_missing_info(self):\n",
    "        \"\"\"Determine what critical information is still missing (RULE-BASED - NO LLM).\"\"\"\n",
    "        missing = []\n",
    "        action = self.entities_mentioned.get(\"action\")\n",
    "\n",
    "        # If action unclear, prioritize that\n",
    "        if not action:\n",
    "            if \"clarify_action\" not in self.questions_asked:\n",
    "                return [\"clarify_action\"]\n",
    "            return []\n",
    "\n",
    "        # ===== ACTION-SPECIFIC REQUIREMENTS =====\n",
    "        if action == \"save\":\n",
    "            # Need: WHAT, SOURCE, DESTINATION, FORMAT\n",
    "            # Check for vague reference first\n",
    "            if self.entities_mentioned.get(\"has_vague_reference\") and \"what_to_save\" not in self.questions_asked:\n",
    "                missing.append(\"what_to_save\")\n",
    "            elif \"filename\" not in self.entities_mentioned and \"filename_base\" not in self.entities_mentioned and \"what_to_save\" not in self.questions_asked:\n",
    "                missing.append(\"what_to_save\")\n",
    "            \n",
    "            if \"source_context\" not in self.entities_mentioned and \"source_context\" not in self.questions_asked:\n",
    "                missing.append(\"source_context\")\n",
    "            \n",
    "            if \"destination\" not in self.entities_mentioned and \"destination\" not in self.questions_asked:\n",
    "                missing.append(\"destination\")\n",
    "            \n",
    "            if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "                missing.append(\"target_format\")\n",
    "\n",
    "        elif action == \"convert\":\n",
    "            if \"filename\" not in self.entities_mentioned and \"source_file\" not in self.questions_asked:\n",
    "                missing.append(\"source_file\")\n",
    "            if \"source_context\" not in self.entities_mentioned and \"source_location\" not in self.questions_asked:\n",
    "                missing.append(\"source_location\")\n",
    "            if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "                missing.append(\"target_format\")\n",
    "\n",
    "        elif action == \"open\":\n",
    "            # Check if we have app name or filename\n",
    "            if \"app_name\" not in self.entities_mentioned and \"filename\" not in self.entities_mentioned:\n",
    "                if self.entities_mentioned.get(\"needs_browser\") and \"browser_choice\" not in self.questions_asked:\n",
    "                    missing.append(\"browser_choice\")\n",
    "                elif \"what_to_open\" not in self.questions_asked:\n",
    "                    missing.append(\"what_to_open\")\n",
    "\n",
    "        elif action == \"browse\":\n",
    "            if \"app_name\" not in self.entities_mentioned and \"browser_choice\" not in self.questions_asked:\n",
    "                missing.append(\"browser_choice\")\n",
    "            if \"search_query\" not in self.entities_mentioned and \"browse_target\" not in self.questions_asked:\n",
    "                missing.append(\"browse_target\")\n",
    "\n",
    "        elif action == \"send_message\":\n",
    "            if \"messaging_platform\" not in self.entities_mentioned and \"platform\" not in self.questions_asked:\n",
    "                missing.append(\"platform\")\n",
    "            if \"recipient\" not in self.entities_mentioned and \"recipient\" not in self.questions_asked:\n",
    "                missing.append(\"recipient\")\n",
    "            if \"message_content\" not in self.entities_mentioned and \"message_content\" not in self.questions_asked:\n",
    "                missing.append(\"message_content\")\n",
    "\n",
    "        elif action == \"search\":\n",
    "            if \"search_query\" not in self.entities_mentioned and \"filename\" not in self.entities_mentioned and \"search_query\" not in self.questions_asked:\n",
    "                missing.append(\"search_query\")\n",
    "\n",
    "        elif action == \"solve\":\n",
    "            if \"subject\" not in self.entities_mentioned and \"subject\" not in self.questions_asked:\n",
    "                missing.append(\"subject\")\n",
    "            if \"platform\" not in self.entities_mentioned and \"app_name\" not in self.entities_mentioned and \"platform_location\" not in self.questions_asked:\n",
    "                missing.append(\"platform_location\")\n",
    "            if \"task_type\" not in self.entities_mentioned and \"specific_assignment\" not in self.questions_asked:\n",
    "                missing.append(\"specific_assignment\")\n",
    "\n",
    "        elif action == \"calculate\":\n",
    "            if \"expression\" not in self.entities_mentioned and \"expression\" not in self.questions_asked:\n",
    "                missing.append(\"expression\")\n",
    "\n",
    "        return missing\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "# ==========================================================\n",
    "# Generate Clarifying Question (LLM with Strong Constraints)\n",
    "# ==========================================================\n",
    "def generate_clarifying_question_llm(history):\n",
    "    \"\"\"Generate ONE natural, human-like question. Uses LLM but with strict validation.\"\"\"\n",
    "    \n",
    "    missing = history.get_missing_info()\n",
    "    if not missing:\n",
    "        return None\n",
    "\n",
    "    missing_key = missing[0]  # Most important missing piece\n",
    "    action = history.entities_mentioned.get(\"action\", \"task\")\n",
    "    \n",
    "    # Build simple, focused prompt\n",
    "    prompt = f\"\"\"You are asking a user for missing information. Be brief and natural.\n",
    "\n",
    "{FEW_SHOT_EXAMPLES}\n",
    "\n",
    "User wants to: {action}\n",
    "You need to ask about: {missing_key}\n",
    "\n",
    "Generate ONE short question (under 30 words) that sounds natural and friendly.\n",
    "\n",
    "Question:\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = reasoner(\n",
    "            prompt,\n",
    "            max_new_tokens=50,  # Shorter to avoid rambling\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.5,  # Prevent repetition\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        raw = resp[0][\"generated_text\"]\n",
    "        \n",
    "        # Extract question\n",
    "        if \"Question:\" in raw:\n",
    "            question = raw.split(\"Question:\")[-1].strip()\n",
    "        else:\n",
    "            question = raw.split('\\n')[-1].strip()\n",
    "        \n",
    "        # Take only first sentence\n",
    "        question = question.split('\\n')[0].strip()\n",
    "        question = re.sub(r'\\s+', ' ', question)  # Clean whitespace\n",
    "        question = question.strip('\"\\'')  # Remove quotes\n",
    "        \n",
    "        # Validation\n",
    "        if not question.endswith('?'):\n",
    "            question += '?'\n",
    "        \n",
    "        # Length check (prevent hallucination)\n",
    "        if len(question) < 10 or len(question) > 200:\n",
    "            raise ValueError(\"Invalid question length\")\n",
    "        \n",
    "        # Must contain question words\n",
    "        question_words = ['what', 'where', 'which', 'who', 'how', 'should', 'would', 'is', 'are', 'do']\n",
    "        if not any(word in question.lower() for word in question_words):\n",
    "            raise ValueError(\"Not a proper question\")\n",
    "        \n",
    "        # Check for repetition (hallucination indicator)\n",
    "        words = question.lower().split()\n",
    "        if len(words) != len(set(words)) * 1.5:  # Too many repeated words\n",
    "            raise ValueError(\"Repetitive text detected\")\n",
    "        \n",
    "        history.mark_question_asked(missing_key)\n",
    "        history.set_last_question(question)\n",
    "        return question\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[LLM question generation failed: {e}, using template]\")\n",
    "        # FALLBACK TO TEMPLATES (guaranteed no hallucination)\n",
    "        return get_template_question(missing_key, history)\n",
    "\n",
    "def get_template_question(missing_key, history):\n",
    "    \"\"\"Fallback template questions - guaranteed safe.\"\"\"\n",
    "    templates = {\n",
    "        \"clarify_action\": \"What would you like me to help you with?\",\n",
    "        \"what_to_save\": \"What would you like me to save?\",\n",
    "        \"source_context\": \"Is this something currently open on your screen, a file on your computer, or content from a website?\",\n",
    "        \"destination\": \"Where should I save it - Desktop, Downloads, or Documents?\",\n",
    "        \"target_format\": \"What format should I save it as - PDF, Word document, text file, or something else?\",\n",
    "        \"what_to_open\": \"What would you like me to open?\",\n",
    "        \"browser_choice\": \"Which browser would you like - Chrome, Firefox, or Edge?\",\n",
    "        \"browse_target\": \"What would you like to browse or search for?\",\n",
    "        \"platform\": \"Which messaging app - Discord or WhatsApp?\",\n",
    "        \"recipient\": \"Who should I send the message to?\",\n",
    "        \"message_content\": \"What should the message say?\",\n",
    "        \"search_query\": \"What would you like me to search for?\",\n",
    "        \"source_file\": \"Which file should I convert?\",\n",
    "        \"source_location\": \"Is the file already open, or should I look for it somewhere specific?\",\n",
    "        \"subject\": \"What subject is this assignment for?\",\n",
    "        \"platform_location\": \"Where can I find this assignment - Moodle, Canvas, or somewhere else?\",\n",
    "        \"specific_assignment\": \"Which specific assignment are you working on?\",\n",
    "        \"expression\": \"What calculation do you need?\"\n",
    "    }\n",
    "    \n",
    "    question = templates.get(missing_key, \"Could you provide more details?\")\n",
    "    history.mark_question_asked(missing_key)\n",
    "    history.set_last_question(question)\n",
    "    return question\n",
    "\n",
    "# ==========================================================\n",
    "# Task Decomposition and JSON Generation\n",
    "# ==========================================================\n",
    "def decompose_and_generate_json(history):\n",
    "    \"\"\"Generate reasoning and JSON output for Coordinator Agent.\"\"\"\n",
    "    \n",
    "    entities = history.entities_mentioned\n",
    "    action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "    # Determine JSON context\n",
    "    source_context = entities.get(\"source_context\", \"local_file\")\n",
    "    if source_context == \"web\" or action == \"browse\":\n",
    "        json_context = \"web\"\n",
    "    elif action in [\"open\", \"send_message\", \"calculate\"]:\n",
    "        json_context = \"local\"\n",
    "    else:\n",
    "        json_context = \"system\"\n",
    "\n",
    "    # Generate reasoning (simple, rule-based to avoid hallucination)\n",
    "    reasoning = generate_rule_based_reasoning(entities, history.clarifications)\n",
    "\n",
    "    print(\"\\nðŸ§  Task Reasoning:\")\n",
    "    print(reasoning)\n",
    "    print()\n",
    "\n",
    "    # Build JSON structure (rule-based)\n",
    "    json_output = build_json_structure(entities, json_context)\n",
    "    \n",
    "    # Save to file\n",
    "    os.makedirs(\"output_logs\", exist_ok=True)\n",
    "    timestamp = int(time.time())\n",
    "    fname = f\"output_logs/task_{timestamp}_{str(uuid.uuid4())[:8]}.json\"\n",
    "    \n",
    "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"conversation\": history.get_full_context(),\n",
    "            \"reasoning\": reasoning,\n",
    "            \"task_json\": json_output\n",
    "        }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(\"ðŸ“‹ Generated JSON for Coordinator Agent:\")\n",
    "    print(json.dumps(json_output, indent=2))\n",
    "    print(f\"\\nðŸ’¾ Saved to: {fname}\\n\")\n",
    "\n",
    "    return reasoning, json_output, fname\n",
    "\n",
    "def generate_rule_based_reasoning(entities, clarifications):\n",
    "    \"\"\"Generate reasoning using RULES (no LLM - no hallucination).\"\"\"\n",
    "    action = entities.get(\"action\", \"task\")\n",
    "    \n",
    "    reasoning_map = {\n",
    "        \"save\": f\"The agent will save {entities.get('filename', 'the file')} from {entities.get('source_context', 'the source')} to {entities.get('destination', 'the destination')} in {entities.get('target_format', 'the specified format').upper()} format.\",\n",
    "        \n",
    "        \"open\": f\"The agent will open {entities.get('app_name') or entities.get('filename', 'the specified application')}.\",\n",
    "        \n",
    "        \"solve\": f\"The agent will access the {entities.get('subject', 'assignment')} from {entities.get('platform', 'the platform')} and provide assistance with solving it.\",\n",
    "        \n",
    "        \"send_message\": f\"The agent will send a message via {entities.get('messaging_platform', 'the messaging app')} to {entities.get('recipient', 'the recipient')}.\",\n",
    "        \n",
    "        \"search\": f\"The agent will search for {entities.get('search_query') or entities.get('filename', 'the specified item')}.\",\n",
    "        \n",
    "        \"browse\": f\"The agent will open {entities.get('app_name', 'the browser')} and navigate to {entities.get('search_query', 'the specified location')}.\",\n",
    "        \n",
    "        \"convert\": f\"The agent will convert {entities.get('filename', 'the file')} to {entities.get('target_format', 'the target format').upper()} format.\",\n",
    "        \n",
    "        \"calculate\": f\"The agent will calculate {entities.get('expression', 'the expression')}.\"\n",
    "    }\n",
    "    \n",
    "    return reasoning_map.get(action, f\"The agent will perform the {action} operation based on the provided information.\")\n",
    "\n",
    "def build_json_structure(entities, json_context):\n",
    "    \"\"\"Build JSON structure using RULES (no LLM - no hallucination).\"\"\"\n",
    "    \n",
    "    action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "    # Map action to action_type\n",
    "    action_type_map = {\n",
    "        \"save\": \"save_as_pdf\" if entities.get(\"target_format\") == \"pdf\" else \"save_file\",\n",
    "        \"open\": \"open_app\",\n",
    "        \"send_message\": \"send_message\",\n",
    "        \"search\": \"search\",\n",
    "        \"convert\": \"convert_file\",\n",
    "        \"calculate\": \"calculate\",\n",
    "        \"delete\": \"delete_file\",\n",
    "        \"solve\": \"solve_assignment\",\n",
    "        \"browse\": \"browse_web\"\n",
    "    }\n",
    "    action_type = action_type_map.get(action, action)\n",
    "\n",
    "    # Build params based on action\n",
    "    params = {\"action_type\": action_type}\n",
    "    \n",
    "    if action == \"save\":\n",
    "        filename = entities.get(\"filename\") or entities.get(\"filename_base\", \"document\")\n",
    "        target_format = entities.get(\"target_format\", \"pdf\")\n",
    "        \n",
    "        # Ensure correct extension\n",
    "        if not filename.endswith(f\".{target_format}\"):\n",
    "            if '.' in filename:\n",
    "                filename = filename.rsplit('.', 1)[0]\n",
    "            filename = f\"{filename}.{target_format}\"\n",
    "        \n",
    "        dest = entities.get(\"destination\", \"desktop\")\n",
    "        params[\"file_path\"] = f\"{{{{{dest}_path}}}}/{filename}\"\n",
    "        params[\"format\"] = target_format\n",
    "        \n",
    "        if entities.get(\"source_context\") == \"open_application\":\n",
    "            params[\"source\"] = \"current_application\"\n",
    "            params[\"file_type\"] = entities.get(\"app_name\", \"unknown\")\n",
    "        else:\n",
    "            params[\"source\"] = \"file_system\"\n",
    "            params[\"file_type\"] = entities.get(\"app_name\", \"word\")\n",
    "    \n",
    "    elif action == \"solve\":\n",
    "        params[\"task_type\"] = entities.get(\"task_type\", \"assignment\")\n",
    "        params[\"subject\"] = entities.get(\"subject\", \"\")\n",
    "        params[\"platform\"] = entities.get(\"platform\", \"\")\n",
    "    \n",
    "    elif action == \"open\":\n",
    "        if entities.get(\"app_name\"):\n",
    "            params[\"app_name\"] = entities[\"app_name\"]\n",
    "        if entities.get(\"filename\"):\n",
    "            params[\"file_path\"] = entities[\"filename\"]\n",
    "    \n",
    "    elif action == \"browse\":\n",
    "        params[\"browser\"] = entities.get(\"app_name\", \"chrome\")\n",
    "        if entities.get(\"search_query\"):\n",
    "            params[\"search_query\"] = entities[\"search_query\"]\n",
    "    \n",
    "    elif action == \"send_message\":\n",
    "        params[\"platform\"] = entities.get(\"messaging_platform\", \"\")\n",
    "        params[\"recipient\"] = entities.get(\"recipient\", \"\")\n",
    "        params[\"message\"] = entities.get(\"message_content\", \"\")\n",
    "    \n",
    "    elif action == \"search\":\n",
    "        params[\"query\"] = entities.get(\"search_query\", entities.get(\"filename\", \"\"))\n",
    "    \n",
    "    elif action == \"calculate\":\n",
    "        params[\"expression\"] = entities.get(\"expression\", \"\")\n",
    "    \n",
    "    elif action == \"convert\":\n",
    "        params[\"source_file\"] = entities.get(\"filename\", \"\")\n",
    "        params[\"target_format\"] = entities.get(\"target_format\", \"\")\n",
    "\n",
    "    # Build final JSON\n",
    "    json_output = {\n",
    "        \"action\": action,\n",
    "        \"context\": json_context,\n",
    "        \"params\": params,\n",
    "        \"task_id\": \"\",\n",
    "        \"depends_on\": \"\",\n",
    "        \"priority\": \"\",\n",
    "        \"timeout\": \"\",\n",
    "        \"retry_count\": \"\"\n",
    "    }\n",
    "\n",
    "    return json_output\n",
    "\n",
    "# ==========================================================\n",
    "# Main Interaction Loop\n",
    "# ==========================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ¤– SMART LANGUAGE AGENT\")\n",
    "print(\"=\" * 70)\n",
    "print(\"I'll help you complete tasks by asking clear questions when needed.\")\n",
    "print(\"Type 'quit' to exit, 'reset' to start over.\\n\")\n",
    "\n",
    "history = ConversationHistory()\n",
    "in_clarification = False\n",
    "max_turns = 10  # Prevent infinite loops\n",
    "turn_count = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if not in_clarification:\n",
    "            user_input = input(\"ðŸ‘¤ You: \").strip()\n",
    "            \n",
    "            if user_input.lower() == \"quit\":\n",
    "                print(\"\\nðŸ‘‹ Thanks for using the agent. Goodbye!\")\n",
    "                break\n",
    "            if user_input.lower() == \"reset\":\n",
    "                history.reset()\n",
    "                turn_count = 0\n",
    "                print(\"âœ… Conversation reset. Let's start fresh!\\n\")\n",
    "                continue\n",
    "            if not user_input:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n[User input]: {user_input}\")\n",
    "            \n",
    "            # Extract entities (rule-based)\n",
    "            history.set_original_task(user_input)\n",
    "            turn_count += 1\n",
    "            \n",
    "            # Safety check\n",
    "            if turn_count > max_turns:\n",
    "                print(\"\\nðŸ’¬ Agent: I think I need a bit more context. Could you rephrase what you'd like me to do?\\n\")\n",
    "                history.reset()\n",
    "                turn_count = 0\n",
    "                in_clarification = False\n",
    "                continue\n",
    "            \n",
    "            # Check if clarification needed\n",
    "            missing = history.get_missing_info()\n",
    "            \n",
    "            if missing:\n",
    "                question = generate_clarifying_question_llm(history)\n",
    "                print(f\"\\nðŸ’¬ Agent: {question}\\n\")\n",
    "                in_clarification = True\n",
    "            else:\n",
    "                # Enough info - generate plan\n",
    "                print(f\"\\nðŸ’¬ Agent: Got it! Let me prepare that for you...\\n\")\n",
    "                reasoning, json_plan, path = decompose_and_generate_json(history)\n",
    "                history.reset()\n",
    "                turn_count = 0\n",
    "\n",
    "        else:\n",
    "            # In clarification mode\n",
    "            answer = input(\"ðŸ‘¤ You: \").strip()\n",
    "            \n",
    "            if answer.lower() == \"quit\":\n",
    "                print(\"\\nðŸ‘‹ Thanks for using the agent. Goodbye!\")\n",
    "                break\n",
    "            if answer.lower() == \"reset\":\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                turn_count = 0\n",
    "                print(\"âœ… Conversation reset. Let's start fresh!\\n\")\n",
    "                continue\n",
    "            if not answer:\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n[User response]: {answer}\")\n",
    "            \n",
    "            # Record the clarification\n",
    "            history.add_clarification(history.last_question, answer)\n",
    "            turn_count += 1\n",
    "            \n",
    "            # Safety check\n",
    "            if turn_count > max_turns:\n",
    "                print(\"\\nðŸ’¬ Agent: I think I need a bit more context. Could you rephrase what you'd like me to do?\\n\")\n",
    "                history.reset()\n",
    "                turn_count = 0\n",
    "                in_clarification = False\n",
    "                continue\n",
    "            \n",
    "            # Check if more info needed\n",
    "            missing = history.get_missing_info()\n",
    "            \n",
    "            if missing:\n",
    "                question = generate_clarifying_question_llm(history)\n",
    "                print(f\"\\nðŸ’¬ Agent: {question}\\n\")\n",
    "            else:\n",
    "                # All info collected\n",
    "                print(f\"\\nðŸ’¬ Agent: Perfect! I have everything I need. Preparing your task...\\n\")\n",
    "                reasoning, json_plan, path = decompose_and_generate_json(history)\n",
    "                history.reset()\n",
    "                in_clarification = False\n",
    "                turn_count = 0\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nðŸ‘‹ Interrupted. Goodbye!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ Error: {e}\")\n",
    "        print(\"Let's try again. Please rephrase your request.\\n\")\n",
    "        history.reset()\n",
    "        in_clarification = False\n",
    "        turn_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JANA TEST\n",
    "\n",
    "# ==========================================================\n",
    "# ðŸ¤– SMART LANGUAGE AGENT - No Classifier (Anti-Hallucination)\n",
    "# ==========================================================\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# --- Load Reasoning Model ---\n",
    "reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "print(f\"Loading {reasoning_model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(reasoning_model_name)\n",
    "reasoner = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=reasoning_model_name,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float32}\n",
    ")\n",
    "print(\"âœ… Reasoner loaded.\")\n",
    "\n",
    "# ==========================================================\n",
    "# Few-Shot Examples for Question Generation\n",
    "# ==========================================================\n",
    "FEW_SHOT_EXAMPLES = \"\"\"Example 1:\n",
    "User: \"save this\"\n",
    "Missing: what_to_save, source_context, destination\n",
    "Question: \"What would you like me to save? Is it something currently open on your screen, a file on your computer, or content from a website?\"\n",
    "\n",
    "Example 2:\n",
    "User: \"open chrome\"\n",
    "Missing: (nothing)\n",
    "Question: (none needed)\n",
    "\n",
    "Example 3:\n",
    "User: \"save the document to desktop\"\n",
    "Missing: source_context, file_format\n",
    "Question: \"Is this document already open in an application, or should I look for it first? Also, what format should I save it as?\"\n",
    "\n",
    "Example 4:\n",
    "User: \"help with my math assignment\"\n",
    "Missing: where_to_find, specific_assignment\n",
    "Question: \"Where can I find this assignment - is it on Moodle, Canvas, or somewhere else? And which assignment is it?\"\n",
    "\n",
    "Example 5:\n",
    "User: \"send a message\"\n",
    "Missing: platform, recipient\n",
    "Question: \"Which platform should I use - Discord, WhatsApp, or something else? And who should I send it to?\"\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# Conversation History Manager (Rule-Based Entity Extraction)\n",
    "# ==========================================================\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "        self.original_task = None\n",
    "        self.clarifications = []\n",
    "        self.entities_mentioned = {}\n",
    "        self.questions_asked = set()\n",
    "        self.last_question = None\n",
    "\n",
    "    def set_original_task(self, task):\n",
    "        self.original_task = task\n",
    "        self._extract_entities(task)\n",
    "\n",
    "    def add_clarification(self, question, answer):\n",
    "        self.clarifications.append({\"question\": question, \"answer\": answer})\n",
    "        self._extract_entities(answer)\n",
    "\n",
    "    def set_last_question(self, q):\n",
    "        self.last_question = q\n",
    "\n",
    "    def mark_question_asked(self, q_type):\n",
    "        self.questions_asked.add(q_type)\n",
    "\n",
    "    def get_full_context(self):\n",
    "        context = f\"Original request: {self.original_task}\\n\"\n",
    "        if self.clarifications:\n",
    "            context += \"Information gathered:\\n\"\n",
    "            for i, c in enumerate(self.clarifications, 1):\n",
    "                context += f\"  {i}. Q: {c['question']}\\n    A: {c['answer']}\\n\"\n",
    "        return context\n",
    "\n",
    "    def _extract_entities(self, text):\n",
    "        \"\"\"Extract task-relevant entities from text using reliable regex patterns.\"\"\"\n",
    "        if not text:\n",
    "            return\n",
    "            \n",
    "        t = text.lower()\n",
    "        original_text = text  # Keep original for case-sensitive matches\n",
    "\n",
    "        # ===== ACTION DETECTION =====\n",
    "        action_patterns = {\n",
    "            \"save\": r\"\\b(save|store|download|export|save as)\\b\",\n",
    "            \"open\": r\"\\b(open|launch|start|run)\\b(?!\\s+application)\",  # Avoid \"open application\" false positive\n",
    "            \"delete\": r\"\\b(delete|remove|erase|trash)\\b\",\n",
    "            \"send_message\": r\"\\b(send|message|text|dm|post)\\b\",\n",
    "            \"search\": r\"\\b(search|find|lookup|locate)\\b\",\n",
    "            \"solve\": r\"\\b(solve|help|help with|do|complete|work on)\\b.*\\b(assignment|homework|problem|exercise|quiz|test)\\b\",\n",
    "            \"convert\": r\"\\b(convert|transform|change|make into)\\b\",\n",
    "            \"calculate\": r\"\\b(calculate|compute)\\b.*[\\d\\+\\-\\*/]\",\n",
    "            \"browse\": r\"\\b(browse|surf|go to|visit)\\b\"\n",
    "        }\n",
    "        \n",
    "        for action, pattern in action_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"action\"] = action\n",
    "                break\n",
    "        \n",
    "        # ===== VAGUE REFERENCE DETECTION =====\n",
    "        # Critical: \"save this\", \"open that\", etc. need clarification\n",
    "        if re.search(r\"\\b(this|that|it|there|something)\\b\", t) and \"action\" in self.entities_mentioned:\n",
    "            if self.entities_mentioned[\"action\"] in [\"save\", \"open\", \"convert\", \"delete\"]:\n",
    "                self.entities_mentioned[\"has_vague_reference\"] = True\n",
    "        \n",
    "        # ===== SOURCE CONTEXT =====\n",
    "        if re.search(r\"\\b(currently open|open file|current|active window|on screen|on my screen)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"open_application\"\n",
    "        elif re.search(r\"\\b(website|webpage|web page|browser|online|url|http)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"web\"\n",
    "        elif re.search(r\"\\b(file|document|folder|directory|desktop|downloads|my pc|computer|entire pc)\\b\", t):\n",
    "            self.entities_mentioned[\"source_context\"] = \"local_file\"\n",
    "        \n",
    "        # ===== APPLICATION DETECTION =====\n",
    "        app_patterns = {\n",
    "            \"word\": r\"\\b(word|winword|microsoft word|ms word)\\b\",\n",
    "            \"excel\": r\"\\b(excel|ms excel|microsoft excel)\\b\",\n",
    "            \"powerpoint\": r\"\\b(powerpoint|ppt|ms powerpoint)\\b\",\n",
    "            \"notepad\": r\"\\b(notepad)\\b\",\n",
    "            \"chrome\": r\"\\b(chrome|google chrome)\\b\",\n",
    "            \"firefox\": r\"\\b(firefox|mozilla)\\b\",\n",
    "            \"edge\": r\"\\b(edge|microsoft edge)\\b\",\n",
    "            \"calculator\": r\"\\b(calculator|calc)\\b\",\n",
    "            \"spotify\": r\"\\b(spotify)\\b\",\n",
    "            \"discord\": r\"\\b(discord)\\b\",\n",
    "            \"whatsapp\": r\"\\b(whatsapp)\\b\",\n",
    "            \"moodle\": r\"\\b(moodle)\\b\",\n",
    "            \"canvas\": r\"\\b(canvas)\\b\"\n",
    "        }\n",
    "        \n",
    "        for app, pattern in app_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"app_name\"] = app\n",
    "                break\n",
    "        \n",
    "        # Generic browser/internet (needs clarification which browser)\n",
    "        if re.search(r\"\\b(browser|internet)\\b\", t) and \"app_name\" not in self.entities_mentioned:\n",
    "            self.entities_mentioned[\"needs_browser\"] = True\n",
    "\n",
    "        # ===== FILENAME DETECTION =====\n",
    "        # Look for files with extensions\n",
    "        file_match = re.search(r\"([\\w\\-\\s]+?\\.(?:pdf|docx?|xlsx?|pptx?|txt|csv|png|jpg|jpeg|mp3|mp4|zip))\", original_text, flags=re.IGNORECASE)\n",
    "        if file_match:\n",
    "            self.entities_mentioned[\"filename\"] = file_match.group(1).strip()\n",
    "        \n",
    "        # Named file without extension (e.g., \"file called report\")\n",
    "        named_file = re.search(r\"\\b(?:file|document|assignment|report|project)\\s+(?:named|called)\\s+([\\w\\-\\s]+)\", t)\n",
    "        if named_file:\n",
    "            self.entities_mentioned[\"filename_base\"] = named_file.group(1).strip()\n",
    "\n",
    "        # ===== DESTINATION DETECTION =====\n",
    "        dest_patterns = {\n",
    "            \"desktop\": r\"\\b(desktop|on desktop|to desktop)\\b\",\n",
    "            \"downloads\": r\"\\b(downloads|download folder)\\b\",\n",
    "            \"documents\": r\"\\b(documents|my documents)\\b\"\n",
    "        }\n",
    "        for dest, pattern in dest_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"destination\"] = dest\n",
    "                break\n",
    "\n",
    "        # ===== FILE FORMAT DETECTION (TARGET - what to save AS) =====\n",
    "        # Be careful: distinguish between source and target format\n",
    "        format_patterns = {\n",
    "            \"pdf\": r\"\\b(as pdf|to pdf|save as pdf|pdf format|\\.pdf)\\b\",\n",
    "            \"docx\": r\"\\b(as docx|to word|as word document|\\.docx)\\b\",\n",
    "            \"txt\": r\"\\b(as txt|to text|as text file|\\.txt)\\b\",\n",
    "            \"xlsx\": r\"\\b(as xlsx|to excel|as spreadsheet|\\.xlsx)\\b\",\n",
    "            \"png\": r\"\\b(as png|to png|\\.png)\\b\",\n",
    "            \"jpg\": r\"\\b(as jpg|to jpg|as jpeg|\\.jpg)\\b\"\n",
    "        }\n",
    "        for fmt, pattern in format_patterns.items():\n",
    "            if re.search(pattern, t):\n",
    "                self.entities_mentioned[\"target_format\"] = fmt\n",
    "                break\n",
    "\n",
    "        # ===== ACADEMIC/ASSIGNMENT DETECTION =====\n",
    "        if re.search(r\"\\b(assignment|homework|problem|exercise|quiz|test|exam|project)\\b\", t):\n",
    "            self.entities_mentioned[\"task_type\"] = \"assignment\"\n",
    "            \n",
    "            # Course subject\n",
    "            course_match = re.search(r\"\\b(math|mathematics|physics|chemistry|biology|english|history|computer science|cs|programming|calculus|algebra)\\b\", t, re.IGNORECASE)\n",
    "            if course_match:\n",
    "                self.entities_mentioned[\"subject\"] = course_match.group(1)\n",
    "            \n",
    "            # Platform (Moodle, Canvas, etc.)\n",
    "            platform_patterns = {\n",
    "                \"moodle\": r\"\\b(moodle)\\b\",\n",
    "                \"canvas\": r\"\\b(canvas)\\b\",\n",
    "                \"blackboard\": r\"\\b(blackboard)\\b\",\n",
    "                \"google_classroom\": r\"\\b(google classroom|classroom)\\b\"\n",
    "            }\n",
    "            for platform, pattern in platform_patterns.items():\n",
    "                if re.search(pattern, t):\n",
    "                    self.entities_mentioned[\"platform\"] = platform\n",
    "                    break\n",
    "\n",
    "        # ===== MESSAGING PLATFORM =====\n",
    "        if re.search(r\"\\b(discord)\\b\", t):\n",
    "            self.entities_mentioned[\"messaging_platform\"] = \"discord\"\n",
    "        elif re.search(r\"\\b(whatsapp)\\b\", t):\n",
    "            self.entities_mentioned[\"messaging_platform\"] = \"whatsapp\"\n",
    "        \n",
    "        # MESSAGE RECIPIENT\n",
    "        recipient_match = re.search(r\"\\b(?:to|message|dm)\\s+([\\w\\s]+?)(?:\\s+on|\\s+channel|$)\", t)\n",
    "        if recipient_match:\n",
    "            self.entities_mentioned[\"recipient\"] = recipient_match.group(1).strip()\n",
    "        \n",
    "        # MESSAGE CONTENT\n",
    "        msg_match = re.search(r\"(?:say|message|text|send)\\s+['\\\"](.+?)['\\\"]\", original_text, re.IGNORECASE)\n",
    "        if msg_match:\n",
    "            self.entities_mentioned[\"message_content\"] = msg_match.group(1).strip()\n",
    "\n",
    "        # ===== SEARCH QUERY =====\n",
    "        search_match = re.search(r\"(?:search for|find|lookup|locate)\\s+(.+?)(?:\\s+in|\\s+on|$)\", original_text, re.IGNORECASE)\n",
    "        if search_match:\n",
    "            self.entities_mentioned[\"search_query\"] = search_match.group(1).strip()\n",
    "\n",
    "        # ===== EXPRESSION FOR CALCULATION =====\n",
    "        expr_match = re.search(r\"([\\d\\.\\+\\-\\*/\\^\\(\\)\\s]+)$\", text or \"\")\n",
    "        if expr_match and len(expr_match.group(1).strip()) > 2:\n",
    "            self.entities_mentioned[\"expression\"] = expr_match.group(1).strip()\n",
    "\n",
    "    def get_missing_info(self):\n",
    "        \"\"\"Determine what critical information is still missing (RULE-BASED - NO LLM).\"\"\"\n",
    "        missing = []\n",
    "        action = self.entities_mentioned.get(\"action\")\n",
    "\n",
    "        # If action unclear, prioritize that\n",
    "        if not action:\n",
    "            if \"clarify_action\" not in self.questions_asked:\n",
    "                return [\"clarify_action\"]\n",
    "            return []\n",
    "\n",
    "        # ===== ACTION-SPECIFIC REQUIREMENTS =====\n",
    "        if action == \"save\":\n",
    "            # Need: WHAT, SOURCE, DESTINATION, FORMAT\n",
    "            # Check for vague reference first\n",
    "            if self.entities_mentioned.get(\"has_vague_reference\") and \"what_to_save\" not in self.questions_asked:\n",
    "                missing.append(\"what_to_save\")\n",
    "            elif \"filename\" not in self.entities_mentioned and \"filename_base\" not in self.entities_mentioned and \"what_to_save\" not in self.questions_asked:\n",
    "                missing.append(\"what_to_save\")\n",
    "            \n",
    "            if \"source_context\" not in self.entities_mentioned and \"source_context\" not in self.questions_asked:\n",
    "                missing.append(\"source_context\")\n",
    "            \n",
    "            if \"destination\" not in self.entities_mentioned and \"destination\" not in self.questions_asked:\n",
    "                missing.append(\"destination\")\n",
    "            \n",
    "            if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "                missing.append(\"target_format\")\n",
    "\n",
    "        elif action == \"convert\":\n",
    "            if \"filename\" not in self.entities_mentioned and \"source_file\" not in self.questions_asked:\n",
    "                missing.append(\"source_file\")\n",
    "            if \"source_context\" not in self.entities_mentioned and \"source_location\" not in self.questions_asked:\n",
    "                missing.append(\"source_location\")\n",
    "            if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "                missing.append(\"target_format\")\n",
    "\n",
    "        elif action == \"open\":\n",
    "            # Check if we have app name or filename\n",
    "            if \"app_name\" not in self.entities_mentioned and \"filename\" not in self.entities_mentioned:\n",
    "                if self.entities_mentioned.get(\"needs_browser\") and \"browser_choice\" not in self.questions_asked:\n",
    "                    missing.append(\"browser_choice\")\n",
    "                elif \"what_to_open\" not in self.questions_asked:\n",
    "                    missing.append(\"what_to_open\")\n",
    "\n",
    "        elif action == \"browse\":\n",
    "            if \"app_name\" not in self.entities_mentioned and \"browser_choice\" not in self.questions_asked:\n",
    "                missing.append(\"browser_choice\")\n",
    "            if \"search_query\" not in self.entities_mentioned and \"browse_target\" not in self.questions_asked:\n",
    "                missing.append(\"browse_target\")\n",
    "\n",
    "        elif action == \"send_message\":\n",
    "            if \"messaging_platform\" not in self.entities_mentioned and \"platform\" not in self.questions_asked:\n",
    "                missing.append(\"platform\")\n",
    "            if \"recipient\" not in self.entities_mentioned and \"recipient\" not in self.questions_asked:\n",
    "                missing.append(\"recipient\")\n",
    "            if \"message_content\" not in self.entities_mentioned and \"message_content\" not in self.questions_asked:\n",
    "                missing.append(\"message_content\")\n",
    "\n",
    "        elif action == \"search\":\n",
    "            if \"search_query\" not in self.entities_mentioned and \"filename\" not in self.entities_mentioned and \"search_query\" not in self.questions_asked:\n",
    "                missing.append(\"search_query\")\n",
    "\n",
    "        elif action == \"solve\":\n",
    "            if \"subject\" not in self.entities_mentioned and \"subject\" not in self.questions_asked:\n",
    "                missing.append(\"subject\")\n",
    "            if \"platform\" not in self.entities_mentioned and \"app_name\" not in self.entities_mentioned and \"platform_location\" not in self.questions_asked:\n",
    "                missing.append(\"platform_location\")\n",
    "            if \"task_type\" not in self.entities_mentioned and \"specific_assignment\" not in self.questions_asked:\n",
    "                missing.append(\"specific_assignment\")\n",
    "\n",
    "        elif action == \"calculate\":\n",
    "            if \"expression\" not in self.entities_mentioned and \"expression\" not in self.questions_asked:\n",
    "                missing.append(\"expression\")\n",
    "\n",
    "        return missing\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "# ==========================================================\n",
    "# Generate Clarifying Question (LLM with Strong Constraints)\n",
    "# ==========================================================\n",
    "def generate_clarifying_question_llm(history):\n",
    "    \"\"\"Generate ONE natural, human-like question. Uses LLM but with strict validation.\"\"\"\n",
    "    \n",
    "    missing = history.get_missing_info()\n",
    "    if not missing:\n",
    "        return None\n",
    "\n",
    "    missing_key = missing[0]  # Most important missing piece\n",
    "    action = history.entities_mentioned.get(\"action\", \"task\")\n",
    "    \n",
    "    # Build simple, focused prompt\n",
    "    prompt = f\"\"\"You are asking a user for missing information. Be brief and natural.\n",
    "\n",
    "{FEW_SHOT_EXAMPLES}\n",
    "\n",
    "User wants to: {action}\n",
    "You need to ask about: {missing_key}\n",
    "\n",
    "Generate ONE short question (under 30 words) that sounds natural and friendly.\n",
    "\n",
    "Question:\"\"\"\n",
    "\n",
    "    try:\n",
    "        resp = reasoner(\n",
    "            prompt,\n",
    "            max_new_tokens=50,  # Shorter to avoid rambling\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.5,  # Prevent repetition\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        raw = resp[0][\"generated_text\"]\n",
    "        \n",
    "        # Extract question\n",
    "        if \"Question:\" in raw:\n",
    "            question = raw.split(\"Question:\")[-1].strip()\n",
    "        else:\n",
    "            question = raw.split('\\n')[-1].strip()\n",
    "        \n",
    "        # Take only first sentence\n",
    "        question = question.split('\\n')[0].strip()\n",
    "        question = re.sub(r'\\s+', ' ', question)  # Clean whitespace\n",
    "        question = question.strip('\"\\'')  # Remove quotes\n",
    "        \n",
    "        # Validation\n",
    "        if not question.endswith('?'):\n",
    "            question += '?'\n",
    "        \n",
    "        # Length check (prevent hallucination)\n",
    "        if len(question) < 10 or len(question) > 200:\n",
    "            raise ValueError(\"Invalid question length\")\n",
    "        \n",
    "        # Must contain question words\n",
    "        question_words = ['what', 'where', 'which', 'who', 'how', 'should', 'would', 'is', 'are', 'do']\n",
    "        if not any(word in question.lower() for word in question_words):\n",
    "            raise ValueError(\"Not a proper question\")\n",
    "        \n",
    "        # Check for repetition (hallucination indicator)\n",
    "        words = question.lower().split()\n",
    "        if len(words) != len(set(words)) * 1.5:  # Too many repeated words\n",
    "            raise ValueError(\"Repetitive text detected\")\n",
    "        \n",
    "        history.mark_question_asked(missing_key)\n",
    "        history.set_last_question(question)\n",
    "        return question\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[LLM question generation failed: {e}, using template]\")\n",
    "        # FALLBACK TO TEMPLATES (guaranteed no hallucination)\n",
    "        return get_template_question(missing_key, history)\n",
    "\n",
    "def get_template_question(missing_key, history):\n",
    "    \"\"\"Fallback template questions - guaranteed safe.\"\"\"\n",
    "    templates = {\n",
    "        \"clarify_action\": \"What would you like me to help you with?\",\n",
    "        \"what_to_save\": \"What would you like me to save?\",\n",
    "        \"source_context\": \"Is this something currently open on your screen, a file on your computer, or content from a website?\",\n",
    "        \"destination\": \"Where should I save it - Desktop, Downloads, or Documents?\",\n",
    "        \"target_format\": \"What format should I save it as - PDF, Word document, text file, or something else?\",\n",
    "        \"what_to_open\": \"What would you like me to open?\",\n",
    "        \"browser_choice\": \"Which browser would you like - Chrome, Firefox, or Edge?\",\n",
    "        \"browse_target\": \"What would you like to browse or search for?\",\n",
    "        \"platform\": \"Which messaging app - Discord or WhatsApp?\",\n",
    "        \"recipient\": \"Who should I send the message to?\",\n",
    "        \"message_content\": \"What should the message say?\",\n",
    "        \"search_query\": \"What would you like me to search for?\",\n",
    "        \"source_file\": \"Which file should I convert?\",\n",
    "        \"source_location\": \"Is the file already open, or should I look for it somewhere specific?\",\n",
    "        \"subject\": \"What subject is this assignment for?\",\n",
    "        \"platform_location\": \"Where can I find this assignment - Moodle, Canvas, or somewhere else?\",\n",
    "        \"specific_assignment\": \"Which specific assignment are you working on?\",\n",
    "        \"expression\": \"What calculation do you need?\"\n",
    "    }\n",
    "    \n",
    "    question = templates.get(missing_key, \"Could you provide more details?\")\n",
    "    history.mark_question_asked(missing_key)\n",
    "    history.set_last_question(question)\n",
    "    return question\n",
    "\n",
    "# ==========================================================\n",
    "# Task Decomposition and JSON Generation\n",
    "# ==========================================================\n",
    "def decompose_and_generate_json(history):\n",
    "    \"\"\"\n",
    "    Generate reasoning and JSON output for Coordinator Agent.\n",
    "    This function sends the JSON to the coordinator via HTTP POST.\n",
    "    \"\"\"\n",
    "    \n",
    "    entities = history.entities_mentioned\n",
    "    action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "    # Determine JSON context\n",
    "    source_context = entities.get(\"source_context\", \"local_file\")\n",
    "    if source_context == \"web\" or action == \"browse\":\n",
    "        json_context = \"web\"\n",
    "    elif action in [\"open\", \"send_message\", \"calculate\"]:\n",
    "        json_context = \"local\"\n",
    "    else:\n",
    "        json_context = \"system\"\n",
    "\n",
    "    # Generate reasoning (simple, rule-based to avoid hallucination)\n",
    "    reasoning = generate_rule_based_reasoning(entities, history.clarifications)\n",
    "\n",
    "    print(\"\\nðŸ§  Task Reasoning:\")\n",
    "    print(reasoning)\n",
    "    print()\n",
    "\n",
    "    # Build JSON structure (rule-based)\n",
    "    json_output = build_json_structure(entities, json_context)\n",
    "        \n",
    "    # --- Send JSON to Coordinator Agent ---\n",
    "    coordinator_url = \"http://127.0.0.1:8000/coordinate\"  # or your deployed URL\n",
    "\n",
    "    payload = {\n",
    "        \"conversation\": history.get_full_context(),\n",
    "        \"reasoning\": reasoning,\n",
    "        \"task_json\": json_output\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸš€ Sending JSON to Coordinator Agent at {coordinator_url}...\")\n",
    "        \n",
    "        # The Coordinator Agent expects the task details directly, \n",
    "        # so we send json_output content nested inside the 'task_json' key.\n",
    "        response = requests.post(\n",
    "            coordinator_url, \n",
    "            json=payload, # Send the full payload with conversation/reasoning\n",
    "            timeout=15\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        print(\"âœ… Coordinator Agent Response:\")\n",
    "        print(json.dumps(result, indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to send to Coordinator Agent: {e}\")\n",
    "        result = {\"error\": str(e)}\n",
    "\n",
    "    print(\"ðŸ“‹ Generated JSON for Coordinator Agent:\")\n",
    "    print(json.dumps(json_output, indent=2))\n",
    "    print()\n",
    "\n",
    "    return reasoning, json_output, result\n",
    "\n",
    "\n",
    "def generate_rule_based_reasoning(entities, clarifications):\n",
    "    \"\"\"Generate reasoning using RULES (no LLM - no hallucination).\"\"\"\n",
    "    action = entities.get(\"action\", \"task\")\n",
    "    \n",
    "    reasoning_map = {\n",
    "        \"save\": f\"The agent will save {entities.get('filename', 'the file')} from {entities.get('source_context', 'the source')} to {entities.get('destination', 'the destination')} in {entities.get('target_format', 'the specified format').upper()} format.\",\n",
    "        \n",
    "        \"open\": f\"The agent will open {entities.get('app_name') or entities.get('filename', 'the specified application')}.\",\n",
    "        \n",
    "        \"solve\": f\"The agent will access the {entities.get('subject', 'assignment')} from {entities.get('platform', 'the platform')} and provide assistance with solving it.\",\n",
    "        \n",
    "        \"send_message\": f\"The agent will send a message via {entities.get('messaging_platform', 'the messaging app')} to {entities.get('recipient', 'the recipient')}.\",\n",
    "        \n",
    "        \"search\": f\"The agent will search for {entities.get('search_query') or entities.get('filename', 'the specified item')}.\",\n",
    "        \n",
    "        \"browse\": f\"The agent will open {entities.get('app_name', 'the browser')} and navigate to {entities.get('search_query', 'the specified location')}.\",\n",
    "        \n",
    "        \"convert\": f\"The agent will convert {entities.get('filename', 'the file')} to {entities.get('target_format', 'the target format').upper()} format.\",\n",
    "        \n",
    "        \"calculate\": f\"The agent will calculate {entities.get('expression', 'the expression')}.\"\n",
    "    }\n",
    "    \n",
    "    return reasoning_map.get(action, f\"The agent will perform the {action} operation based on the provided information.\")\n",
    "\n",
    "def build_json_structure(entities, json_context):\n",
    "    \"\"\"Build JSON structure using RULES (no LLM - no hallucination).\"\"\"\n",
    "    \n",
    "    action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "    # Map action to action_type\n",
    "    action_type_map = {\n",
    "        \"save\": \"save_as_pdf\" if entities.get(\"target_format\") == \"pdf\" else \"save_file\",\n",
    "        \"open\": \"open_app\",\n",
    "        \"send_message\": \"send_message\",\n",
    "        \"search\": \"search\",\n",
    "        \"convert\": \"convert_file\",\n",
    "        \"calculate\": \"calculate\",\n",
    "        \"delete\": \"delete_file\",\n",
    "        \"solve\": \"solve_assignment\",\n",
    "        \"browse\": \"browse_web\"\n",
    "    }\n",
    "    action_type = action_type_map.get(action, action)\n",
    "\n",
    "    # Build params based on action\n",
    "    params = {\"action_type\": action_type}\n",
    "    \n",
    "    if action == \"save\":\n",
    "        filename = entities.get(\"filename\") or entities.get(\"filename_base\", \"document\")\n",
    "        target_format = entities.get(\"target_format\", \"pdf\")\n",
    "        \n",
    "        # Ensure correct extension\n",
    "        if not filename.endswith(f\".{target_format}\"):\n",
    "            if '.' in filename:\n",
    "                filename = filename.rsplit('.', 1)[0]\n",
    "            filename = f\"{filename}.{target_format}\"\n",
    "        \n",
    "        dest = entities.get(\"destination\", \"desktop\")\n",
    "        params[\"file_path\"] = f\"{{{{{dest}_path}}}}/{filename}\"\n",
    "        params[\"format\"] = target_format\n",
    "        \n",
    "        if entities.get(\"source_context\") == \"open_application\":\n",
    "            params[\"source\"] = \"current_application\"\n",
    "            params[\"file_type\"] = entities.get(\"app_name\", \"unknown\")\n",
    "        else:\n",
    "            params[\"source\"] = \"file_system\"\n",
    "            params[\"file_type\"] = entities.get(\"app_name\", \"word\")\n",
    "    \n",
    "    elif action == \"solve\":\n",
    "        params[\"task_type\"] = entities.get(\"task_type\", \"assignment\")\n",
    "        params[\"subject\"] = entities.get(\"subject\", \"\")\n",
    "        params[\"platform\"] = entities.get(\"platform\", \"\")\n",
    "    \n",
    "    elif action == \"open\":\n",
    "        if entities.get(\"app_name\"):\n",
    "            params[\"app_name\"] = entities[\"app_name\"]\n",
    "        if entities.get(\"filename\"):\n",
    "            params[\"file_path\"] = entities[\"filename\"]\n",
    "    \n",
    "    elif action == \"browse\":\n",
    "        params[\"browser\"] = entities.get(\"app_name\", \"chrome\")\n",
    "        if entities.get(\"search_query\"):\n",
    "            params[\"search_query\"] = entities[\"search_query\"]\n",
    "    \n",
    "    elif action == \"send_message\":\n",
    "        params[\"platform\"] = entities.get(\"messaging_platform\", \"\")\n",
    "        params[\"recipient\"] = entities.get(\"recipient\", \"\")\n",
    "        params[\"message\"] = entities.get(\"message_content\", \"\")\n",
    "    \n",
    "    elif action == \"search\":\n",
    "        params[\"query\"] = entities.get(\"search_query\", entities.get(\"filename\", \"\"))\n",
    "    \n",
    "    elif action == \"calculate\":\n",
    "        params[\"expression\"] = entities.get(\"expression\", \"\")\n",
    "    \n",
    "    elif action == \"convert\":\n",
    "        params[\"source_file\"] = entities.get(\"filename\", \"\")\n",
    "        params[\"target_format\"] = entities.get(\"target_format\", \"\")\n",
    "\n",
    "    # Build final JSON\n",
    "    json_output = {\n",
    "        \"action\": action,\n",
    "        \"context\": json_context,\n",
    "        \"params\": params,\n",
    "        \"task_id\": str(uuid.uuid4()), # Added a unique ID\n",
    "        \"depends_on\": \"\",\n",
    "        \"priority\": \"normal\",\n",
    "        \"timeout\": 300,\n",
    "        \"retry_count\": 3\n",
    "    }\n",
    "\n",
    "    return json_output\n",
    "\n",
    "# ==========================================================\n",
    "# Agent Core Processing Function (for API integration)\n",
    "# ==========================================================\n",
    "def process_agent_turn(user_text: str, history: ConversationHistory):\n",
    "    \"\"\"\n",
    "    Processes a single turn of user input (new task or clarification answer).\n",
    "    \n",
    "    Args:\n",
    "        user_text: The input text from the user.\n",
    "        history: The current state of the conversation (must be maintained \n",
    "                 by the external API server, e.g., in a session/database).\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing either a clarification question (with 'type': 'clarification_needed') \n",
    "        or the final task JSON and coordinator response (with 'type': 'task_ready').\n",
    "    \"\"\"\n",
    "    turn_count = len(history.clarifications) + (1 if history.original_task else 0)\n",
    "    max_turns = 10 \n",
    "    \n",
    "    if turn_count > max_turns:\n",
    "        history.reset()\n",
    "        return {\n",
    "            \"type\": \"error\",\n",
    "            \"message\": \"Too many turns without resolution. Please rephrase your task.\"\n",
    "        }\n",
    "\n",
    "    # 1. Determine if the input is a new task or an answer to a clarification\n",
    "    if not history.original_task:\n",
    "        # NEW TASK\n",
    "        history.set_original_task(user_text)\n",
    "        print(f\"\\n[New Task Received]: {user_text}\")\n",
    "    elif history.last_question:\n",
    "        # ANSWER TO LAST QUESTION\n",
    "        print(f\"\\n[Clarification Answer Received]: {user_text}\")\n",
    "        history.add_clarification(history.last_question, user_text)\n",
    "        history.set_last_question(None) # Clear last question\n",
    "    \n",
    "    # 2. Check for missing information\n",
    "    missing = history.get_missing_info()\n",
    "\n",
    "    if missing:\n",
    "        # Need clarification - generate question\n",
    "        question = generate_clarifying_question_llm(history)\n",
    "        print(f\"\\nðŸ’¬ Agent: {question}\")\n",
    "        return {\n",
    "            \"type\": \"clarification_needed\",\n",
    "            \"question\": question,\n",
    "            \"missing_keys\": missing,\n",
    "            \"conversation_state_snapshot\": history.entities_mentioned \n",
    "        }\n",
    "    else:\n",
    "        # Enough info - generate plan and send to Coordinator\n",
    "        print(f\"\\nðŸ’¬ Agent: Perfect! All info gathered. Generating task plan...\")\n",
    "        \n",
    "        # decompose_and_generate_json sends the JSON to the coordinator via HTTP POST\n",
    "        reasoning, json_plan, coordinator_response = decompose_and_generate_json(history)\n",
    "        \n",
    "        # Reset history for the next task\n",
    "        history.reset()\n",
    "        \n",
    "        return {\n",
    "            \"type\": \"task_ready\",\n",
    "            \"reasoning\": reasoning,\n",
    "            \"task_json\": json_plan,\n",
    "            \"coordinator_response\": coordinator_response \n",
    "        }\n",
    "\n",
    "# ==========================================================\n",
    "# Minimal Example / Testing Block (Replaces original Main Loop)\n",
    "# ==========================================================\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ðŸ¤– SMART LANGUAGE AGENT - API Mode Simulation\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # --- SIMULATE TASK 1: Multi-turn Clarification ---\n",
    "    print(\"\\n--- SIMULATION 1: Multi-turn Clarification (save this as pdf) ---\")\n",
    "    my_history_1 = ConversationHistory()\n",
    "    \n",
    "    # Turn 1: New Task: \"save this as pdf\" (Requires clarification on WHAT and WHERE)\n",
    "    user_input_1 = \"save this document as pdf\"\n",
    "    result_1 = process_agent_turn(user_input_1, my_history_1)\n",
    "    \n",
    "    print(\"\\n--- API Response 1 (Clarification) ---\")\n",
    "    print(json.dumps(result_1, indent=2))\n",
    "    \n",
    "    if result_1.get(\"type\") == \"clarification_needed\":\n",
    "        # Turn 2: Clarification Answer: \"It's the open Word document, save it to downloads\"\n",
    "        print(\"\\n--- Simulating next turn (User answers clarification) ---\\n\")\n",
    "        user_input_2 = \"It's the open Word document, save it to downloads\"\n",
    "        result_2 = process_agent_turn(user_input_2, my_history_1)\n",
    "        \n",
    "        print(\"\\n--- API Response 2 (Task Ready) ---\")\n",
    "        print(json.dumps(result_2, indent=2))\n",
    "        \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    # --- SIMULATE TASK 2: Single-turn Completion ---\n",
    "    print(\"\\n--- SIMULATION 2: Single-turn Completion (open Chrome) ---\")\n",
    "    my_history_2 = ConversationHistory()\n",
    "    \n",
    "    # Turn 1: New Task: \"open chrome\" (No clarification needed)\n",
    "    user_input_3 = \"open chrome\"\n",
    "    result_3 = process_agent_turn(user_input_3, my_history_2)\n",
    "    \n",
    "    print(\"\\n--- API Response 3 (Task Ready) ---\")\n",
    "    print(json.dumps(result_3, indent=2))\n",
    "    \n",
    "    print(\"\\nðŸ‘‹ Simulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c355a8b",
   "metadata": {},
   "source": [
    "#BEST ONE SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fadb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classifier from: c:\\Users\\Shosh\\Desktop\\Univeristy\\Graduation project\\code\\sharc_distilbert_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Classifier loaded.\n",
      "Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reasoner loaded.\n",
      "\n",
      "======================================================================\n",
      "ðŸ¤– SMART LANGUAGE AGENT - Anti-Hallucination Version\n",
      "======================================================================\n",
      "I'll help you complete tasks by asking clear questions when needed.\n",
      "Type 'quit' to exit, 'reset' to start over.\n",
      "\n",
      "\n",
      "[User input]: download file\n",
      "\n",
      "ðŸ’¬ Agent: What would you like me to save?\n",
      "\n",
      "\n",
      "[User response]: download a file from IEEE, related to mutli agents, search for it\n",
      "\n",
      "ðŸ’¬ Agent: Where should I save it - Desktop, Downloads, Documents, or somewhere else?\n",
      "\n",
      "\n",
      "[User response]: downloads, and can you rename it?\n",
      "\n",
      "ðŸ’¬ Agent: What format should I save it as - PDF, Word document, text file, or something else?\n",
      "\n",
      "\n",
      "[User response]: pdf\n",
      "\n",
      "ðŸ’¬ Agent: Perfect! I have everything I need. Preparing your task...\n",
      "\n",
      "\n",
      "ðŸ§  Task Reasoning:\n",
      "The user will need to navigate through the website's interface to find the relevant information they are looking for. Once found, they will be prompted with options to download the content (PDF, Word document, etc.) or save it to their desired location on their computer. They may also have the option to rename the downloaded file if needed.\n",
      "\n",
      "ðŸ“‹ Generated JSON for Coordinator Agent:\n",
      "{\n",
      "  \"action\": \"save\",\n",
      "  \"context\": \"system\",\n",
      "  \"params\": {\n",
      "    \"action_type\": \"save_as_pdf\",\n",
      "    \"file_path\": \"{{downloads_path}}/document.pdf\",\n",
      "    \"content\": \"{{file_content}}\",\n",
      "    \"file_type\": \"word\"\n",
      "  },\n",
      "  \"task_id\": \"\",\n",
      "  \"depends_on\": \"\",\n",
      "  \"priority\": \"\",\n",
      "  \"timeout\": \"\",\n",
      "  \"retry_count\": \"\"\n",
      "}\n",
      "\n",
      "ðŸ’¾ Saved to: output_logs/task_1762123689_79c2b330.json\n",
      "\n",
      "\n",
      "ðŸ‘‹ Thanks for using the agent. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# # ==========================================================\n",
    "# # ðŸ¤– ENHANCED SMART LANGUAGE AGENT (Anti-Hallucination Version)\n",
    "# # ==========================================================\n",
    "# from transformers import pipeline, AutoTokenizer, set_seed\n",
    "# import torch\n",
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import uuid\n",
    "# import time\n",
    "\n",
    "# # Set seed for reproducibility\n",
    "# set_seed(42)\n",
    "\n",
    "# # --- 1. Load Classifier ---\n",
    "# classifier_path = \"./sharc_distilbert_final\"\n",
    "# classifier_path_abs = os.path.abspath(classifier_path)\n",
    "# print(f\"Loading classifier from: {classifier_path_abs}\")\n",
    "# classifier = pipeline(\"text-classification\", model=classifier_path_abs)\n",
    "# print(\"âœ… Classifier loaded.\")\n",
    "\n",
    "# # --- 2. Load Reasoning Model ---\n",
    "# reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# print(f\"Loading {reasoning_model_name}...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(reasoning_model_name)\n",
    "\n",
    "# # Fix: Create pipeline without generation_config parameter\n",
    "# # We'll pass generation_config during each generate() call instead\n",
    "# reasoner = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=reasoning_model_name,\n",
    "#     tokenizer=tokenizer,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float32\n",
    "# )\n",
    "# print(\"âœ… Reasoner loaded.\")\n",
    "\n",
    "# # ==========================================================\n",
    "# # 3. Template-Based Question Bank (Primary Method)\n",
    "# # ==========================================================\n",
    "# QUESTION_TEMPLATES = {\n",
    "#     \"what_to_save\": [\n",
    "#         \"What would you like me to save?\",\n",
    "#         \"What content needs to be saved?\",\n",
    "#         \"Which file or document should I save?\"\n",
    "#     ],\n",
    "#     \"source_context\": [\n",
    "#         \"Is this something currently open on your screen, a file I need to find, or content from a website?\",\n",
    "#         \"Where is this located - in an open application, on your computer, or online?\",\n",
    "#         \"Should I work with something already open, or look for a file?\"\n",
    "#     ],\n",
    "#     \"destination\": [\n",
    "#         \"Where should I save it - Desktop, Downloads, Documents, or somewhere else?\",\n",
    "#         \"Which folder would you like me to save this to?\",\n",
    "#         \"What's the destination folder?\"\n",
    "#     ],\n",
    "#     \"target_format\": [\n",
    "#         \"What format should I save it as - PDF, Word document, text file, or something else?\",\n",
    "#         \"Which file format do you need?\",\n",
    "#         \"Should this be saved as PDF, DOCX, TXT, or another format?\"\n",
    "#     ],\n",
    "#     \"clarify_action\": [\n",
    "#         \"What would you like me to do - save something, open an app, send a message, or something else?\",\n",
    "#         \"Could you clarify the action - are you trying to save, open, delete, or do something else?\",\n",
    "#         \"What's the main task you need help with?\"\n",
    "#     ],\n",
    "#     \"what_to_open\": [\n",
    "#         \"What would you like me to open?\",\n",
    "#         \"Which application or file should I open?\",\n",
    "#         \"What needs to be opened?\"\n",
    "#     ],\n",
    "#     \"platform\": [\n",
    "#         \"Which messaging platform should I use - Discord, WhatsApp, or another app?\",\n",
    "#         \"Where should I send the message?\",\n",
    "#         \"Which app - Discord or WhatsApp?\"\n",
    "#     ],\n",
    "#     \"recipient\": [\n",
    "#         \"Who should I send the message to?\",\n",
    "#         \"What's the recipient's name or channel?\",\n",
    "#         \"Who is the message for?\"\n",
    "#     ],\n",
    "#     \"message_content\": [\n",
    "#         \"What should the message say?\",\n",
    "#         \"What content should I send?\",\n",
    "#         \"What's the message?\"\n",
    "#     ],\n",
    "#     \"search_query\": [\n",
    "#         \"What would you like me to search for?\",\n",
    "#         \"What's the search query?\",\n",
    "#         \"What should I look up?\"\n",
    "#     ],\n",
    "#     \"source_file\": [\n",
    "#         \"Which file should I convert?\",\n",
    "#         \"What's the file name?\",\n",
    "#         \"Which file are you referring to?\"\n",
    "#     ],\n",
    "#     \"source_location\": [\n",
    "#         \"Is the file already open, or should I look for it in a specific location?\",\n",
    "#         \"Where is this file located?\",\n",
    "#         \"Should I search for the file, or is it already open?\"\n",
    "#     ],\n",
    "#     \"expression\": [\n",
    "#         \"What's the calculation you need?\",\n",
    "#         \"What should I calculate?\",\n",
    "#         \"What's the math expression?\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# # ==========================================================\n",
    "# # 4. Conversation History Manager\n",
    "# # ==========================================================\n",
    "# class ConversationHistory:\n",
    "#     def __init__(self):\n",
    "#         self.messages = []\n",
    "#         self.original_task = None\n",
    "#         self.clarifications = []\n",
    "#         self.entities_mentioned = {}\n",
    "#         self.questions_asked = set()\n",
    "#         self.last_question = None\n",
    "#         self.user_confirmations = []\n",
    "\n",
    "#     def set_original_task(self, task):\n",
    "#         self.original_task = task\n",
    "#         self._extract_entities(task)\n",
    "\n",
    "#     def add_clarification(self, question, answer):\n",
    "#         self.clarifications.append({\"question\": question, \"answer\": answer})\n",
    "#         self._extract_entities(answer)\n",
    "\n",
    "#     def set_last_question(self, q):\n",
    "#         self.last_question = q\n",
    "\n",
    "#     def mark_question_asked(self, q_type):\n",
    "#         self.questions_asked.add(q_type)\n",
    "\n",
    "#     def get_full_context(self):\n",
    "#         context = f\"Original request: {self.original_task}\\n\"\n",
    "#         if self.clarifications:\n",
    "#             context += \"Information gathered:\\n\"\n",
    "#             for i, c in enumerate(self.clarifications, 1):\n",
    "#                 context += f\"  {i}. Q: {c['question']}\\n     A: {c['answer']}\\n\"\n",
    "#         return context\n",
    "\n",
    "#     def _extract_entities(self, text):\n",
    "#         \"\"\"Extract task-relevant entities from text.\"\"\"\n",
    "#         if not text:\n",
    "#             return\n",
    "            \n",
    "#         t = text.lower()\n",
    "\n",
    "#         # ACTION DETECTION\n",
    "#         if re.search(r\"\\b(save|store|download|export|save as)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"save\"\n",
    "#         elif re.search(r\"\\b(open|launch|start|run)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"open\"\n",
    "#         elif re.search(r\"\\b(delete|remove|erase)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"delete\"\n",
    "#         elif re.search(r\"\\b(send|message|text|dm)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"send_message\"\n",
    "#         elif re.search(r\"\\b(search|find|lookup|google)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"search\"\n",
    "#         elif re.search(r\"\\b(convert|transform|change)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"convert\"\n",
    "#         elif re.search(r\"\\b(calculate|compute|solve|what is)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"calculate\"\n",
    "        \n",
    "#         # SOURCE CONTEXT - Critical for \"save\" and \"convert\" actions\n",
    "#         if re.search(r\"\\b(currently open|open file|current|this application|this app|active window)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"open_application\"\n",
    "#         elif re.search(r\"\\b(website|webpage|web page|browser|online|url|http)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"web\"\n",
    "#         elif re.search(r\"\\b(file|document|folder|directory|desktop|downloads|c:\\\\|/home/)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"local_file\"\n",
    "        \n",
    "#         # APPLICATION DETECTION\n",
    "#         app_patterns = {\n",
    "#             \"word\": r\"\\b(word|winword|microsoft word|ms word|\\.docx?)\\b\",\n",
    "#             \"excel\": r\"\\b(excel|ms excel|microsoft excel|\\.xlsx?)\\b\",\n",
    "#             \"powerpoint\": r\"\\b(powerpoint|ppt|ms powerpoint|\\.pptx?)\\b\",\n",
    "#             \"notepad\": r\"\\b(notepad|notepad\\+\\+)\\b\",\n",
    "#             \"chrome\": r\"\\b(chrome|google chrome)\\b\",\n",
    "#             \"firefox\": r\"\\b(firefox|mozilla)\\b\",\n",
    "#             \"calculator\": r\"\\b(calculator|calc)\\b\",\n",
    "#             \"spotify\": r\"\\b(spotify)\\b\",\n",
    "#             \"discord\": r\"\\b(discord)\\b\",\n",
    "#             \"whatsapp\": r\"\\b(whatsapp|whats app)\\b\"\n",
    "#         }\n",
    "#         for app, pattern in app_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"app_name\"] = app\n",
    "#                 break\n",
    "\n",
    "#         # FILENAME DETECTION\n",
    "#         file_match = re.search(r\"([\\w\\-\\s]+?\\.(?:pdf|docx?|xlsx?|pptx?|txt|csv|png|jpg|mp3|mp4))\", text, flags=re.IGNORECASE)\n",
    "#         if file_match:\n",
    "#             self.entities_mentioned[\"filename\"] = file_match.group(1).strip()\n",
    "        \n",
    "#         # Named file without extension\n",
    "#         named_file = re.search(r\"\\b(?:file|document|assignment|report|project)\\s+(?:named|called)\\s+([\\w\\-\\s]+)\", t)\n",
    "#         if named_file:\n",
    "#             self.entities_mentioned[\"filename_base\"] = named_file.group(1).strip()\n",
    "\n",
    "#         # DESTINATION DETECTION\n",
    "#         dest_patterns = {\n",
    "#             \"desktop\": r\"\\b(desktop|on desktop|to desktop)\\b\",\n",
    "#             \"downloads\": r\"\\b(downloads|download folder)\\b\",\n",
    "#             \"documents\": r\"\\b(documents|my documents)\\b\"\n",
    "#         }\n",
    "#         for dest, pattern in dest_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"destination\"] = dest\n",
    "#                 break\n",
    "\n",
    "#         # FILE FORMAT DETECTION\n",
    "#         format_patterns = {\n",
    "#             \"pdf\": r\"\\b(pdf|to pdf|as pdf)\\b\",\n",
    "#             \"docx\": r\"\\b(docx|word document)\\b\",\n",
    "#             \"txt\": r\"\\b(txt|text file|plain text)\\b\",\n",
    "#             \"xlsx\": r\"\\b(xlsx|excel|spreadsheet)\\b\"\n",
    "#         }\n",
    "#         for fmt, pattern in format_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"target_format\"] = fmt\n",
    "#                 break\n",
    "\n",
    "#         # MESSAGING PLATFORM\n",
    "#         if re.search(r\"\\b(discord)\\b\", t):\n",
    "#             self.entities_mentioned[\"platform\"] = \"discord\"\n",
    "#         elif re.search(r\"\\b(whatsapp)\\b\", t):\n",
    "#             self.entities_mentioned[\"platform\"] = \"whatsapp\"\n",
    "        \n",
    "#         # MESSAGE RECIPIENT/CHANNEL\n",
    "#         channel_match = re.search(r\"\\bto\\s+([\\w\\-\\s]+?)(?:\\s+channel|\\s+server|$)\", t)\n",
    "#         if channel_match:\n",
    "#             self.entities_mentioned[\"recipient\"] = channel_match.group(1).strip()\n",
    "        \n",
    "#         # MESSAGE CONTENT\n",
    "#         msg_match = re.search(r\"(?:say|message|text|send)\\s+['\\\"](.+?)['\\\"]\", text, flags=re.IGNORECASE)\n",
    "#         if msg_match:\n",
    "#             self.entities_mentioned[\"message_content\"] = msg_match.group(1).strip()\n",
    "\n",
    "#         # SEARCH QUERY\n",
    "#         search_match = re.search(r\"(?:search for|find|lookup|google)\\s+['\\\"]?(.+?)['\\\"]?$\", text, flags=re.IGNORECASE)\n",
    "#         if search_match:\n",
    "#             self.entities_mentioned[\"search_query\"] = search_match.group(1).strip()\n",
    "\n",
    "#         # EXPRESSION FOR CALCULATION\n",
    "#         expr_match = re.search(r\"([\\d\\.\\+\\-\\*/\\^\\(\\)\\s]+)$\", text or \"\")\n",
    "#         if expr_match and len(expr_match.group(1).strip()) > 2:\n",
    "#             self.entities_mentioned[\"expression\"] = expr_match.group(1).strip()\n",
    "\n",
    "#     def get_missing_info(self):\n",
    "#         \"\"\"Determine what critical information is still missing.\"\"\"\n",
    "#         missing = []\n",
    "#         action = self.entities_mentioned.get(\"action\")\n",
    "\n",
    "#         # If action unclear, prioritize that\n",
    "#         if not action and \"clarify_action\" not in self.questions_asked:\n",
    "#             missing.append(\"clarify_action\")\n",
    "#             return missing\n",
    "\n",
    "#         # ACTION-SPECIFIC REQUIREMENTS\n",
    "#         if action == \"save\":\n",
    "#             # Need: WHAT (filename/content), SOURCE (where from), DESTINATION (where to), FORMAT\n",
    "#             if \"filename\" not in self.entities_mentioned and \"filename_base\" not in self.entities_mentioned and \"what_to_save\" not in self.questions_asked:\n",
    "#                 missing.append(\"what_to_save\")\n",
    "#             if \"source_context\" not in self.entities_mentioned and \"source_context\" not in self.questions_asked:\n",
    "#                 missing.append(\"source_context\")\n",
    "#             if \"destination\" not in self.entities_mentioned and \"destination\" not in self.questions_asked:\n",
    "#                 missing.append(\"destination\")\n",
    "#             if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "#                 missing.append(\"target_format\")\n",
    "\n",
    "#         elif action == \"convert\":\n",
    "#             if \"filename\" not in self.entities_mentioned and \"source_file\" not in self.questions_asked:\n",
    "#                 missing.append(\"source_file\")\n",
    "#             if \"source_context\" not in self.entities_mentioned and \"source_location\" not in self.questions_asked:\n",
    "#                 missing.append(\"source_location\")\n",
    "#             if \"target_format\" not in self.entities_mentioned and \"target_format\" not in self.questions_asked:\n",
    "#                 missing.append(\"target_format\")\n",
    "\n",
    "#         elif action == \"open\":\n",
    "#             if \"app_name\" not in self.entities_mentioned and \"filename\" not in self.entities_mentioned and \"what_to_open\" not in self.questions_asked:\n",
    "#                 missing.append(\"what_to_open\")\n",
    "\n",
    "#         elif action == \"send_message\":\n",
    "#             if \"platform\" not in self.entities_mentioned and \"platform\" not in self.questions_asked:\n",
    "#                 missing.append(\"platform\")\n",
    "#             if \"recipient\" not in self.entities_mentioned and \"recipient\" not in self.questions_asked:\n",
    "#                 missing.append(\"recipient\")\n",
    "#             if \"message_content\" not in self.entities_mentioned and \"message_content\" not in self.questions_asked:\n",
    "#                 missing.append(\"message_content\")\n",
    "\n",
    "#         elif action == \"search\":\n",
    "#             if \"search_query\" not in self.entities_mentioned and \"search_query\" not in self.questions_asked:\n",
    "#                 missing.append(\"search_query\")\n",
    "\n",
    "#         elif action == \"calculate\":\n",
    "#             if \"expression\" not in self.entities_mentioned and \"expression\" not in self.questions_asked:\n",
    "#                 missing.append(\"expression\")\n",
    "\n",
    "#         return missing\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.__init__()\n",
    "\n",
    "# # ==========================================================\n",
    "# # 5. Template-Based Question Generator (Primary)\n",
    "# # ==========================================================\n",
    "# def generate_clarifying_question_template(history):\n",
    "#     \"\"\"Generate question using deterministic templates (primary method).\"\"\"\n",
    "    \n",
    "#     missing = history.get_missing_info()\n",
    "#     if not missing:\n",
    "#         return None\n",
    "\n",
    "#     # Get the most critical missing piece\n",
    "#     missing_key = missing[0]\n",
    "    \n",
    "#     # Select template from bank\n",
    "#     if missing_key in QUESTION_TEMPLATES:\n",
    "#         # Use first template (most natural)\n",
    "#         question = QUESTION_TEMPLATES[missing_key][0]\n",
    "#     else:\n",
    "#         # Generic fallback\n",
    "#         question = \"Could you provide more details about what you'd like me to do?\"\n",
    "    \n",
    "#     history.mark_question_asked(missing_key)\n",
    "#     history.set_last_question(question)\n",
    "#     return question\n",
    "\n",
    "# # ==========================================================\n",
    "# # 6. Validate LLM Output (Anti-Hallucination)\n",
    "# # ==========================================================\n",
    "# def is_valid_question(text, max_length=150):\n",
    "#     \"\"\"Validate generated question for quality.\"\"\"\n",
    "#     if not text or len(text.strip()) == 0:\n",
    "#         return False\n",
    "    \n",
    "#     # Must end with question mark\n",
    "#     if not text.strip().endswith('?'):\n",
    "#         return False\n",
    "    \n",
    "#     # Reasonable length\n",
    "#     if len(text) > max_length or len(text) < 10:\n",
    "#         return False\n",
    "    \n",
    "#     # Must contain question words or be interrogative\n",
    "#     question_indicators = ['what', 'where', 'when', 'which', 'who', 'how', 'should', 'would', 'could', 'is', 'are', 'do']\n",
    "#     if not any(word in text.lower() for word in question_indicators):\n",
    "#         return False\n",
    "    \n",
    "#     # No repetitive patterns (hallucination indicator)\n",
    "#     words = text.lower().split()\n",
    "#     if len(words) != len(set(words)):  # Check for exact word repetition\n",
    "#         word_counts = {}\n",
    "#         for word in words:\n",
    "#             word_counts[word] = word_counts.get(word, 0) + 1\n",
    "#             if word_counts[word] > 2:  # Same word appears 3+ times\n",
    "#                 return False\n",
    "    \n",
    "#     return True\n",
    "\n",
    "# def is_valid_reasoning(text, max_length=800):\n",
    "#     \"\"\"Validate reasoning output.\"\"\"\n",
    "#     if not text or len(text.strip()) == 0:\n",
    "#         return False\n",
    "    \n",
    "#     # Reasonable length\n",
    "#     if len(text) > max_length or len(text) < 20:\n",
    "#         return False\n",
    "    \n",
    "#     # Must contain action-related keywords\n",
    "#     action_keywords = ['will', 'should', 'need', 'task', 'action', 'step', 'first', 'then', 'agent', 'perform']\n",
    "#     if not any(word in text.lower() for word in action_keywords):\n",
    "#         return False\n",
    "    \n",
    "#     # Check for hallucination patterns\n",
    "#     lines = text.split('\\n')\n",
    "#     if len(lines) > 15:  # Too many lines = likely repetition\n",
    "#         return False\n",
    "    \n",
    "#     return True\n",
    "\n",
    "# # ==========================================================\n",
    "# # 7. Task Decomposition and JSON Generation\n",
    "# # ==========================================================\n",
    "# def decompose_and_generate_json(history):\n",
    "#     \"\"\"Generate reasoning steps and proper JSON output for Coordinator Agent.\"\"\"\n",
    "    \n",
    "#     context = history.get_full_context()\n",
    "#     entities = history.entities_mentioned\n",
    "    \n",
    "#     # Determine context for JSON\n",
    "#     action = entities.get(\"action\", \"unknown\")\n",
    "#     source_context = entities.get(\"source_context\", \"local_file\")\n",
    "    \n",
    "#     # Map to JSON context\n",
    "#     if source_context == \"web\":\n",
    "#         json_context = \"web\"\n",
    "#     elif action in [\"open\", \"send_message\", \"calculate\"]:\n",
    "#         json_context = \"local\"\n",
    "#     else:\n",
    "#         json_context = \"system\"\n",
    "\n",
    "#     # CONSTRAINED reasoning generation\n",
    "#     reasoning_prompt = f\"\"\"Task: {history.original_task}\n",
    "\n",
    "# Context: {'; '.join([f\"{c['question']} â†’ {c['answer']}\" for c in history.clarifications])}\n",
    "\n",
    "# Explain in 2-3 sentences how to complete this task. Be specific and factual.\n",
    "# Reasoning:\"\"\"\n",
    "\n",
    "#     try:\n",
    "#         # Use deterministic generation (no sampling)\n",
    "#         config = GenerationConfig(\n",
    "#             max_new_tokens=120,\n",
    "#             do_sample=False,\n",
    "#             pad_token_id=tokenizer.eos_token_id,\n",
    "#             eos_token_id=tokenizer.eos_token_id,\n",
    "#             repetition_penalty=1.2\n",
    "#         )\n",
    "        \n",
    "#         resp = reasoner(\n",
    "#             reasoning_prompt,\n",
    "#             generation_config=config\n",
    "#         )\n",
    "#         raw = resp[0][\"generated_text\"]\n",
    "#         reasoning = raw.split(\"Reasoning:\")[-1].strip()\n",
    "        \n",
    "#         # Clean up and validate\n",
    "#         lines = [l.strip() for l in reasoning.split('\\n') if l.strip()]\n",
    "#         reasoning = ' '.join(lines[:5])  # Max 5 lines, join as paragraph\n",
    "        \n",
    "#         # Validate\n",
    "#         if not is_valid_reasoning(reasoning):\n",
    "#             raise ValueError(\"Invalid reasoning generated\")\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         # Rule-based fallback\n",
    "#         reasoning = generate_rule_based_reasoning(entities, history.clarifications)\n",
    "\n",
    "#     print(\"\\nðŸ§  Task Reasoning:\")\n",
    "#     print(reasoning)\n",
    "#     print()\n",
    "\n",
    "#     # Build JSON structure\n",
    "#     json_output = build_json_structure(entities, json_context)\n",
    "    \n",
    "#     # Save to file\n",
    "#     os.makedirs(\"output_logs\", exist_ok=True)\n",
    "#     timestamp = int(time.time())\n",
    "#     fname = f\"output_logs/task_{timestamp}_{str(uuid.uuid4())[:8]}.json\"\n",
    "    \n",
    "#     with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump({\n",
    "#             \"reasoning\": reasoning,\n",
    "#             \"task_json\": json_output\n",
    "#         }, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "#     print(\"ðŸ“‹ Generated JSON for Coordinator Agent:\")\n",
    "#     print(json.dumps(json_output, indent=2))\n",
    "#     print(f\"\\nðŸ’¾ Saved to: {fname}\\n\")\n",
    "\n",
    "#     return reasoning, json_output, fname\n",
    "\n",
    "# def generate_rule_based_reasoning(entities, clarifications):\n",
    "#     \"\"\"Fallback: Generate reasoning using rules instead of LLM.\"\"\"\n",
    "#     action = entities.get(\"action\", \"task\")\n",
    "#     source = entities.get(\"source_context\", \"\")\n",
    "#     filename = entities.get(\"filename\") or entities.get(\"filename_base\", \"file\")\n",
    "#     dest = entities.get(\"destination\", \"specified location\")\n",
    "#     format_type = entities.get(\"target_format\", \"\")\n",
    "    \n",
    "#     if action == \"save\":\n",
    "#         if source == \"open_application\":\n",
    "#             return f\"The agent will save the currently open document '{filename}' to {dest} in {format_type.upper()} format using the application's export functionality.\"\n",
    "#         else:\n",
    "#             return f\"The agent will locate '{filename}', open it, and save it to {dest} in {format_type.upper()} format.\"\n",
    "    \n",
    "#     elif action == \"open\":\n",
    "#         app_name = entities.get(\"app_name\", filename)\n",
    "#         return f\"The agent will launch {app_name} using the system's application launcher.\"\n",
    "    \n",
    "#     elif action == \"send_message\":\n",
    "#         platform = entities.get(\"platform\", \"messaging app\")\n",
    "#         recipient = entities.get(\"recipient\", \"recipient\")\n",
    "#         return f\"The agent will open {platform}, navigate to {recipient}, and send the specified message.\"\n",
    "    \n",
    "#     elif action == \"search\":\n",
    "#         query = entities.get(\"search_query\", \"query\")\n",
    "#         return f\"The agent will perform a search for '{query}' using the default search method.\"\n",
    "    \n",
    "#     else:\n",
    "#         return f\"The agent will execute the {action} operation based on the provided parameters.\"\n",
    "\n",
    "# def build_json_structure(entities, json_context):\n",
    "#     \"\"\"Build the JSON structure according to Coordinator Agent specification.\"\"\"\n",
    "    \n",
    "#     action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "#     # Map action to action_type\n",
    "#     action_type_map = {\n",
    "#         \"save\": \"save_as_pdf\" if entities.get(\"target_format\") == \"pdf\" else \"save_file\",\n",
    "#         \"open\": \"open_app\",\n",
    "#         \"send_message\": \"send_message\",\n",
    "#         \"search\": \"search\",\n",
    "#         \"convert\": \"convert_file\",\n",
    "#         \"calculate\": \"calculate\",\n",
    "#         \"delete\": \"delete_file\"\n",
    "#     }\n",
    "#     action_type = action_type_map.get(action, action)\n",
    "\n",
    "#     # Build params based on action\n",
    "#     params = {\"action_type\": action_type}\n",
    "    \n",
    "#     if action == \"save\":\n",
    "#         filename = entities.get(\"filename\") or entities.get(\"filename_base\", \"document\")\n",
    "#         target_format = entities.get(\"target_format\", \"pdf\")\n",
    "        \n",
    "#         if not filename.endswith(f\".{target_format}\"):\n",
    "#             filename = f\"{filename}.{target_format}\"\n",
    "        \n",
    "#         dest = entities.get(\"destination\", \"desktop\")\n",
    "#         params[\"file_path\"] = f\"{{{{{dest}_path}}}}/{filename}\"\n",
    "        \n",
    "#         if entities.get(\"source_context\") == \"open_application\":\n",
    "#             params[\"content\"] = \"{{current_document}}\"\n",
    "#             params[\"file_type\"] = entities.get(\"app_name\", \"unknown\")\n",
    "#         else:\n",
    "#             params[\"content\"] = \"{{file_content}}\"\n",
    "#             params[\"file_type\"] = entities.get(\"app_name\", \"word\")\n",
    "    \n",
    "#     elif action == \"open\":\n",
    "#         if entities.get(\"app_name\"):\n",
    "#             params[\"app_name\"] = entities[\"app_name\"]\n",
    "#         elif entities.get(\"filename\"):\n",
    "#             params[\"file_path\"] = entities[\"filename\"]\n",
    "    \n",
    "#     elif action == \"send_message\":\n",
    "#         params[\"platform\"] = entities.get(\"platform\", \"discord\")\n",
    "#         if entities.get(\"recipient\"):\n",
    "#             params[\"recipient\"] = entities[\"recipient\"]\n",
    "#         if entities.get(\"message_content\"):\n",
    "#             params[\"message\"] = entities[\"message_content\"]\n",
    "    \n",
    "#     elif action == \"search\":\n",
    "#         params[\"query\"] = entities.get(\"search_query\", entities.get(\"expression\", \"\"))\n",
    "    \n",
    "#     elif action == \"calculate\":\n",
    "#         params[\"expression\"] = entities.get(\"expression\", \"\")\n",
    "\n",
    "#     # Build final JSON - leave optional fields empty as strings\n",
    "#     json_output = {\n",
    "#         \"action\": action,\n",
    "#         \"context\": json_context,\n",
    "#         \"params\": params,\n",
    "#         \"task_id\": \"\",\n",
    "#         \"depends_on\": \"\",\n",
    "#         \"priority\": \"\",\n",
    "#         \"timeout\": \"\",\n",
    "#         \"retry_count\": \"\"\n",
    "#     }\n",
    "\n",
    "#     return json_output\n",
    "\n",
    "# # ==========================================================\n",
    "# # 8. Main Interaction Loop\n",
    "# # ==========================================================\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"ðŸ¤– SMART LANGUAGE AGENT - Anti-Hallucination Version\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"I'll help you complete tasks by asking clear questions when needed.\")\n",
    "# print(\"Type 'quit' to exit, 'reset' to start over.\\n\")\n",
    "\n",
    "# history = ConversationHistory()\n",
    "# in_clarification = False\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         if not in_clarification:\n",
    "#             user_input = input(\"ðŸ‘¤ You: \").strip()\n",
    "            \n",
    "#             if user_input.lower() == \"quit\":\n",
    "#                 print(\"\\nðŸ‘‹ Thanks for using the agent. Goodbye!\")\n",
    "#                 break\n",
    "#             if user_input.lower() == \"reset\":\n",
    "#                 history.reset()\n",
    "#                 print(\"âœ… Conversation reset. Let's start fresh!\\n\")\n",
    "#                 continue\n",
    "#             if not user_input:\n",
    "#                 continue\n",
    "\n",
    "#             print(f\"\\n[User input]: {user_input}\")\n",
    "            \n",
    "#             # Classify and extract entities\n",
    "#             history.set_original_task(user_input)\n",
    "#             classification = classifier(user_input)[0]\n",
    "            \n",
    "#             # Check if clarification needed\n",
    "#             missing = history.get_missing_info()\n",
    "            \n",
    "#             # Also check for vague pronouns\n",
    "#             if re.search(r\"\\b(this|that|it|there)\\b\", user_input.lower()) and not missing:\n",
    "#                 missing = [\"clarify_reference\"]\n",
    "            \n",
    "#             if missing:\n",
    "#                 # USE TEMPLATE-BASED QUESTIONS (primary method)\n",
    "#                 question = generate_clarifying_question_template(history)\n",
    "#                 print(f\"\\nðŸ’¬ Agent: {question}\\n\")\n",
    "#                 in_clarification = True\n",
    "#             else:\n",
    "#                 # Enough info - generate plan\n",
    "#                 print(f\"\\nðŸ’¬ Agent: Got it! Let me prepare that for you...\\n\")\n",
    "#                 reasoning, json_plan, path = decompose_and_generate_json(history)\n",
    "#                 history.reset()\n",
    "\n",
    "#         else:\n",
    "#             # In clarification mode\n",
    "#             answer = input(\"ðŸ‘¤ You: \").strip()\n",
    "            \n",
    "#             if answer.lower() == \"quit\":\n",
    "#                 print(\"\\nðŸ‘‹ Thanks for using the agent. Goodbye!\")\n",
    "#                 break\n",
    "#             if answer.lower() == \"reset\":\n",
    "#                 history.reset()\n",
    "#                 in_clarification = False\n",
    "#                 print(\"âœ… Conversation reset. Let's start fresh!\\n\")\n",
    "#                 continue\n",
    "#             if not answer:\n",
    "#                 continue\n",
    "\n",
    "#             print(f\"\\n[User response]: {answer}\")\n",
    "            \n",
    "#             # Record the clarification\n",
    "#             history.add_clarification(history.last_question, answer)\n",
    "            \n",
    "#             # Check if more info needed\n",
    "#             missing = history.get_missing_info()\n",
    "            \n",
    "#             if missing:\n",
    "#                 question = generate_clarifying_question_template(history)\n",
    "#                 print(f\"\\nðŸ’¬ Agent: {question}\\n\")\n",
    "#             else:\n",
    "#                 # All info collected\n",
    "#                 print(f\"\\nðŸ’¬ Agent: Perfect! I have everything I need. Preparing your task...\\n\")\n",
    "#                 reasoning, json_plan, path = decompose_and_generate_json(history)\n",
    "#                 history.reset()\n",
    "#                 in_clarification = False\n",
    "\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"\\n\\nðŸ‘‹ Interrupted. Goodbye!\")\n",
    "#         break\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nâš ï¸ Error: {e}\")\n",
    "#         print(\"Let's try again. Please rephrase your request.\\n\")\n",
    "#         history.reset()\n",
    "#         in_clarification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb4aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Reasoner loaded.\n",
      "\n",
      "======================================================================\n",
      "ðŸ¤– SMART LANGUAGE AGENT\n",
      "======================================================================\n",
      "I'm here to help you complete tasks. Just tell me what you need!\n",
      "Type 'quit' to exit, 'reset' to start over.\n",
      "\n",
      "\n",
      "[User input]: solve this\n",
      "\n",
      "ðŸ’¬ Agent: Can you summarize the benefits of using a chatbot as an A/B testing tool for ecommerce websites according to the text material given above?\n",
      "\n",
      "\n",
      "ðŸ‘‹ Thanks for chatting! Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# # ==========================================================\n",
    "# # ðŸ¤– ENHANCED SMART LANGUAGE AGENT (LLM-Driven Version)\n",
    "# # ==========================================================\n",
    "# from transformers import pipeline, AutoTokenizer, set_seed\n",
    "# import torch\n",
    "# import os\n",
    "# import re\n",
    "# import json\n",
    "# import uuid\n",
    "# import time\n",
    "\n",
    "# # Set seed for reproducibility\n",
    "# set_seed(42)\n",
    "\n",
    "# # --- Load Reasoning Model ---\n",
    "# reasoning_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "# print(f\"Loading {reasoning_model_name}...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(reasoning_model_name)\n",
    "\n",
    "# reasoner = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=reasoning_model_name,\n",
    "#     tokenizer=tokenizer,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float32\n",
    "# )\n",
    "# print(\"âœ… Reasoner loaded.\")\n",
    "\n",
    "# # ==========================================================\n",
    "# # ACTION TYPES AND REQUIRED INFORMATION MAPPING\n",
    "# # ==========================================================\n",
    "# ACTION_REQUIREMENTS = {\n",
    "#     \"save\": {\n",
    "#         \"required\": [\"what_to_save\", \"source_context\", \"destination\", \"format\"],\n",
    "#         \"description\": \"saving a file or document\"\n",
    "#     },\n",
    "#     \"open\": {\n",
    "#         \"required\": [\"what_to_open\"],\n",
    "#         \"description\": \"opening an application, file, or website\"\n",
    "#     },\n",
    "#     \"browse\": {\n",
    "#         \"required\": [\"browser_choice\", \"url_or_query\"],\n",
    "#         \"description\": \"browsing the internet\"\n",
    "#     },\n",
    "#     \"send_message\": {\n",
    "#         \"required\": [\"platform\", \"recipient\", \"message_content\"],\n",
    "#         \"description\": \"sending a message\"\n",
    "#     },\n",
    "#     \"search\": {\n",
    "#         \"required\": [\"search_target\", \"search_location\"],\n",
    "#         \"description\": \"searching for files or content\"\n",
    "#     },\n",
    "#     \"solve\": {\n",
    "#         \"required\": [\"problem_type\", \"problem_source\", \"course_subject\"],\n",
    "#         \"description\": \"solving assignments or problems\"\n",
    "#     },\n",
    "#     \"calculate\": {\n",
    "#         \"required\": [\"expression\"],\n",
    "#         \"description\": \"performing calculations\"\n",
    "#     },\n",
    "#     \"convert\": {\n",
    "#         \"required\": [\"source_file\", \"target_format\"],\n",
    "#         \"description\": \"converting files between formats\"\n",
    "#     },\n",
    "#     \"delete\": {\n",
    "#         \"required\": [\"what_to_delete\", \"confirmation\"],\n",
    "#         \"description\": \"deleting files or content\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # ==========================================================\n",
    "# # CONVERSATION HISTORY MANAGER\n",
    "# # ==========================================================\n",
    "# class ConversationHistory:\n",
    "#     def __init__(self):\n",
    "#         self.messages = []\n",
    "#         self.original_task = None\n",
    "#         self.clarifications = []\n",
    "#         self.entities_mentioned = {}\n",
    "#         self.questions_asked = set()\n",
    "#         self.conversation_context = []\n",
    "\n",
    "#     def set_original_task(self, task):\n",
    "#         self.original_task = task\n",
    "#         self.conversation_context.append({\"role\": \"user\", \"content\": task})\n",
    "#         self._extract_entities(task)\n",
    "\n",
    "#     def add_clarification(self, question, answer):\n",
    "#         self.clarifications.append({\"question\": question, \"answer\": answer})\n",
    "#         self.conversation_context.append({\"role\": \"assistant\", \"content\": question})\n",
    "#         self.conversation_context.append({\"role\": \"user\", \"content\": answer})\n",
    "#         self._extract_entities(answer)\n",
    "\n",
    "#     def get_full_context(self):\n",
    "#         context = f\"Original request: {self.original_task}\\n\"\n",
    "#         if self.clarifications:\n",
    "#             context += \"Conversation:\\n\"\n",
    "#             for i, c in enumerate(self.clarifications, 1):\n",
    "#                 context += f\"  Agent: {c['question']}\\n  User: {c['answer']}\\n\"\n",
    "#         return context\n",
    "\n",
    "#     def _extract_entities(self, text):\n",
    "#         \"\"\"Extract task-relevant entities from text.\"\"\"\n",
    "#         if not text:\n",
    "#             return\n",
    "            \n",
    "#         t = text.lower()\n",
    "\n",
    "#         # ACTION DETECTION (Enhanced)\n",
    "#         if re.search(r\"\\b(save|store|download|export|save as)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"save\"\n",
    "#         elif re.search(r\"\\b(open|launch|start|run)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"open\"\n",
    "#         elif re.search(r\"\\b(browse|surf|go to|visit|internet)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"browse\"\n",
    "#         elif re.search(r\"\\b(delete|remove|erase|trash)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"delete\"\n",
    "#         elif re.search(r\"\\b(send|message|text|dm|post)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"send_message\"\n",
    "#         elif re.search(r\"\\b(search|find|lookup|locate)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"search\"\n",
    "#         elif re.search(r\"\\b(solve|help with|do|complete|work on)\\b.*\\b(assignment|homework|problem|exercise|quiz|test)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"solve\"\n",
    "#         elif re.search(r\"\\b(convert|transform|change|make into)\\b\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"convert\"\n",
    "#         elif re.search(r\"\\b(calculate|compute|solve|what is)\\b.*[\\d\\+\\-\\*/]\", t):\n",
    "#             self.entities_mentioned[\"action\"] = \"calculate\"\n",
    "        \n",
    "#         # ACADEMIC/ASSIGNMENT DETECTION\n",
    "#         if re.search(r\"\\b(assignment|homework|problem|exercise|quiz|test|exam|project)\\b\", t):\n",
    "#             self.entities_mentioned[\"problem_type\"] = \"assignment\"\n",
    "            \n",
    "#             # Course detection\n",
    "#             course_match = re.search(r\"\\b(math|physics|chemistry|biology|english|history|computer science|programming|calculus)\\b\", t, re.IGNORECASE)\n",
    "#             if course_match:\n",
    "#                 self.entities_mentioned[\"course_subject\"] = course_match.group(1)\n",
    "            \n",
    "#             # Platform detection\n",
    "#             if re.search(r\"\\b(moodle|canvas|blackboard|google classroom)\\b\", t):\n",
    "#                 self.entities_mentioned[\"problem_source\"] = \"online_platform\"\n",
    "#                 platform_match = re.search(r\"\\b(moodle|canvas|blackboard|google classroom)\\b\", t, re.IGNORECASE)\n",
    "#                 if platform_match:\n",
    "#                     self.entities_mentioned[\"platform_name\"] = platform_match.group(1)\n",
    "        \n",
    "#         # SOURCE CONTEXT\n",
    "#         if re.search(r\"\\b(currently open|open file|current|this application|active window)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"open_application\"\n",
    "#         elif re.search(r\"\\b(website|webpage|web page|browser|online|url|http)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"web\"\n",
    "#         elif re.search(r\"\\b(file|document|folder|directory|desktop|downloads|my pc|computer|disk)\\b\", t):\n",
    "#             self.entities_mentioned[\"source_context\"] = \"local_file\"\n",
    "        \n",
    "#         # APPLICATION DETECTION\n",
    "#         app_patterns = {\n",
    "#             \"chrome\": r\"\\b(chrome|google chrome)\\b\",\n",
    "#             \"firefox\": r\"\\b(firefox|mozilla)\\b\",\n",
    "#             \"edge\": r\"\\b(edge|microsoft edge)\\b\",\n",
    "#             \"word\": r\"\\b(word|winword|microsoft word|ms word)\\b\",\n",
    "#             \"excel\": r\"\\b(excel|ms excel|microsoft excel)\\b\",\n",
    "#             \"powerpoint\": r\"\\b(powerpoint|ppt|ms powerpoint)\\b\",\n",
    "#             \"notepad\": r\"\\b(notepad)\\b\",\n",
    "#             \"calculator\": r\"\\b(calculator|calc)\\b\",\n",
    "#             \"spotify\": r\"\\b(spotify)\\b\",\n",
    "#             \"discord\": r\"\\b(discord)\\b\",\n",
    "#             \"whatsapp\": r\"\\b(whatsapp)\\b\",\n",
    "#             \"moodle\": r\"\\b(moodle)\\b\"\n",
    "#         }\n",
    "#         for app, pattern in app_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"app_name\"] = app\n",
    "#                 break\n",
    "        \n",
    "#         # Generic browser/internet\n",
    "#         if re.search(r\"\\b(browser|internet)\\b\", t) and \"app_name\" not in self.entities_mentioned:\n",
    "#             self.entities_mentioned[\"needs_browser\"] = True\n",
    "\n",
    "#         # FILENAME DETECTION\n",
    "#         file_match = re.search(r\"([\\w\\-\\s]+?\\.(?:pdf|docx?|xlsx?|pptx?|txt|csv|png|jpg|jpeg|mp3|mp4))\", text, flags=re.IGNORECASE)\n",
    "#         if file_match:\n",
    "#             self.entities_mentioned[\"filename\"] = file_match.group(1).strip()\n",
    "        \n",
    "#         # DESTINATION DETECTION\n",
    "#         dest_patterns = {\n",
    "#             \"desktop\": r\"\\b(desktop|on desktop)\\b\",\n",
    "#             \"downloads\": r\"\\b(downloads|download folder)\\b\",\n",
    "#             \"documents\": r\"\\b(documents|my documents)\\b\"\n",
    "#         }\n",
    "#         for dest, pattern in dest_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"destination\"] = dest\n",
    "#                 break\n",
    "\n",
    "#         # FORMAT DETECTION\n",
    "#         format_patterns = {\n",
    "#             \"pdf\": r\"\\b(as pdf|to pdf|pdf format|\\.pdf)\\b\",\n",
    "#             \"docx\": r\"\\b(as docx|to word|word document|\\.docx)\\b\",\n",
    "#             \"txt\": r\"\\b(as txt|to text|text file|\\.txt)\\b\",\n",
    "#             \"xlsx\": r\"\\b(as xlsx|to excel|spreadsheet|\\.xlsx)\\b\"\n",
    "#         }\n",
    "#         for fmt, pattern in format_patterns.items():\n",
    "#             if re.search(pattern, t):\n",
    "#                 self.entities_mentioned[\"target_format\"] = fmt\n",
    "#                 break\n",
    "\n",
    "#         # MESSAGING PLATFORM\n",
    "#         if re.search(r\"\\b(discord)\\b\", t):\n",
    "#             self.entities_mentioned[\"platform\"] = \"discord\"\n",
    "#         elif re.search(r\"\\b(whatsapp)\\b\", t):\n",
    "#             self.entities_mentioned[\"platform\"] = \"whatsapp\"\n",
    "        \n",
    "#         # RECIPIENT\n",
    "#         recipient_match = re.search(r\"\\b(?:to|message|dm)\\s+([\\w\\s]+?)(?:\\s+on|\\s+channel|$)\", t)\n",
    "#         if recipient_match:\n",
    "#             self.entities_mentioned[\"recipient\"] = recipient_match.group(1).strip()\n",
    "        \n",
    "#         # MESSAGE CONTENT\n",
    "#         msg_match = re.search(r\"(?:say|message|text|send)\\s+['\\\"](.+?)['\\\"]\", text, flags=re.IGNORECASE)\n",
    "#         if msg_match:\n",
    "#             self.entities_mentioned[\"message_content\"] = msg_match.group(1).strip()\n",
    "\n",
    "#         # SEARCH QUERY\n",
    "#         search_match = re.search(r\"(?:search for|find|lookup)\\s+(.+?)(?:\\s+in|\\s+on|$)\", text, flags=re.IGNORECASE)\n",
    "#         if search_match:\n",
    "#             self.entities_mentioned[\"search_target\"] = search_match.group(1).strip()\n",
    "        \n",
    "#         # SEARCH LOCATION\n",
    "#         if re.search(r\"\\b(entire pc|whole computer|everywhere|all drives)\\b\", t):\n",
    "#             self.entities_mentioned[\"search_location\"] = \"entire_pc\"\n",
    "#         elif re.search(r\"\\b(downloads|download folder)\\b\", t):\n",
    "#             self.entities_mentioned[\"search_location\"] = \"downloads\"\n",
    "\n",
    "#         # URL Detection\n",
    "#         url_match = re.search(r\"(https?://[^\\s]+|www\\.[^\\s]+)\", text, flags=re.IGNORECASE)\n",
    "#         if url_match:\n",
    "#             self.entities_mentioned[\"url\"] = url_match.group(1).strip()\n",
    "\n",
    "#         # EXPRESSION FOR CALCULATION\n",
    "#         expr_match = re.search(r\"([\\d\\.\\+\\-\\*/\\^\\(\\)\\s]+)$\", text or \"\")\n",
    "#         if expr_match and len(expr_match.group(1).strip()) > 2:\n",
    "#             self.entities_mentioned[\"expression\"] = expr_match.group(1).strip()\n",
    "\n",
    "#     def get_missing_info(self):\n",
    "#         \"\"\"Determine what critical information is missing based on action.\"\"\"\n",
    "#         action = self.entities_mentioned.get(\"action\")\n",
    "        \n",
    "#         if not action:\n",
    "#             return [\"action_clarification\"]\n",
    "        \n",
    "#         if action not in ACTION_REQUIREMENTS:\n",
    "#             return []\n",
    "        \n",
    "#         required = ACTION_REQUIREMENTS[action][\"required\"]\n",
    "#         missing = []\n",
    "        \n",
    "#         for req in required:\n",
    "#             if req not in self.entities_mentioned:\n",
    "#                 # Check if already asked about this\n",
    "#                 if req not in self.questions_asked:\n",
    "#                     missing.append(req)\n",
    "        \n",
    "#         return missing\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.__init__()\n",
    "\n",
    "# # ==========================================================\n",
    "# # LLM-BASED QUESTION GENERATOR\n",
    "# # ==========================================================\n",
    "# def generate_natural_question(history):\n",
    "#     \"\"\"Generate natural, context-aware clarifying question using LLM.\"\"\"\n",
    "    \n",
    "#     missing = history.get_missing_info()\n",
    "#     if not missing:\n",
    "#         return None\n",
    "    \n",
    "#     missing_key = missing[0]\n",
    "#     action = history.entities_mentioned.get(\"action\", \"task\")\n",
    "    \n",
    "#     # Build context from conversation\n",
    "#     conversation_summary = \"\"\n",
    "#     if history.clarifications:\n",
    "#         conversation_summary = \"\\nPrevious conversation:\\n\"\n",
    "#         for c in history.clarifications[-3:]:  # Last 3 exchanges\n",
    "#             conversation_summary += f\"Agent: {c['question']}\\nUser: {c['answer']}\\n\"\n",
    "    \n",
    "#     # Few-shot examples for natural question generation\n",
    "#     few_shot_examples = \"\"\"Example 1:\n",
    "# User: \"save this\"\n",
    "# Agent needs: what_to_save, source_context\n",
    "# Agent: \"What would you like me to save? Is it something currently open, a file on your computer, or content from a website?\"\n",
    "\n",
    "# Example 2:\n",
    "# User: \"help me with my assignment\"\n",
    "# Agent needs: problem_type, course_subject, problem_source\n",
    "# Agent: \"I'd be happy to help! What subject is this assignment for, and where can I find it?\"\n",
    "\n",
    "# Example 3:\n",
    "# User: \"search image clouds.jpg\"\n",
    "# Agent needs: search_location\n",
    "# Agent: \"Got it. Should I search just in Downloads, or do you want me to check your entire computer?\"\n",
    "\n",
    "# Example 4:\n",
    "# User: \"open browser\"\n",
    "# Agent needs: browser_choice, url_or_query\n",
    "# Agent: \"Sure! Which browser would you like - Chrome, Firefox, or Edge? And what would you like to do once it's open?\"\n",
    "\n",
    "# Example 5:\n",
    "# User: \"send a message\"\n",
    "# Agent needs: platform, recipient\n",
    "# Agent: \"I can do that. Which platform - Discord or WhatsApp? And who should I send it to?\"\n",
    "# \"\"\"\n",
    "    \n",
    "#     # Create prompt for natural question generation\n",
    "#     prompt = f\"\"\"You are a helpful desktop assistant having a natural conversation with a user.\n",
    "\n",
    "# {few_shot_examples}\n",
    "\n",
    "# Current situation:\n",
    "# User's original request: \"{history.original_task}\"{conversation_summary}\n",
    "\n",
    "# The user wants to: {action}\n",
    "# Missing information: {missing_key}\n",
    "\n",
    "# Generate ONE natural, conversational question to ask the user. The question should:\n",
    "# - Sound like a human assistant, not a robot\n",
    "# - Be clear and specific about what you need to know\n",
    "# - Be contextually relevant to what the user has already said\n",
    "# - Not repeat information already provided\n",
    "# - Be concise (1-2 sentences max)\n",
    "\n",
    "# Question:\"\"\"\n",
    "\n",
    "#     try:\n",
    "#         response = reasoner(\n",
    "#             prompt,\n",
    "#             max_new_tokens=80,\n",
    "#             do_sample=True,\n",
    "#             temperature=0.7,\n",
    "#             top_p=0.9,\n",
    "#             pad_token_id=tokenizer.eos_token_id,\n",
    "#             repetition_penalty=1.3,\n",
    "#             num_return_sequences=1\n",
    "#         )\n",
    "        \n",
    "#         raw = response[0][\"generated_text\"]\n",
    "#         question = raw.split(\"Question:\")[-1].strip()\n",
    "        \n",
    "#         # Clean up\n",
    "#         question = question.split('\\n')[0].strip()\n",
    "        \n",
    "#         # Validation\n",
    "#         if len(question) < 10 or len(question) > 200 or '?' not in question:\n",
    "#             raise ValueError(\"Invalid question format\")\n",
    "        \n",
    "#         # Mark as asked\n",
    "#         history.questions_asked.add(missing_key)\n",
    "        \n",
    "#         return question\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         # Fallback to rule-based question\n",
    "#         return generate_fallback_question(missing_key, action, history)\n",
    "\n",
    "# def generate_fallback_question(missing_key, action, history):\n",
    "#     \"\"\"Fallback questions when LLM fails.\"\"\"\n",
    "    \n",
    "#     fallback_map = {\n",
    "#         \"action_clarification\": \"What would you like me to help you with?\",\n",
    "#         \"what_to_save\": \"What would you like me to save?\",\n",
    "#         \"source_context\": \"Is this something currently open, a file on your computer, or from a website?\",\n",
    "#         \"destination\": \"Where should I save it - Desktop, Downloads, or Documents?\",\n",
    "#         \"format\": \"What format should I save it as - PDF, Word, or something else?\",\n",
    "#         \"what_to_open\": \"What would you like me to open?\",\n",
    "#         \"browser_choice\": \"Which browser would you like - Chrome, Firefox, or Edge?\",\n",
    "#         \"url_or_query\": \"What would you like to browse or search for?\",\n",
    "#         \"platform\": \"Which messaging app - Discord or WhatsApp?\",\n",
    "#         \"recipient\": \"Who should I send the message to?\",\n",
    "#         \"message_content\": \"What should the message say?\",\n",
    "#         \"search_target\": \"What are you looking for?\",\n",
    "#         \"search_location\": \"Should I search in a specific folder, or check your entire computer?\",\n",
    "#         \"problem_type\": \"What kind of assignment is this?\",\n",
    "#         \"problem_source\": \"Where can I find this assignment?\",\n",
    "#         \"course_subject\": \"What subject is this for?\",\n",
    "#         \"expression\": \"What calculation do you need?\",\n",
    "#         \"source_file\": \"Which file should I convert?\",\n",
    "#         \"target_format\": \"What format would you like?\",\n",
    "#         \"confirmation\": \"Are you sure you want to delete this?\"\n",
    "#     }\n",
    "    \n",
    "#     history.questions_asked.add(missing_key)\n",
    "#     return fallback_map.get(missing_key, \"Could you provide more details?\")\n",
    "\n",
    "# # ==========================================================\n",
    "# # TASK REASONING AND JSON GENERATION\n",
    "# # ==========================================================\n",
    "# def generate_task_reasoning(history):\n",
    "#     \"\"\"Generate step-by-step reasoning for task execution.\"\"\"\n",
    "    \n",
    "#     context = history.get_full_context()\n",
    "#     entities = history.entities_mentioned\n",
    "#     action = entities.get(\"action\", \"task\")\n",
    "    \n",
    "#     prompt = f\"\"\"Given the following task and information, provide a clear 2-3 sentence explanation of how to complete it.\n",
    "\n",
    "# Task: {history.original_task}\n",
    "\n",
    "# Gathered information:\n",
    "# {json.dumps(entities, indent=2)}\n",
    "\n",
    "# Provide step-by-step reasoning in 2-3 sentences. Be specific and actionable.\n",
    "\n",
    "# Reasoning:\"\"\"\n",
    "\n",
    "#     try:\n",
    "#         response = reasoner(\n",
    "#             prompt,\n",
    "#             max_new_tokens=150,\n",
    "#             do_sample=False,\n",
    "#             pad_token_id=tokenizer.eos_token_id,\n",
    "#             repetition_penalty=1.2\n",
    "#         )\n",
    "        \n",
    "#         raw = response[0][\"generated_text\"]\n",
    "#         reasoning = raw.split(\"Reasoning:\")[-1].strip()\n",
    "        \n",
    "#         # Clean up\n",
    "#         sentences = [s.strip() for s in reasoning.split('.') if s.strip()]\n",
    "#         reasoning = '. '.join(sentences[:3]) + '.'\n",
    "        \n",
    "#         return reasoning\n",
    "        \n",
    "#     except Exception:\n",
    "#         return generate_rule_based_reasoning(entities)\n",
    "\n",
    "# def generate_rule_based_reasoning(entities):\n",
    "#     \"\"\"Fallback reasoning generator.\"\"\"\n",
    "#     action = entities.get(\"action\", \"task\")\n",
    "    \n",
    "#     reasoning_templates = {\n",
    "#         \"save\": \"The system will locate the specified content, convert it to the requested format, and save it to the designated location.\",\n",
    "#         \"open\": f\"The system will launch {entities.get('app_name', 'the application')} and navigate to the specified location if provided.\",\n",
    "#         \"solve\": f\"The system will access the {entities.get('course_subject', 'assignment')} content from {entities.get('platform_name', 'the platform')} and provide assistance with solving it.\",\n",
    "#         \"search\": f\"The system will search for '{entities.get('search_target', 'the file')}' in {entities.get('search_location', 'the specified location')}.\",\n",
    "#         \"send_message\": f\"The system will open {entities.get('platform', 'the messaging app')} and send the message to {entities.get('recipient', 'the recipient')}.\",\n",
    "#         \"browse\": f\"The system will open {entities.get('app_name', 'the browser')} and navigate to the specified location.\"\n",
    "#     }\n",
    "    \n",
    "#     return reasoning_templates.get(action, \"The system will execute the requested task based on the provided information.\")\n",
    "\n",
    "# def build_coordinator_json(history):\n",
    "#     \"\"\"Build JSON structure for Coordinator Agent.\"\"\"\n",
    "    \n",
    "#     entities = history.entities_mentioned\n",
    "#     action = entities.get(\"action\", \"unknown\")\n",
    "    \n",
    "#     # Determine context\n",
    "#     source_context = entities.get(\"source_context\", \"\")\n",
    "#     if source_context == \"web\" or action == \"browse\":\n",
    "#         json_context = \"web\"\n",
    "#     elif action in [\"open\", \"send_message\", \"calculate\", \"search\"]:\n",
    "#         json_context = \"local\"\n",
    "#     else:\n",
    "#         json_context = \"system\"\n",
    "    \n",
    "#     # Build params based on action\n",
    "#     params = {}\n",
    "    \n",
    "#     if action == \"save\":\n",
    "#         filename = entities.get(\"filename\", \"document\")\n",
    "#         target_format = entities.get(\"target_format\", \"pdf\")\n",
    "        \n",
    "#         if not filename.endswith(f\".{target_format}\"):\n",
    "#             if '.' in filename:\n",
    "#                 filename = filename.rsplit('.', 1)[0]\n",
    "#             filename = f\"{filename}.{target_format}\"\n",
    "        \n",
    "#         dest = entities.get(\"destination\", \"desktop\")\n",
    "#         params[\"file_path\"] = f\"{{{{{dest}_path}}}}/{filename}\"\n",
    "#         params[\"format\"] = target_format\n",
    "        \n",
    "#         if entities.get(\"source_context\") == \"open_application\":\n",
    "#             params[\"source\"] = \"current_application\"\n",
    "#         else:\n",
    "#             params[\"source\"] = \"file_system\"\n",
    "    \n",
    "#     elif action == \"solve\":\n",
    "#         params[\"assignment_type\"] = entities.get(\"problem_type\", \"assignment\")\n",
    "#         params[\"subject\"] = entities.get(\"course_subject\", \"\")\n",
    "#         params[\"platform\"] = entities.get(\"platform_name\", \"\")\n",
    "#         params[\"source\"] = entities.get(\"problem_source\", \"online_platform\")\n",
    "    \n",
    "#     elif action == \"open\":\n",
    "#         if entities.get(\"app_name\"):\n",
    "#             params[\"app_name\"] = entities[\"app_name\"]\n",
    "#         if entities.get(\"filename\"):\n",
    "#             params[\"file_path\"] = entities[\"filename\"]\n",
    "    \n",
    "#     elif action == \"browse\":\n",
    "#         params[\"browser\"] = entities.get(\"app_name\", \"chrome\")\n",
    "#         if entities.get(\"url\"):\n",
    "#             params[\"url\"] = entities[\"url\"]\n",
    "#         elif entities.get(\"search_query\"):\n",
    "#             params[\"search_query\"] = entities[\"search_query\"]\n",
    "    \n",
    "#     elif action == \"send_message\":\n",
    "#         params[\"platform\"] = entities.get(\"platform\", \"\")\n",
    "#         params[\"recipient\"] = entities.get(\"recipient\", \"\")\n",
    "#         params[\"message\"] = entities.get(\"message_content\", \"\")\n",
    "    \n",
    "#     elif action == \"search\":\n",
    "#         params[\"target\"] = entities.get(\"search_target\", \"\")\n",
    "#         params[\"location\"] = entities.get(\"search_location\", \"downloads\")\n",
    "#         params[\"search_scope\"] = entities.get(\"search_location\", \"specific_folder\")\n",
    "    \n",
    "#     elif action == \"calculate\":\n",
    "#         params[\"expression\"] = entities.get(\"expression\", \"\")\n",
    "    \n",
    "#     # Build final JSON\n",
    "#     json_output = {\n",
    "#         \"action\": action,\n",
    "#         \"context\": json_context,\n",
    "#         \"params\": params,\n",
    "#         \"task_id\": \"\",\n",
    "#         \"depends_on\": \"\",\n",
    "#         \"priority\": \"\",\n",
    "#         \"timeout\": \"\",\n",
    "#         \"retry_count\": \"\"\n",
    "#     }\n",
    "    \n",
    "#     return json_output\n",
    "\n",
    "# def finalize_task(history):\n",
    "#     \"\"\"Generate reasoning and JSON, save to file.\"\"\"\n",
    "    \n",
    "#     reasoning = generate_task_reasoning(history)\n",
    "#     json_output = build_coordinator_json(history)\n",
    "    \n",
    "#     # Save to file\n",
    "#     os.makedirs(\"output_logs\", exist_ok=True)\n",
    "#     timestamp = int(time.time())\n",
    "#     fname = f\"output_logs/task_{timestamp}_{str(uuid.uuid4())[:8]}.json\"\n",
    "    \n",
    "#     with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump({\n",
    "#             \"reasoning\": reasoning,\n",
    "#             \"task_json\": json_output\n",
    "#         }, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "#     print(\"\\nðŸ§  Task Reasoning:\")\n",
    "#     print(reasoning)\n",
    "#     print(\"\\nðŸ“‹ Generated JSON for Coordinator Agent:\")\n",
    "#     print(json.dumps(json_output, indent=2))\n",
    "#     print(f\"\\nðŸ’¾ Saved to: {fname}\\n\")\n",
    "    \n",
    "#     return reasoning, json_output, fname\n",
    "\n",
    "# # ==========================================================\n",
    "# # MAIN INTERACTION LOOP\n",
    "# # ==========================================================\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"ðŸ¤– SMART LANGUAGE AGENT\")\n",
    "# print(\"=\" * 70)\n",
    "# print(\"I'm here to help you complete tasks. Just tell me what you need!\")\n",
    "# print(\"Type 'quit' to exit, 'reset' to start over.\\n\")\n",
    "\n",
    "# history = ConversationHistory()\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         user_input = input(\"ðŸ‘¤ You: \").strip()\n",
    "        \n",
    "#         if user_input.lower() == \"quit\":\n",
    "#             print(\"\\nðŸ‘‹ Thanks for chatting! Goodbye!\")\n",
    "#             break\n",
    "#         if user_input.lower() == \"reset\":\n",
    "#             history.reset()\n",
    "#             print(\"âœ… Let's start fresh!\\n\")\n",
    "#             continue\n",
    "#         if not user_input:\n",
    "#             continue\n",
    "        \n",
    "#         print(f\"\\n[User input]: {user_input}\")\n",
    "        \n",
    "#         # First input or continuing conversation\n",
    "#         if not history.original_task:\n",
    "#             history.set_original_task(user_input)\n",
    "#         else:\n",
    "#             # This is a response to a clarification\n",
    "#             if history.conversation_context:\n",
    "#                 last_question = history.conversation_context[-1][\"content\"]\n",
    "#                 history.add_clarification(last_question, user_input)\n",
    "        \n",
    "#         # Check if we need more information\n",
    "#         missing = history.get_missing_info()\n",
    "        \n",
    "#         if missing:\n",
    "#             question = generate_natural_question(history)\n",
    "#             if question:\n",
    "#                 print(f\"\\nðŸ’¬ Agent: {question}\\n\")\n",
    "#         else:\n",
    "#             # We have everything we need\n",
    "#             print(f\"\\nðŸ’¬ Agent: Perfect! Let me get that ready for you...\\n\")\n",
    "#             finalize_task(history)\n",
    "#             history.reset()\n",
    "    \n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"\\n\\nðŸ‘‹ Interrupted. Goodbye!\")\n",
    "#         break\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nâš ï¸ Oops, something went wrong: {e}\")\n",
    "#         print(\"Let's try that again. What would you like me to do?\\n\")\n",
    "#         history.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
