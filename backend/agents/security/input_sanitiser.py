"""
INPUT SANITISER â€” DiD Layer 1
Checks raw user input before it reaches the LLM.
Called from: language_agent.py â†’ handle_user_input()

Checks applied (in order):
  S-04  Length cap        â€” truncate first so all later checks see bounded text
  S-05  Unicode normalise â€” NFKC + confusables map (Cyrillic lookalikes â†’ ASCII)
  S-01  Override keywords â€” injection phrases
  S-02  Base64 decode     â€” re-check decoded content for S-01 patterns
  S-03  Delimiters        â€” ChatML / role tokens
"""

import re
import base64
import unicodedata
import logging
from dataclasses import dataclass, field
from typing import List

logger = logging.getLogger(__name__)

# â”€â”€â”€ Result object â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class SanitisationResult:
    original_text: str
    clean_text: str
    was_blocked: bool = False
    was_modified: bool = False
    risk_level: str = "LOW"          # LOW | MEDIUM | HIGH | CRITICAL
    triggered_checks: List[str] = field(default_factory=list)
    block_reason: str = ""

# â”€â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MAX_LENGTH = 4096

# S-01: Instruction override / role hijack patterns
OVERRIDE_PATTERNS = [
    r"ignore\s+(all\s+)?(previous|prior|above)\s+instructions?",
    r"disregard\s+(all\s+)?(previous|prior|above|your)\s+",
    r"forget\s+(everything|all\s+instructions?|your\s+instructions?)",
    r"new\s+system\s+prompt",
    r"you\s+are\s+now\s+",
    r"act\s+as\s+(if\s+you\s+(are|have)|a\s+)",
    r"pretend\s+(you\s+are|to\s+be)\s+",
    r"(reveal|show|output|print|display)\s+(the\s+)?(password|api.?key|secret|token|mongodb|database\s+uri)",
    r"(bypass|override|disable)\s+(your\s+)?(safety|security|filter|restriction)",
    r"from\s+now\s+on\s+(you\s+are|ignore)",
    r"your\s+(true\s+)?instructions?\s+(are|is)\s+",
]

# S-03: Prompt role delimiter tokens
DELIMITER_PATTERNS = [
    r"<\|system\|>",
    r"<\|user\|>",
    r"<\|assistant\|>",
    r"\[INST\]",
    r"<<SYS>>",
    r"\[/INST\]",
    r"<</SYS>>",
]

# S-05: Confusables map â€” visually identical characters that NFKC does NOT collapse
# Maps lookalike Unicode chars â†’ their ASCII equivalent for pattern matching only
# (we normalise a COPY for matching; the user's clean_text keeps NFKC form)
CONFUSABLES = {
    # Cyrillic â†’ Latin
    '\u0456': 'i',   # Ñ–  Cyrillic Byelorussian-Ukrainian I  â†’ i
    '\u0430': 'a',   # Ð°  Cyrillic Small Letter A            â†’ a
    '\u0435': 'e',   # Ðµ  Cyrillic Small Letter IE           â†’ e
    '\u043e': 'o',   # Ð¾  Cyrillic Small Letter O            â†’ o
    '\u0440': 'r',   # Ñ€  Cyrillic Small Letter ER           â†’ r
    '\u0441': 'c',   # Ñ  Cyrillic Small Letter ES           â†’ c
    '\u0445': 'x',   # Ñ…  Cyrillic Small Letter HA          â†’ x
    '\u0455': 's',   # Ñ•  Cyrillic Small Letter DZE         â†’ s
    '\u0440': 'r',   # Ñ€  Cyrillic Small Letter ER           â†’ r
    '\u0443': 'y',   # Ñƒ  Cyrillic Small Letter U            â†’ y
    # Greek â†’ Latin
    '\u03b1': 'a',   # Î±  Greek Small Letter Alpha           â†’ a
    '\u03b5': 'e',   # Îµ  Greek Small Letter Epsilon         â†’ e
    '\u03bf': 'o',   # Î¿  Greek Small Letter Omicron         â†’ o
    '\u03c1': 'p',   # Ï  Greek Small Letter Rho             â†’ p
    '\u03bd': 'v',   # Î½  Greek Small Letter Nu              â†’ v
    # Fullwidth â†’ ASCII
    '\uff49': 'i',   # ï½‰ Fullwidth Latin Small Letter I     â†’ i
    '\uff41': 'a',   # ï½ Fullwidth Latin Small Letter A     â†’ a
}


# â”€â”€â”€ InputSanitiser class â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class InputSanitiser:
    """
    Runs S-01 through S-05 checks on raw user input.
    Returns a SanitisationResult â€” caller decides what to do with it.

    Check order (important):
      S-04 first  â†’ truncate to MAX_LENGTH so all later checks see bounded text
      S-05 second â†’ unicode normalise + confusables mapping
      S-01 third  â†’ keyword patterns (on normalised text)
      S-02 fourth â†’ base64 decode and re-check
      S-03 fifth  â†’ delimiter tokens
    """

    def sanitise(self, text: str) -> SanitisationResult:
        result = SanitisationResult(
            original_text=text,
            clean_text=text
        )

        # â”€â”€ S-04 FIRST: truncate so all later checks see bounded input â”€â”€â”€â”€â”€â”€â”€â”€
        # This means a length-bomb injection suffix gets cut off before S-01 sees it
        self._s04_length(result)

        # â”€â”€ S-05: Unicode normalise (NFKC) + confusables map â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._s05_unicode_normalise(result)
        if result.was_blocked:
            return result

        # â”€â”€ S-01: Override / role-hijack keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._s01_override_keywords(result)
        if result.was_blocked:
            return result

        # â”€â”€ S-02: Base64 encoded payload â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._s02_base64(result)
        if result.was_blocked:
            return result

        # â”€â”€ S-03: Prompt delimiter tokens â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._s03_delimiters(result)

        # â”€â”€ Final risk level â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if result.was_blocked:
            result.risk_level = "CRITICAL"
        elif result.was_modified:
            result.risk_level = "MEDIUM"
        else:
            result.risk_level = "LOW"

        return result

    # â”€â”€ S-04 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _s04_length(self, result: SanitisationResult):
        """Truncate input that exceeds MAX_LENGTH. Runs FIRST."""
        if len(result.clean_text) > MAX_LENGTH:
            original_len = len(result.clean_text)
            result.clean_text = result.clean_text[:MAX_LENGTH] + " [INPUT TRUNCATED]"
            result.was_modified = True
            result.triggered_checks.append(f"S-04:truncated({original_len}â†’{MAX_LENGTH})")
            logger.warning(f"âœ‚ï¸  S-04: Input truncated {original_len} â†’ {MAX_LENGTH} chars")

    # â”€â”€ S-05 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _s05_unicode_normalise(self, result: SanitisationResult):
        """
        Two-pass normalisation:
          Pass 1 â€” NFKC (handles composed forms, fullwidth, etc.)
          Pass 2 â€” Confusables map (Cyrillic/Greek lookalikes NFKC doesn't collapse)

        We store the normalised text in clean_text so downstream checks use it.
        We also keep a 'match_text' (fully ASCII-folded) used only for S-01 matching.
        """
        original = result.clean_text

        # Pass 1: NFKC
        nfkc = unicodedata.normalize("NFKC", original)

        # Pass 2: confusables map on the NFKC result
        mapped = ''.join(CONFUSABLES.get(c, c) for c in nfkc)

        if mapped != original:
            result.was_modified = True
            result.triggered_checks.append("S-05:unicode_normalise")
            logger.info(f"ðŸ”¤ S-05: Unicode normalised (original had homoglyphs/composed chars)")
            logger.info(f"   Before: {repr(original[:60])}")
            logger.info(f"   After : {repr(mapped[:60])}")

        # Store fully-mapped version as clean_text so S-01 can match it
        result.clean_text = mapped

    # â”€â”€ S-01 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _s01_override_keywords(self, result: SanitisationResult):
        """Check for instruction override / role hijack phrases."""
        text_lower = result.clean_text.lower()
        for pattern in OVERRIDE_PATTERNS:
            if re.search(pattern, text_lower, re.IGNORECASE):
                result.was_blocked = True
                result.block_reason = f"S-01: Injection keyword matched: '{pattern}'"
                result.triggered_checks.append("S-01:override_keyword")
                logger.warning(f"ðŸš« S-01 BLOCKED â€” pattern: {pattern}")
                logger.warning(f"   Input preview: {result.clean_text[:100]}")
                return

    # â”€â”€ S-02 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _s02_base64(self, result: SanitisationResult):
        """Detect base64-encoded injections by decoding and re-scanning."""
        candidates = re.findall(r'[A-Za-z0-9+/]{20,}={0,2}', result.clean_text)
        for candidate in candidates:
            try:
                padded = candidate + "=" * (4 - len(candidate) % 4)
                decoded = base64.b64decode(padded).decode("utf-8", errors="ignore")
                decoded_lower = decoded.lower()
                for pattern in OVERRIDE_PATTERNS:
                    if re.search(pattern, decoded_lower, re.IGNORECASE):
                        result.was_blocked = True
                        result.block_reason = (
                            f"S-02: Base64-encoded injection detected "
                            f"(decoded: '{decoded[:60]}...')"
                        )
                        result.triggered_checks.append("S-02:base64_injection")
                        logger.warning(f"ðŸš« S-02 BLOCKED â€” base64 decoded to injection")
                        logger.warning(f"   Decoded: {decoded[:100]}")
                        return
            except Exception:
                pass

    # â”€â”€ S-03 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _s03_delimiters(self, result: SanitisationResult):
        """Detect prompt role delimiter tokens (ChatML, Llama, etc.)."""
        for pattern in DELIMITER_PATTERNS:
            if re.search(pattern, result.clean_text, re.IGNORECASE):
                result.was_blocked = True
                result.block_reason = f"S-03: Prompt delimiter token detected: '{pattern}'"
                result.triggered_checks.append("S-03:delimiter")
                logger.warning(f"ðŸš« S-03 BLOCKED â€” delimiter: {pattern}")
                return


# â”€â”€â”€ Module-level singleton + public function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_sanitiser = InputSanitiser()

def sanitise_input(text: str) -> SanitisationResult:
    """
    Public entry point â€” import and call this from language_agent.py.

    Usage in language_agent.py:
        from agents.security.input_sanitiser import sanitise_input
        result = sanitise_input(input_text)
        if result.was_blocked:
            # return early with rejection message
    """
    return _sanitiser.sanitise(text)